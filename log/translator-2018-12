2018-12-14 20:33:00,127 INFO Test worker  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 20:33:00,139 INFO Test worker  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 20:33:00,151 INFO Test worker  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@2911c5c7, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@25989219, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@97d00a, org.springframework.test.context.support.DirtiesContextTestExecutionListener@548321e4, org.springframework.test.context.transaction.TransactionalTestExecutionListener@731be94e, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@12f2a56e]
2018-12-14 20:33:00,852 INFO Test worker  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 6606 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/build/classes/test started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 20:33:00,853 INFO Test worker  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 20:33:00,931 INFO Test worker  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@6585a07f: startup date [Fri Dec 14 20:33:00 CET 2018]; root of context hierarchy
2018-12-14 20:33:01,398 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 20:33:02,050 INFO Test worker  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$d37b1678] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 20:33:03,593 INFO Test worker  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 20:33:03,601 INFO Test worker  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 20:33:03,662 INFO Test worker  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 20:33:03,663 INFO Test worker  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 20:33:03,665 INFO Test worker  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 20:33:03,796 INFO Test worker  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 20:33:03,853 INFO Test worker  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 20:33:04,000 INFO Test worker  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 20:33:04,301 INFO Test worker  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 20:33:04,313 INFO Test worker  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 20:33:05,249 INFO Test worker  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@6585a07f: startup date [Fri Dec 14 20:33:00 CET 2018]; root of context hierarchy
2018-12-14 20:33:05,323 INFO Test worker  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 20:33:05,324 INFO Test worker  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 20:33:05,353 INFO Test worker  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 20:33:05,353 INFO Test worker  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 20:33:05,391 INFO Test worker  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 20:33:05,728 INFO Test worker  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.49 seconds (JVM running for 6.904)
2018-12-14 20:33:05,731 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T19:33:05.721Z
2018-12-14 20:33:06,105 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - 9e772d9f-2e91-4f7c-a9b5-87f7e2bcb1db item bought at 2018-12-14T19:33:05.760Z
2018-12-14 20:33:06,222 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - 693805a4-f18c-4d63-b4ae-f03fe64a42f8 item bought at 2018-12-14T19:33:06.218Z
2018-12-14 20:33:06,240 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - 693805a4-f18c-4d63-b4ae-f03fe64a42f8 item paid at 2018-12-14T19:33:06.227Z
2018-12-14 20:33:06,273 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - ab6e4171-4681-4e2a-8fa0-08364f96b8bc item bought at 2018-12-14T19:33:06.270Z
2018-12-14 20:33:06,288 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - ab6e4171-4681-4e2a-8fa0-08364f96b8bc item marked as payment timeout at 2018-12-14T19:33:06.277Z
2018-12-14 20:33:06,306 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - beaf35e4-48e6-4952-9692-11156b948465 item bought at 2018-12-14T19:33:06.301Z
2018-12-14 20:33:06,316 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - beaf35e4-48e6-4952-9692-11156b948465 item paid at 2018-12-14T19:33:06.309Z
2018-12-14 20:33:06,332 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - 7f571566-27a9-48ef-a496-a1c7e8a062e3 item bought at 2018-12-14T19:33:06.328Z
2018-12-14 20:33:06,344 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - 7f571566-27a9-48ef-a496-a1c7e8a062e3 item marked as payment timeout at 2018-12-14T19:33:06.336Z
2018-12-14 20:33:06,355 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - 7f571566-27a9-48ef-a496-a1c7e8a062e3 item paid at 2018-12-14T19:33:06.348Z
2018-12-14 20:33:06,368 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - 09aafd05-5109-4eb6-92cd-c25038d8b81d item bought at 2018-12-14T19:33:06.365Z
2018-12-14 20:33:06,375 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - 09aafd05-5109-4eb6-92cd-c25038d8b81d item bought at 2018-12-14T19:33:06.371Z
2018-12-14 20:33:06,384 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - b6a4f44f-d745-4ce9-853f-3e7deb6b33cf item bought at 2018-12-14T19:33:06.381Z
2018-12-14 20:33:06,396 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - b6a4f44f-d745-4ce9-853f-3e7deb6b33cf item marked as payment timeout at 2018-12-14T19:33:06.388Z
2018-12-14 20:33:06,405 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - b6a4f44f-d745-4ce9-853f-3e7deb6b33cf item marked as payment timeout at 2018-12-14T19:33:06.400Z
2018-12-14 20:33:06,416 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - 62848b29-77e5-4a77-8614-634d53d0d39d item bought at 2018-12-14T19:33:06.412Z
2018-12-14 20:33:06,426 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - 62848b29-77e5-4a77-8614-634d53d0d39d item paid at 2018-12-14T19:33:06.419Z
2018-12-14 20:33:06,435 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - 62848b29-77e5-4a77-8614-634d53d0d39d item paid at 2018-12-14T19:33:06.429Z
2018-12-14 20:33:06,444 INFO Test worker  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 20:33:06,446 INFO Test worker  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 20:33:06,447 INFO Test worker  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@2360c0de, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@2924b28c, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@32414973, org.springframework.test.context.support.DirtiesContextTestExecutionListener@56d021fb, org.springframework.test.context.transaction.TransactionalTestExecutionListener@73937dcf, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@7faf11e3]
2018-12-14 20:33:06,451 INFO Test worker  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 20:33:06,453 INFO Test worker  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 20:33:06,454 INFO Test worker  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@4e44d40b, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@4f4146b2, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@30d76c42, org.springframework.test.context.support.DirtiesContextTestExecutionListener@9cf6935, org.springframework.test.context.transaction.TransactionalTestExecutionListener@6143108b, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@2472aec7]
2018-12-14 20:33:06,544 INFO Test worker  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 20:33:06,546 INFO Test worker  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 20:33:06,546 INFO Test worker  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@28531136, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@547a2fe1, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@cd31c76, org.springframework.test.context.support.DirtiesContextTestExecutionListener@64f02b42, org.springframework.test.context.transaction.TransactionalTestExecutionListener@541a4c4b, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@511a740e]
2018-12-14 20:33:06,565 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - db9b0e81-4f5c-42eb-9822-be4057a90781 item bought at 2018-12-14T19:33:06.561Z
2018-12-14 20:33:06,589 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - cce386cc-d3ac-425d-afce-1299257166cd item bought at 2018-12-14T19:33:06.584Z
2018-12-14 20:33:06,600 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - cce386cc-d3ac-425d-afce-1299257166cd item paid at 2018-12-14T19:33:06.594Z
2018-12-14 20:33:06,612 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - b658f505-668f-479e-b922-558445a4426d item bought at 2018-12-14T19:33:06.609Z
2018-12-14 20:33:06,621 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - b658f505-668f-479e-b922-558445a4426d item marked as payment timeout at 2018-12-14T19:33:06.615Z
2018-12-14 20:33:06,630 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - b658f505-668f-479e-b922-558445a4426d item paid at 2018-12-14T19:33:06.624Z
2018-12-14 20:33:06,643 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - 230febbb-22f8-45ac-8ba9-2515db280683 item bought at 2018-12-14T19:33:06.640Z
2018-12-14 20:33:06,651 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - 230febbb-22f8-45ac-8ba9-2515db280683 item bought at 2018-12-14T19:33:06.646Z
2018-12-14 20:33:06,659 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - a224eee1-6838-499f-aa8e-1d3f226a63a0 item bought at 2018-12-14T19:33:06.656Z
2018-12-14 20:33:06,669 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - a224eee1-6838-499f-aa8e-1d3f226a63a0 item marked as payment timeout at 2018-12-14T19:33:06.663Z
2018-12-14 20:33:06,677 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - a224eee1-6838-499f-aa8e-1d3f226a63a0 item marked as payment timeout at 2018-12-14T19:33:06.672Z
2018-12-14 20:33:06,687 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - 0db8e201-33f4-40d2-b51e-09c6f18215d7 item bought at 2018-12-14T19:33:06.682Z
2018-12-14 20:33:06,696 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - 0db8e201-33f4-40d2-b51e-09c6f18215d7 item paid at 2018-12-14T19:33:06.690Z
2018-12-14 20:33:06,704 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - 0db8e201-33f4-40d2-b51e-09c6f18215d7 item paid at 2018-12-14T19:33:06.699Z
2018-12-14 20:33:06,711 INFO Test worker  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 20:33:06,712 INFO Test worker  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 20:33:06,713 INFO Test worker  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@673ce530, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@998458c, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@2092f022, org.springframework.test.context.support.DirtiesContextTestExecutionListener@3f8ac43b, org.springframework.test.context.transaction.TransactionalTestExecutionListener@3f1fa39f, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@74e035d5]
2018-12-14 20:33:06,730 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - e5e6e6ed-91c6-49f5-a0a4-f912d05bbc92 item bought at 2018-12-13T18:33:06.726Z
2018-12-14 20:33:06,735 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - 88959311-2ad2-4838-83bc-38da790ec702 item bought at 2018-12-13T18:33:06.732Z
2018-12-14 20:33:06,740 INFO Test worker  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 2 items that payment did not arrive at 2018-12-14T19:33:06.739Z
2018-12-14 20:33:06,747 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - e5e6e6ed-91c6-49f5-a0a4-f912d05bbc92 item marked as payment timeout at 2018-12-14T19:33:06.739Z
2018-12-14 20:33:06,755 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - 88959311-2ad2-4838-83bc-38da790ec702 item marked as payment timeout at 2018-12-14T19:33:06.739Z
2018-12-14 20:33:06,775 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - 95b639d4-c02d-4647-80f4-2e22580f3d22 item bought at 2018-12-14T19:33:06.771Z
2018-12-14 20:33:06,777 INFO Test worker  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T19:33:06.777Z
2018-12-14 20:33:06,785 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - 906231bd-6c74-40d2-8210-6571b179efea item bought at 2018-12-14T19:33:06.780Z
2018-12-14 20:33:06,796 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - 906231bd-6c74-40d2-8210-6571b179efea item paid at 2018-12-14T19:33:06.788Z
2018-12-14 20:33:06,802 INFO Test worker  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T19:33:06.802Z
2018-12-14 20:33:06,809 INFO Test worker  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 20:33:06,812 INFO Test worker  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 20:33:06,813 INFO Test worker  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@2d5670c6, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@4b98219a, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@1c52e600, org.springframework.test.context.support.DirtiesContextTestExecutionListener@20a4e6f6, org.springframework.test.context.transaction.TransactionalTestExecutionListener@3e6a7264, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@34f410c2]
2018-12-14 20:33:06,839 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - a973bc55-c7ac-42ce-be3c-a09a3fec7660 item bought at 1995-10-23T10:12:35Z
2018-12-14 20:33:06,856 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - 95dccd3f-58a1-4471-8bc7-f48b79f52482 item bought at 1995-10-23T10:12:35Z
2018-12-14 20:33:06,865 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - 95dccd3f-58a1-4471-8bc7-f48b79f52482 item bought at 1995-10-23T10:14:15Z
2018-12-14 20:33:06,874 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - c3b2e370-cc47-4d0b-94bd-84562f273597 item bought at 1995-10-23T10:12:35Z
2018-12-14 20:33:06,885 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - c3b2e370-cc47-4d0b-94bd-84562f273597 item paid at 1995-10-23T10:14:15Z
2018-12-14 20:33:06,898 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - 125ab612-b192-4f26-a902-3afa822df28e item bought at 1995-10-23T10:12:35Z
2018-12-14 20:33:06,907 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - 125ab612-b192-4f26-a902-3afa822df28e item paid at 1995-10-23T10:14:15Z
2018-12-14 20:33:06,916 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - 125ab612-b192-4f26-a902-3afa822df28e item paid at 1995-10-23T10:15:55Z
2018-12-14 20:33:06,924 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - 09f6b94d-1e40-475a-846f-20b6b46ddc41 item bought at 1995-10-23T10:12:35Z
2018-12-14 20:33:06,935 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - 09f6b94d-1e40-475a-846f-20b6b46ddc41 item marked as payment timeout at 1995-10-23T10:14:15Z
2018-12-14 20:33:06,944 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - ab8c01d2-45fe-475c-b16d-0605303d6bc7 item bought at 1995-10-23T10:12:35Z
2018-12-14 20:33:06,950 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - ab8c01d2-45fe-475c-b16d-0605303d6bc7 item marked as payment timeout at 1995-10-23T10:14:15Z
2018-12-14 20:33:06,957 INFO Test worker  io.dddbyexamples.eventsource.boundary.ShopItems - ab8c01d2-45fe-475c-b16d-0605303d6bc7 item marked as payment timeout at 1995-10-23T10:15:55Z
2018-12-14 20:33:07,203 INFO Thread-5  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@6585a07f: startup date [Fri Dec 14 20:33:00 CET 2018]; root of context hierarchy
2018-12-14 20:33:07,213 INFO Thread-5  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 20:33:07,214 INFO Thread-5  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 20:33:07,222 INFO Thread-5  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 21:48:12,819 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 21:48:12,832 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 21:48:12,844 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@78d6692f, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7a55af6b, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3d9c13b5, org.springframework.test.context.support.DirtiesContextTestExecutionListener@492691d7, org.springframework.test.context.transaction.TransactionalTestExecutionListener@27216cd, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@558bdf1f]
2018-12-14 21:48:24,255 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 21:48:24,268 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 21:48:24,280 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@10a9d961, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@130e116b, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@e383572, org.springframework.test.context.support.DirtiesContextTestExecutionListener@5ddf0d24, org.springframework.test.context.transaction.TransactionalTestExecutionListener@363a52f, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@60856961]
2018-12-14 21:48:25,021 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 6896 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 21:48:25,021 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 21:48:25,082 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 21:48:25 CET 2018]; root of context hierarchy
2018-12-14 21:48:25,458 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 21:48:26,243 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$b9e5abbd] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 21:48:27,526 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 21:48:27,533 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 21:48:27,593 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 21:48:27,594 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 21:48:27,596 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 21:48:27,740 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 21:48:27,785 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 21:48:27,912 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 21:48:28,119 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 21:48:28,128 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 21:48:28,498 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 21:48:28,687 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 21:48:28,736 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 21:48:28,736 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 21:48:28,743 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 21:48:28,777 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 21:48:28,778 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 21:48:29,133 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 21:48:25 CET 2018]; root of context hierarchy
2018-12-14 21:48:29,193 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 21:48:29,194 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 21:48:29,216 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 21:48:29,216 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 21:48:29,243 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 21:48:29,481 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.099 seconds (JVM running for 6.462)
2018-12-14 21:48:29,483 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T20:48:29.476Z
2018-12-14 21:48:29,523 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 21:48:29,674 WARN kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.NetworkClient - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2018-12-14 21:48:29,781 WARN kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.NetworkClient - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2018-12-14 21:48:29,989 WARN kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.NetworkClient - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2018-12-14 21:48:30,196 WARN kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.NetworkClient - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2018-12-14 21:48:30,610 WARN kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.NetworkClient - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2018-12-14 21:48:31,441 WARN kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.NetworkClient - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2018-12-14 21:48:32,574 WARN kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.NetworkClient - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2018-12-14 21:48:33,502 WARN kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.NetworkClient - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2018-12-14 21:48:34,529 WARN kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.NetworkClient - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2018-12-14 21:48:35,764 WARN kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.NetworkClient - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2018-12-14 21:48:36,790 WARN kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.NetworkClient - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2018-12-14 21:48:38,020 WARN kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.NetworkClient - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2018-12-14 21:48:38,842 WARN kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.NetworkClient - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2018-12-14 21:48:39,867 WARN kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.NetworkClient - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2018-12-14 21:48:40,796 WARN kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.NetworkClient - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2018-12-14 21:48:41,923 WARN kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.NetworkClient - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2018-12-14 21:48:42,188 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 21:48:25 CET 2018]; root of context hierarchy
2018-12-14 21:48:42,192 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 21:48:42,192 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 21:48:42,196 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 21:52:37,253 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 21:52:37,265 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 21:52:37,277 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@10a9d961, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@130e116b, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@e383572, org.springframework.test.context.support.DirtiesContextTestExecutionListener@5ddf0d24, org.springframework.test.context.transaction.TransactionalTestExecutionListener@363a52f, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@60856961]
2018-12-14 21:52:38,028 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 7933 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 21:52:38,028 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 21:52:38,088 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 21:52:38 CET 2018]; root of context hierarchy
2018-12-14 21:52:38,461 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 21:52:39,187 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$b9e5abbd] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 21:52:40,464 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 21:52:40,473 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 21:52:40,531 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 21:52:40,533 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 21:52:40,534 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 21:52:40,701 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 21:52:40,748 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 21:52:40,871 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 21:52:41,090 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 21:52:41,101 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 21:52:41,478 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 21:52:41,651 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 21:52:41,699 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 21:52:41,699 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 21:52:41,707 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 21:52:41,749 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 21:52:41,749 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 21:52:42,115 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 21:52:38 CET 2018]; root of context hierarchy
2018-12-14 21:52:42,179 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 21:52:42,180 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 21:52:42,200 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 21:52:42,200 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 21:52:42,226 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 21:52:42,472 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.094 seconds (JVM running for 6.471)
2018-12-14 21:52:42,474 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T20:52:42.467Z
2018-12-14 21:52:42,512 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 21:52:43,594 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 0
2018-12-14 21:52:43,611 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 21:52:43,882 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 21:52:38 CET 2018]; root of context hierarchy
2018-12-14 21:52:43,888 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 21:52:43,889 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 21:52:43,894 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 21:54:09,145 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 21:54:09,161 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 21:54:09,174 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@10a9d961, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@130e116b, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@e383572, org.springframework.test.context.support.DirtiesContextTestExecutionListener@5ddf0d24, org.springframework.test.context.transaction.TransactionalTestExecutionListener@363a52f, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@60856961]
2018-12-14 21:54:09,955 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 7939 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 21:54:09,955 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 21:54:10,014 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 21:54:10 CET 2018]; root of context hierarchy
2018-12-14 21:54:10,397 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 21:54:11,102 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$b9e5abbd] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 21:54:12,399 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 21:54:12,407 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 21:54:12,471 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 21:54:12,473 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 21:54:12,474 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 21:54:12,626 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 21:54:12,669 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 21:54:12,771 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 21:54:12,973 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 21:54:12,981 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 21:54:13,323 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 21:54:13,492 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 21:54:13,541 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 21:54:13,541 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 21:54:13,547 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 21:54:13,589 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 21:54:13,589 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 21:54:13,938 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 21:54:10 CET 2018]; root of context hierarchy
2018-12-14 21:54:13,997 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 21:54:13,998 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 21:54:14,021 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 21:54:14,021 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 21:54:14,048 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 21:54:14,292 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.009 seconds (JVM running for 6.416)
2018-12-14 21:54:14,294 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T20:54:14.287Z
2018-12-14 21:54:14,334 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 21:54:14,598 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 1
2018-12-14 21:54:14,608 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 21:54:14,608 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 21:54:14,609 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Revoking previously assigned partitions []
2018-12-14 21:54:14,610 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] (Re-)joining group
2018-12-14 21:54:14,887 INFO main  io.dddbyexamples.eventsource.boundary.ShopItems - 57dcd1f2-9c13-4caa-b284-25df606e2797 item bought at 2018-12-14T20:54:14.317Z
2018-12-14 21:54:15,080 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 21:54:10 CET 2018]; root of context hierarchy
2018-12-14 21:54:15,084 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 21:54:15,084 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 21:54:15,089 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 21:56:14,587 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 21:56:14,603 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 21:56:14,619 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@255990cc, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@51c929ae, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3c8bdd5b, org.springframework.test.context.support.DirtiesContextTestExecutionListener@29d2d081, org.springframework.test.context.transaction.TransactionalTestExecutionListener@40e4ea87, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@58783f6c]
2018-12-14 21:56:15,427 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 9563 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 21:56:15,427 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 21:56:15,503 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@45cd7bc5: startup date [Fri Dec 14 21:56:15 CET 2018]; root of context hierarchy
2018-12-14 21:56:16,055 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 21:56:16,960 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$a2ec6dc9] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 21:56:18,484 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 21:56:18,493 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 21:56:18,576 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 21:56:18,578 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 21:56:18,580 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 21:56:18,778 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 21:56:18,849 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 21:56:19,016 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 21:56:19,230 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 21:56:19,238 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 21:56:19,876 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 21:56:19,902 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 21:56:19,969 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 21:56:19,969 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 21:56:19,975 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 21:56:20,011 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 21:56:20,011 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 21:56:20,433 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@45cd7bc5: startup date [Fri Dec 14 21:56:15 CET 2018]; root of context hierarchy
2018-12-14 21:56:20,498 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 21:56:20,499 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 21:56:20,524 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 21:56:20,524 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 21:56:20,559 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 21:56:20,917 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 6.153 seconds (JVM running for 8.052)
2018-12-14 21:56:20,921 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T20:56:20.911Z
2018-12-14 21:56:20,967 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 21:56:21,263 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 2
2018-12-14 21:56:21,278 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 21:56:21,279 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 21:56:21,280 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Revoking previously assigned partitions []
2018-12-14 21:56:21,281 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] (Re-)joining group
2018-12-14 21:56:21,295 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Successfully joined group with generation 3
2018-12-14 21:56:21,297 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Setting newly assigned partitions [shop-items-0]
2018-12-14 21:56:21,308 INFO main  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Resetting offset for partition shop-items-0 to offset 0.
2018-12-14 21:56:21,549 INFO main  io.dddbyexamples.eventsource.boundary.ShopItems - 83707e7e-1e78-4486-9966-e0fadb2c216a item bought at 2018-12-14T20:56:20.947Z
2018-12-14 21:56:21,814 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@45cd7bc5: startup date [Fri Dec 14 21:56:15 CET 2018]; root of context hierarchy
2018-12-14 21:56:21,819 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 21:56:21,819 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 21:56:21,826 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 21:56:29,402 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 21:56:29,418 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 21:56:29,438 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@255990cc, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@51c929ae, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3c8bdd5b, org.springframework.test.context.support.DirtiesContextTestExecutionListener@29d2d081, org.springframework.test.context.transaction.TransactionalTestExecutionListener@40e4ea87, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@58783f6c]
2018-12-14 21:56:30,265 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 9567 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 21:56:30,265 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 21:56:30,344 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@45cd7bc5: startup date [Fri Dec 14 21:56:30 CET 2018]; root of context hierarchy
2018-12-14 21:56:30,794 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 21:56:31,585 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$750edf61] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 21:56:33,158 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 21:56:33,170 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 21:56:33,265 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 21:56:33,267 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 21:56:33,269 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 21:56:33,469 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 21:56:33,516 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 21:56:33,626 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 21:56:33,850 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 21:56:33,857 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 21:56:34,418 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 21:56:34,436 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 21:56:34,483 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 21:56:34,483 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 21:56:34,490 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 21:56:34,521 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 21:56:34,521 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 21:56:34,899 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@45cd7bc5: startup date [Fri Dec 14 21:56:30 CET 2018]; root of context hierarchy
2018-12-14 21:56:34,966 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 21:56:34,967 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 21:56:34,994 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 21:56:34,995 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 21:56:35,028 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 21:56:35,368 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.791 seconds (JVM running for 7.64)
2018-12-14 21:56:35,371 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T20:56:35.361Z
2018-12-14 21:56:35,418 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 21:56:35,715 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 3
2018-12-14 21:56:35,730 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 21:56:35,731 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 21:56:35,733 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Revoking previously assigned partitions []
2018-12-14 21:56:35,733 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] (Re-)joining group
2018-12-14 21:56:35,747 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Successfully joined group with generation 5
2018-12-14 21:56:35,749 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Setting newly assigned partitions [shop-items-0]
2018-12-14 21:56:35,761 INFO main  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Resetting offset for partition shop-items-0 to offset 0.
2018-12-14 21:56:39,758 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@45cd7bc5: startup date [Fri Dec 14 21:56:30 CET 2018]; root of context hierarchy
2018-12-14 21:56:39,762 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 21:56:39,762 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 21:56:39,767 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 21:57:18,267 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 21:57:18,280 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 21:57:18,292 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@10a9d961, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@130e116b, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@e383572, org.springframework.test.context.support.DirtiesContextTestExecutionListener@5ddf0d24, org.springframework.test.context.transaction.TransactionalTestExecutionListener@363a52f, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@60856961]
2018-12-14 21:57:19,030 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 9837 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 21:57:19,030 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 21:57:19,087 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 21:57:19 CET 2018]; root of context hierarchy
2018-12-14 21:57:19,437 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 21:57:20,030 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$bfe26f5e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 21:57:21,212 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 21:57:21,220 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 21:57:21,279 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 21:57:21,280 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 21:57:21,281 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 21:57:21,432 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 21:57:21,488 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 21:57:21,641 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 21:57:21,845 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 21:57:21,853 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 21:57:22,171 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 21:57:22,336 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 21:57:22,376 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 21:57:22,377 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 21:57:22,383 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 21:57:22,411 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 21:57:22,411 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 21:57:22,729 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 21:57:19 CET 2018]; root of context hierarchy
2018-12-14 21:57:22,785 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 21:57:22,786 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 21:57:22,806 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 21:57:22,807 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 21:57:22,833 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 21:57:23,068 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 4.669 seconds (JVM running for 6.047)
2018-12-14 21:57:23,070 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T20:57:23.063Z
2018-12-14 21:57:23,109 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 21:57:23,484 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 5
2018-12-14 21:57:23,495 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 21:57:23,495 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 21:57:23,497 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Revoking previously assigned partitions []
2018-12-14 21:57:23,497 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] (Re-)joining group
2018-12-14 21:57:23,510 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Successfully joined group with generation 7
2018-12-14 21:57:23,512 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Setting newly assigned partitions [shop-items-0]
2018-12-14 21:57:23,522 INFO main  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Resetting offset for partition shop-items-0 to offset 0.
2018-12-14 21:57:23,767 INFO main  io.dddbyexamples.eventsource.boundary.ShopItems - b1b88f81-8faf-48ad-9086-7e302da2210c item bought at 2018-12-14T20:57:23.093Z
2018-12-14 21:57:23,940 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 21:57:19 CET 2018]; root of context hierarchy
2018-12-14 21:57:23,945 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 21:57:23,945 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 21:57:23,950 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 21:57:41,015 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 21:57:41,030 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 21:57:41,047 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@255990cc, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@51c929ae, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3c8bdd5b, org.springframework.test.context.support.DirtiesContextTestExecutionListener@29d2d081, org.springframework.test.context.transaction.TransactionalTestExecutionListener@40e4ea87, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@58783f6c]
2018-12-14 21:57:41,848 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 9840 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 21:57:41,849 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 21:57:41,921 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@45cd7bc5: startup date [Fri Dec 14 21:57:41 CET 2018]; root of context hierarchy
2018-12-14 21:57:42,348 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 21:57:43,168 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$eb52a1b5] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 21:57:44,677 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 21:57:44,688 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 21:57:44,781 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 21:57:44,784 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 21:57:44,785 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 21:57:45,017 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 21:57:45,080 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 21:57:45,212 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 21:57:45,442 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 21:57:45,449 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 21:57:46,010 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 21:57:46,029 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 21:57:46,075 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 21:57:46,075 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 21:57:46,081 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 21:57:46,112 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 21:57:46,112 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 21:57:46,495 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@45cd7bc5: startup date [Fri Dec 14 21:57:41 CET 2018]; root of context hierarchy
2018-12-14 21:57:46,567 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 21:57:46,568 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 21:57:46,594 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 21:57:46,594 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 21:57:46,626 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 21:57:46,974 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.785 seconds (JVM running for 7.582)
2018-12-14 21:57:46,977 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T20:57:46.968Z
2018-12-14 21:57:47,025 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 21:57:47,292 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 6
2018-12-14 21:57:47,307 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 21:57:47,308 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 21:57:47,309 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Revoking previously assigned partitions []
2018-12-14 21:57:47,310 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] (Re-)joining group
2018-12-14 21:57:47,321 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Successfully joined group with generation 9
2018-12-14 21:57:47,323 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Setting newly assigned partitions [shop-items-0]
2018-12-14 21:57:47,333 INFO main  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Resetting offset for partition shop-items-0 to offset 0.
2018-12-14 21:58:01,792 INFO kafka-coordinator-heartbeat-thread | some-group-id  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2018-12-14 21:58:01,835 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@45cd7bc5: startup date [Fri Dec 14 21:57:41 CET 2018]; root of context hierarchy
2018-12-14 21:58:01,839 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 21:58:01,839 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 21:58:01,844 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 21:58:06,748 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 21:58:06,763 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 21:58:06,782 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@255990cc, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@51c929ae, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3c8bdd5b, org.springframework.test.context.support.DirtiesContextTestExecutionListener@29d2d081, org.springframework.test.context.transaction.TransactionalTestExecutionListener@40e4ea87, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@58783f6c]
2018-12-14 21:58:07,601 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 9846 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 21:58:07,601 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 21:58:07,677 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@45cd7bc5: startup date [Fri Dec 14 21:58:07 CET 2018]; root of context hierarchy
2018-12-14 21:58:08,110 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 21:58:08,902 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$f0d09b20] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 21:58:10,448 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 21:58:10,461 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 21:58:10,553 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 21:58:10,556 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 21:58:10,558 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 21:58:10,787 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 21:58:10,843 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 21:58:10,968 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 21:58:11,233 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 21:58:11,242 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 21:58:11,840 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 21:58:11,857 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 21:58:11,901 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 21:58:11,901 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 21:58:11,906 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 21:58:11,937 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 21:58:11,938 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 21:58:12,323 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@45cd7bc5: startup date [Fri Dec 14 21:58:07 CET 2018]; root of context hierarchy
2018-12-14 21:58:12,391 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 21:58:12,392 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 21:58:12,420 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 21:58:12,420 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 21:58:12,452 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 21:58:12,805 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.876 seconds (JVM running for 7.668)
2018-12-14 21:58:12,808 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T20:58:12.798Z
2018-12-14 21:58:12,855 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 21:58:13,263 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 8
2018-12-14 21:58:13,277 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 21:58:13,277 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 21:58:13,279 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Revoking previously assigned partitions []
2018-12-14 21:58:13,279 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] (Re-)joining group
2018-12-14 21:58:13,291 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Successfully joined group with generation 11
2018-12-14 21:58:13,293 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Setting newly assigned partitions [shop-items-0]
2018-12-14 21:58:13,304 INFO main  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Resetting offset for partition shop-items-0 to offset 0.
2018-12-14 21:58:26,103 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@45cd7bc5: startup date [Fri Dec 14 21:58:07 CET 2018]; root of context hierarchy
2018-12-14 21:58:26,108 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 21:58:26,109 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 21:58:26,113 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 21:58:30,148 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 21:58:30,162 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 21:58:30,179 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@255990cc, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@51c929ae, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3c8bdd5b, org.springframework.test.context.support.DirtiesContextTestExecutionListener@29d2d081, org.springframework.test.context.transaction.TransactionalTestExecutionListener@40e4ea87, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@58783f6c]
2018-12-14 21:58:30,969 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 9850 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 21:58:30,969 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 21:58:31,045 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@45cd7bc5: startup date [Fri Dec 14 21:58:31 CET 2018]; root of context hierarchy
2018-12-14 21:58:31,498 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 21:58:32,298 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$f972d37f] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 21:58:33,889 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 21:58:33,902 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 21:58:33,996 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 21:58:33,999 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 21:58:34,001 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 21:58:34,218 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 21:58:34,302 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 21:58:34,417 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 21:58:34,653 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 21:58:34,660 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 21:58:35,242 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 21:58:35,262 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 21:58:35,316 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 21:58:35,316 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 21:58:35,322 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 21:58:35,355 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 21:58:35,355 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 21:58:35,745 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@45cd7bc5: startup date [Fri Dec 14 21:58:31 CET 2018]; root of context hierarchy
2018-12-14 21:58:35,814 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 21:58:35,815 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 21:58:35,840 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 21:58:35,840 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 21:58:35,871 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 21:58:36,209 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.901 seconds (JVM running for 7.679)
2018-12-14 21:58:36,213 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T20:58:36.201Z
2018-12-14 21:58:36,259 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 21:58:36,663 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 10
2018-12-14 21:58:36,678 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 21:58:36,678 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 21:58:36,680 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Revoking previously assigned partitions []
2018-12-14 21:58:36,681 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] (Re-)joining group
2018-12-14 21:58:36,694 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Successfully joined group with generation 13
2018-12-14 21:58:36,696 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Setting newly assigned partitions [shop-items-0]
2018-12-14 21:58:36,708 INFO main  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Resetting offset for partition shop-items-0 to offset 0.
2018-12-14 21:59:35,833 INFO kafka-coordinator-heartbeat-thread | some-group-id  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2018-12-14 21:59:39,049 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@45cd7bc5: startup date [Fri Dec 14 21:58:31 CET 2018]; root of context hierarchy
2018-12-14 21:59:39,053 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 21:59:39,054 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 21:59:39,059 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:00:09,265 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 22:00:09,277 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 22:00:09,288 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@10a9d961, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@130e116b, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@e383572, org.springframework.test.context.support.DirtiesContextTestExecutionListener@5ddf0d24, org.springframework.test.context.transaction.TransactionalTestExecutionListener@363a52f, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@60856961]
2018-12-14 22:00:09,930 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 9855 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 22:00:09,931 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 22:00:09,988 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 22:00:09 CET 2018]; root of context hierarchy
2018-12-14 22:00:10,346 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 22:00:11,047 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$b9e5abbd] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 22:00:12,326 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 22:00:12,333 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 22:00:12,383 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 22:00:12,384 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 22:00:12,385 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 22:00:12,507 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 22:00:12,546 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 22:00:12,644 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 22:00:12,834 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:00:12,842 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:00:13,190 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 22:00:13,356 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 22:00:13,397 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:00:13,398 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:00:13,403 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 22:00:13,433 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:00:13,433 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:00:13,746 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 22:00:09 CET 2018]; root of context hierarchy
2018-12-14 22:00:13,800 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 22:00:13,801 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 22:00:13,820 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:00:13,820 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:00:13,843 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:00:14,067 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 4.684 seconds (JVM running for 6.043)
2018-12-14 22:00:14,069 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T21:00:14.062Z
2018-12-14 22:00:14,107 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 22:00:14,469 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 12
2018-12-14 22:00:14,481 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:00:14,482 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 22:00:14,483 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Revoking previously assigned partitions []
2018-12-14 22:00:14,483 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] (Re-)joining group
2018-12-14 22:00:14,494 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Successfully joined group with generation 15
2018-12-14 22:00:14,496 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Setting newly assigned partitions [shop-items-0]
2018-12-14 22:00:14,506 INFO main  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Resetting offset for partition shop-items-0 to offset 0.
2018-12-14 22:00:14,541 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:00:14,819 INFO main  io.dddbyexamples.eventsource.boundary.ShopItems - 44d9ff06-f43e-4216-9346-80b92154ce5b item bought at 2018-12-14T21:00:14.091Z
2018-12-14 22:00:15,006 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 22:00:09 CET 2018]; root of context hierarchy
2018-12-14 22:00:15,012 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 22:00:15,012 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:00:15,017 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:00:58,562 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 22:00:58,575 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 22:00:58,587 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@10a9d961, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@130e116b, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@e383572, org.springframework.test.context.support.DirtiesContextTestExecutionListener@5ddf0d24, org.springframework.test.context.transaction.TransactionalTestExecutionListener@363a52f, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@60856961]
2018-12-14 22:00:59,317 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 9859 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 22:00:59,317 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 22:00:59,376 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 22:00:59 CET 2018]; root of context hierarchy
2018-12-14 22:00:59,755 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 22:01:00,494 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$b9e5abbd] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 22:01:01,794 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 22:01:01,802 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 22:01:01,876 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 22:01:01,877 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 22:01:01,878 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 22:01:02,017 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 22:01:02,058 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 22:01:02,171 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 22:01:02,373 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:01:02,382 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:01:02,741 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 22:01:02,906 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 22:01:02,949 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:01:02,949 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:01:02,954 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 22:01:02,984 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:01:02,984 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:01:03,315 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 22:00:59 CET 2018]; root of context hierarchy
2018-12-14 22:01:03,374 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 22:01:03,375 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 22:01:03,396 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:01:03,396 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:01:03,423 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:01:03,683 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 4.992 seconds (JVM running for 6.363)
2018-12-14 22:01:03,685 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T21:01:03.678Z
2018-12-14 22:01:03,724 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 22:01:03,997 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 13
2018-12-14 22:01:04,009 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:01:04,009 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 22:01:04,011 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Revoking previously assigned partitions []
2018-12-14 22:01:04,011 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] (Re-)joining group
2018-12-14 22:01:04,022 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Successfully joined group with generation 17
2018-12-14 22:01:04,024 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Setting newly assigned partitions [shop-items-0]
2018-12-14 22:01:04,032 INFO main  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Resetting offset for partition shop-items-0 to offset 0.
2018-12-14 22:01:04,097 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:01:04,348 INFO main  io.dddbyexamples.eventsource.boundary.ShopItems - 1a06b615-c918-4b4a-834f-7d8c9140a228 item bought at 2018-12-14T21:01:03.708Z
2018-12-14 22:01:04,405 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 22:00:59 CET 2018]; root of context hierarchy
2018-12-14 22:01:04,410 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 22:01:04,410 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:01:04,414 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:02:09,688 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 22:02:09,700 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 22:02:09,712 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@10a9d961, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@130e116b, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@e383572, org.springframework.test.context.support.DirtiesContextTestExecutionListener@5ddf0d24, org.springframework.test.context.transaction.TransactionalTestExecutionListener@363a52f, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@60856961]
2018-12-14 22:02:10,439 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 9864 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 22:02:10,439 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 22:02:10,504 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 22:02:10 CET 2018]; root of context hierarchy
2018-12-14 22:02:10,864 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 22:02:11,518 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$b9e5abbd] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 22:02:12,760 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 22:02:12,768 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 22:02:12,826 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 22:02:12,827 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 22:02:12,829 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 22:02:12,992 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 22:02:13,048 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 22:02:13,195 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 22:02:13,408 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:02:13,417 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:02:13,782 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 22:02:13,960 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 22:02:14,007 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:02:14,008 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:02:14,015 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 22:02:14,053 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:02:14,053 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:02:14,388 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 22:02:10 CET 2018]; root of context hierarchy
2018-12-14 22:02:14,447 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 22:02:14,448 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 22:02:14,471 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:02:14,471 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:02:14,499 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:02:14,749 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 4.93 seconds (JVM running for 6.364)
2018-12-14 22:02:14,751 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T21:02:14.744Z
2018-12-14 22:02:14,790 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 22:02:15,064 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 14
2018-12-14 22:02:15,074 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:02:15,074 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 22:02:15,076 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Revoking previously assigned partitions []
2018-12-14 22:02:15,076 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] (Re-)joining group
2018-12-14 22:02:15,085 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Successfully joined group with generation 19
2018-12-14 22:02:15,087 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Setting newly assigned partitions [shop-items-0]
2018-12-14 22:02:15,163 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:02:15,463 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 22:02:10 CET 2018]; root of context hierarchy
2018-12-14 22:02:15,468 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 22:02:15,468 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:02:15,474 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:02:31,662 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 22:02:31,676 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 22:02:31,688 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ae42ce3, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4f5991f6, org.springframework.test.context.support.DirtiesContextTestExecutionListener@484094a5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@38234a38, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@63fbfaeb]
2018-12-14 22:02:32,454 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 9867 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 22:02:32,454 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 22:02:32,512 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Fri Dec 14 22:02:32 CET 2018]; root of context hierarchy
2018-12-14 22:02:32,895 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 22:02:33,611 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$ecee938] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 22:02:34,894 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 22:02:34,904 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 22:02:34,960 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 22:02:34,961 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 22:02:34,962 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 22:02:35,109 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 22:02:35,154 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 22:02:35,279 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 22:02:35,483 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:02:35,493 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:02:35,863 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 22:02:36,041 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 22:02:36,089 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:02:36,089 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:02:36,095 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 22:02:36,127 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:02:36,127 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:02:36,453 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Fri Dec 14 22:02:32 CET 2018]; root of context hierarchy
2018-12-14 22:02:36,508 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 22:02:36,509 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 22:02:36,531 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:02:36,531 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:02:36,560 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:02:36,805 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.013 seconds (JVM running for 6.432)
2018-12-14 22:02:36,807 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T21:02:36.799Z
2018-12-14 22:02:36,847 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 22:02:37,121 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 15
2018-12-14 22:02:37,133 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:02:37,134 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 22:02:37,136 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Revoking previously assigned partitions []
2018-12-14 22:02:37,136 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] (Re-)joining group
2018-12-14 22:02:37,146 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Successfully joined group with generation 21
2018-12-14 22:02:37,148 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Setting newly assigned partitions [shop-items-0]
2018-12-14 22:02:37,216 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:02:37,485 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Fri Dec 14 22:02:32 CET 2018]; root of context hierarchy
2018-12-14 22:02:37,490 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 22:02:37,490 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:02:37,494 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:02:45,784 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 22:02:45,799 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 22:02:45,811 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ae42ce3, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4f5991f6, org.springframework.test.context.support.DirtiesContextTestExecutionListener@484094a5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@38234a38, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@63fbfaeb]
2018-12-14 22:02:46,600 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 9870 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 22:02:46,601 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 22:02:46,658 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Fri Dec 14 22:02:46 CET 2018]; root of context hierarchy
2018-12-14 22:02:47,051 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 22:02:47,774 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$ecee938] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 22:02:49,180 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 22:02:49,188 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 22:02:49,247 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 22:02:49,248 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 22:02:49,250 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 22:02:49,398 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 22:02:49,447 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 22:02:49,572 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 22:02:49,790 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:02:49,800 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:02:50,166 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 22:02:50,334 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 22:02:50,376 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:02:50,376 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:02:50,382 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 22:02:50,411 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:02:50,412 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:02:50,748 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Fri Dec 14 22:02:46 CET 2018]; root of context hierarchy
2018-12-14 22:02:50,805 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 22:02:50,806 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 22:02:50,828 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:02:50,829 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:02:50,859 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:02:51,110 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.189 seconds (JVM running for 6.645)
2018-12-14 22:02:51,112 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T21:02:51.106Z
2018-12-14 22:02:51,151 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 22:02:51,420 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 16
2018-12-14 22:02:51,433 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:02:51,433 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 22:02:51,435 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Revoking previously assigned partitions []
2018-12-14 22:02:51,435 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] (Re-)joining group
2018-12-14 22:02:51,445 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Successfully joined group with generation 23
2018-12-14 22:02:51,447 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Setting newly assigned partitions [shop-items-0]
2018-12-14 22:02:51,520 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:02:51,773 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Fri Dec 14 22:02:46 CET 2018]; root of context hierarchy
2018-12-14 22:02:51,777 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 22:02:51,778 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:02:51,781 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:03:28,827 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 22:03:28,842 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 22:03:28,855 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ae42ce3, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4f5991f6, org.springframework.test.context.support.DirtiesContextTestExecutionListener@484094a5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@38234a38, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@63fbfaeb]
2018-12-14 22:03:29,646 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 9873 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 22:03:29,647 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 22:03:29,705 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Fri Dec 14 22:03:29 CET 2018]; root of context hierarchy
2018-12-14 22:03:30,077 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 22:03:30,773 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$ecee938] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 22:03:32,034 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 22:03:32,041 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 22:03:32,109 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 22:03:32,111 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 22:03:32,112 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 22:03:32,257 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 22:03:32,298 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 22:03:32,406 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 22:03:32,615 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:03:32,623 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:03:32,980 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 22:03:33,155 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 22:03:33,201 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:03:33,201 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:03:33,207 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 22:03:33,239 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:03:33,239 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:03:33,571 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Fri Dec 14 22:03:29 CET 2018]; root of context hierarchy
2018-12-14 22:03:33,628 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 22:03:33,629 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 22:03:33,649 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:03:33,649 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:03:33,675 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:03:33,919 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 4.958 seconds (JVM running for 6.38)
2018-12-14 22:03:33,921 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T21:03:33.915Z
2018-12-14 22:03:33,959 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 22:03:34,218 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 17
2018-12-14 22:03:34,231 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:03:34,231 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 22:03:34,233 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Revoking previously assigned partitions []
2018-12-14 22:03:34,233 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] (Re-)joining group
2018-12-14 22:03:34,242 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Successfully joined group with generation 25
2018-12-14 22:03:34,244 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Setting newly assigned partitions [shop-items-0]
2018-12-14 22:03:34,315 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:03:34,583 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Fri Dec 14 22:03:29 CET 2018]; root of context hierarchy
2018-12-14 22:03:34,589 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 22:03:34,590 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:03:34,595 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:06:37,644 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 22:06:37,657 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 22:06:37,671 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ae42ce3, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4f5991f6, org.springframework.test.context.support.DirtiesContextTestExecutionListener@484094a5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@38234a38, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@63fbfaeb]
2018-12-14 22:06:38,440 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 9879 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 22:06:38,440 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 22:06:38,499 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Fri Dec 14 22:06:38 CET 2018]; root of context hierarchy
2018-12-14 22:06:38,872 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 22:06:39,612 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$ecee938] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 22:06:40,889 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 22:06:40,897 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 22:06:40,957 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 22:06:40,958 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 22:06:40,959 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 22:06:41,111 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 22:06:41,149 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 22:06:41,238 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 22:06:41,447 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:06:41,457 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:06:41,809 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 22:06:41,975 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 22:06:42,024 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:06:42,024 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:06:42,030 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 22:06:42,062 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:06:42,062 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:06:42,401 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Fri Dec 14 22:06:38 CET 2018]; root of context hierarchy
2018-12-14 22:06:42,455 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 22:06:42,456 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 22:06:42,476 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:06:42,476 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:06:42,503 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:06:42,744 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 4.962 seconds (JVM running for 6.364)
2018-12-14 22:06:42,746 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T21:06:42.739Z
2018-12-14 22:06:42,787 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 22:06:43,051 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 18
2018-12-14 22:06:43,063 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:06:43,063 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 22:06:43,065 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Revoking previously assigned partitions []
2018-12-14 22:06:43,065 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] (Re-)joining group
2018-12-14 22:06:43,076 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Successfully joined group with generation 27
2018-12-14 22:06:43,078 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Setting newly assigned partitions [shop-items-0]
2018-12-14 22:06:43,158 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:06:43,415 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Fri Dec 14 22:06:38 CET 2018]; root of context hierarchy
2018-12-14 22:06:43,418 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 22:06:43,419 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:06:43,423 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:06:53,255 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 22:06:53,268 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 22:06:53,281 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@10a9d961, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@130e116b, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@e383572, org.springframework.test.context.support.DirtiesContextTestExecutionListener@5ddf0d24, org.springframework.test.context.transaction.TransactionalTestExecutionListener@363a52f, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@60856961]
2018-12-14 22:06:54,058 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 9882 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 22:06:54,058 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 22:06:54,118 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 22:06:54 CET 2018]; root of context hierarchy
2018-12-14 22:06:54,502 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 22:06:55,219 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$b9e5abbd] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 22:06:56,589 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 22:06:56,597 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 22:06:56,657 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 22:06:56,659 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 22:06:56,661 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 22:06:56,812 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 22:06:56,862 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 22:06:56,980 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 22:06:57,218 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:06:57,227 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:06:57,594 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 22:06:57,764 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 22:06:57,814 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:06:57,814 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:06:57,820 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 22:06:57,853 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:06:57,853 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:06:58,197 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 22:06:54 CET 2018]; root of context hierarchy
2018-12-14 22:06:58,252 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 22:06:58,253 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 22:06:58,272 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:06:58,273 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:06:58,300 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:06:58,543 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.151 seconds (JVM running for 6.526)
2018-12-14 22:06:58,545 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T21:06:58.537Z
2018-12-14 22:06:58,585 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 22:06:58,847 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 19
2018-12-14 22:06:58,860 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:06:58,860 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 22:06:58,862 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Revoking previously assigned partitions []
2018-12-14 22:06:58,862 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] (Re-)joining group
2018-12-14 22:06:58,872 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Successfully joined group with generation 29
2018-12-14 22:06:58,874 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Setting newly assigned partitions [shop-items-0]
2018-12-14 22:06:58,952 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:06:59,244 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 22:06:54 CET 2018]; root of context hierarchy
2018-12-14 22:06:59,249 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 22:06:59,249 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:06:59,254 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:07:24,288 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 22:07:24,301 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 22:07:24,315 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@10a9d961, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@130e116b, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@e383572, org.springframework.test.context.support.DirtiesContextTestExecutionListener@5ddf0d24, org.springframework.test.context.transaction.TransactionalTestExecutionListener@363a52f, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@60856961]
2018-12-14 22:07:25,092 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 9888 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 22:07:25,093 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 22:07:25,152 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 22:07:25 CET 2018]; root of context hierarchy
2018-12-14 22:07:25,536 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 22:07:26,276 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$b9e5abbd] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 22:07:27,566 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 22:07:27,574 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 22:07:27,656 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 22:07:27,657 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 22:07:27,659 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 22:07:27,812 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 22:07:27,861 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 22:07:27,988 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 22:07:28,225 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:07:28,235 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:07:28,601 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 22:07:28,779 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 22:07:28,820 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:07:28,820 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:07:28,825 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 22:07:28,853 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:07:28,853 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:07:29,186 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 22:07:25 CET 2018]; root of context hierarchy
2018-12-14 22:07:29,242 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 22:07:29,243 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 22:07:29,265 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:07:29,266 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:07:29,294 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:07:29,544 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.116 seconds (JVM running for 6.778)
2018-12-14 22:07:29,547 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T21:07:29.539Z
2018-12-14 22:07:29,587 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 22:07:29,839 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 20
2018-12-14 22:07:29,851 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:07:29,852 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 22:07:29,853 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Revoking previously assigned partitions []
2018-12-14 22:07:29,854 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] (Re-)joining group
2018-12-14 22:07:29,864 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Successfully joined group with generation 31
2018-12-14 22:07:29,866 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Setting newly assigned partitions [shop-items-0]
2018-12-14 22:07:29,935 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:07:30,221 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 22:07:25 CET 2018]; root of context hierarchy
2018-12-14 22:07:30,225 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 22:07:30,225 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:07:30,229 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:08:38,759 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 22:08:38,771 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 22:08:38,784 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@10a9d961, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@130e116b, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@e383572, org.springframework.test.context.support.DirtiesContextTestExecutionListener@5ddf0d24, org.springframework.test.context.transaction.TransactionalTestExecutionListener@363a52f, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@60856961]
2018-12-14 22:08:39,515 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 9892 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 22:08:39,515 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 22:08:39,571 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 22:08:39 CET 2018]; root of context hierarchy
2018-12-14 22:08:39,955 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 22:08:40,619 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$b9e5abbd] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 22:08:41,911 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 22:08:41,918 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 22:08:41,974 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 22:08:41,975 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 22:08:41,976 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 22:08:42,127 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 22:08:42,174 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 22:08:42,292 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 22:08:42,477 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:08:42,484 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:08:42,801 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 22:08:42,973 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 22:08:43,023 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:08:43,023 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:08:43,025 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 22:08:43,316 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 21
2018-12-14 22:08:43,321 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 22:08:43,354 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:08:43,354 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:08:43,697 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 22:08:39 CET 2018]; root of context hierarchy
2018-12-14 22:08:43,757 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 22:08:43,758 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 22:08:43,779 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:08:43,779 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:08:43,806 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:08:44,052 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.166 seconds (JVM running for 6.657)
2018-12-14 22:08:44,054 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T21:08:44.047Z
2018-12-14 22:08:44,103 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:08:44,104 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 22:08:44,105 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Revoking previously assigned partitions []
2018-12-14 22:08:44,106 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] (Re-)joining group
2018-12-14 22:08:44,116 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Successfully joined group with generation 33
2018-12-14 22:08:44,118 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Setting newly assigned partitions [shop-items-0]
2018-12-14 22:08:44,196 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:08:44,524 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 22:08:39 CET 2018]; root of context hierarchy
2018-12-14 22:08:44,531 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 22:08:44,531 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:08:44,536 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:09:21,417 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 22:09:21,430 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 22:09:21,442 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@528c868, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@466276d8, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@5ce8d869, org.springframework.test.context.support.DirtiesContextTestExecutionListener@27eedb64, org.springframework.test.context.transaction.TransactionalTestExecutionListener@64c63c79, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@31c7528f]
2018-12-14 22:09:22,212 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 9895 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 22:09:22,213 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 22:09:22,271 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@60e21209: startup date [Fri Dec 14 22:09:22 CET 2018]; root of context hierarchy
2018-12-14 22:09:22,656 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 22:09:23,339 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$9d630ee7] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 22:09:24,594 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 22:09:24,601 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 22:09:24,657 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 22:09:24,658 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 22:09:24,660 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 22:09:24,803 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 22:09:24,849 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 22:09:24,966 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 22:09:25,201 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:09:25,210 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:09:25,738 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 22:09:25,754 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 22:09:25,799 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:09:25,800 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:09:25,802 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 22:09:26,166 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 22
2018-12-14 22:09:26,172 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 22:09:26,200 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:09:26,200 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:09:26,522 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@60e21209: startup date [Fri Dec 14 22:09:22 CET 2018]; root of context hierarchy
2018-12-14 22:09:26,578 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 22:09:26,579 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 22:09:26,601 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:09:26,601 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:09:26,627 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:09:26,877 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.324 seconds (JVM running for 6.811)
2018-12-14 22:09:26,879 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T21:09:26.872Z
2018-12-14 22:09:26,930 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:09:26,931 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 22:09:26,933 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Revoking previously assigned partitions []
2018-12-14 22:09:26,933 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] (Re-)joining group
2018-12-14 22:09:26,945 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Successfully joined group with generation 35
2018-12-14 22:09:26,947 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Setting newly assigned partitions [shop-items-0]
2018-12-14 22:09:27,026 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:09:27,341 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@60e21209: startup date [Fri Dec 14 22:09:22 CET 2018]; root of context hierarchy
2018-12-14 22:09:27,346 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 22:09:27,346 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:09:27,350 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:09:41,417 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 22:09:41,431 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 22:09:41,444 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ae42ce3, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4f5991f6, org.springframework.test.context.support.DirtiesContextTestExecutionListener@484094a5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@38234a38, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@63fbfaeb]
2018-12-14 22:09:42,216 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 9898 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 22:09:42,216 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 22:09:42,275 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Fri Dec 14 22:09:42 CET 2018]; root of context hierarchy
2018-12-14 22:09:42,646 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 22:09:43,358 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$ecee938] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 22:09:44,647 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 22:09:44,655 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 22:09:44,715 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 22:09:44,717 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 22:09:44,718 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 22:09:44,870 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 22:09:44,915 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 22:09:45,021 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 22:09:45,210 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:09:45,218 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:09:45,571 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 22:09:45,740 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 22:09:45,786 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:09:45,786 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:09:45,788 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 22:09:46,064 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 23
2018-12-14 22:09:46,069 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 22:09:46,100 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:09:46,100 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:09:46,438 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Fri Dec 14 22:09:42 CET 2018]; root of context hierarchy
2018-12-14 22:09:46,496 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 22:09:46,497 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 22:09:46,518 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:09:46,518 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:09:46,545 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:09:46,793 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.24 seconds (JVM running for 6.68)
2018-12-14 22:09:46,795 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T21:09:46.788Z
2018-12-14 22:09:46,843 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:09:46,844 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 22:09:46,845 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Revoking previously assigned partitions []
2018-12-14 22:09:46,846 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] (Re-)joining group
2018-12-14 22:09:46,857 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Successfully joined group with generation 37
2018-12-14 22:09:46,860 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Setting newly assigned partitions [shop-items-0]
2018-12-14 22:09:46,942 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:09:47,208 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Fri Dec 14 22:09:42 CET 2018]; root of context hierarchy
2018-12-14 22:09:47,212 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 22:09:47,212 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:09:47,216 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:10:28,494 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 22:10:28,506 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 22:10:28,519 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@10a9d961, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@130e116b, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@e383572, org.springframework.test.context.support.DirtiesContextTestExecutionListener@5ddf0d24, org.springframework.test.context.transaction.TransactionalTestExecutionListener@363a52f, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@60856961]
2018-12-14 22:10:29,276 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 9905 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 22:10:29,276 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 22:10:29,334 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@1dbb650b: startup date [Fri Dec 14 22:10:29 CET 2018]; root of context hierarchy
2018-12-14 22:10:29,694 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 22:10:30,335 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$49c9f8c3] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 22:10:31,559 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 22:10:31,567 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 22:10:31,628 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 22:10:31,630 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 22:10:31,631 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 22:10:31,798 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 22:10:31,852 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 22:10:31,987 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 22:10:32,210 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:10:32,218 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:10:32,564 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 22:10:32,736 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 22:10:32,784 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:10:32,784 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:10:32,787 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 22:10:33,066 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 24
2018-12-14 22:10:33,071 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 22:10:33,096 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:10:33,097 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:10:33,401 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@1dbb650b: startup date [Fri Dec 14 22:10:29 CET 2018]; root of context hierarchy
2018-12-14 22:10:33,453 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 22:10:33,454 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 22:10:33,472 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:10:33,472 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:10:33,498 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:10:33,741 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.128 seconds (JVM running for 6.57)
2018-12-14 22:10:33,743 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T21:10:33.736Z
2018-12-14 22:10:33,795 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:10:33,796 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 22:10:33,797 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Revoking previously assigned partitions []
2018-12-14 22:10:33,798 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] (Re-)joining group
2018-12-14 22:10:33,808 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Successfully joined group with generation 39
2018-12-14 22:10:33,810 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Setting newly assigned partitions [shop-items-0]
2018-12-14 22:10:33,906 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:10:34,247 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@1dbb650b: startup date [Fri Dec 14 22:10:29 CET 2018]; root of context hierarchy
2018-12-14 22:10:34,253 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 22:10:34,253 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:10:34,260 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:10:50,136 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 22:10:50,150 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 22:10:50,163 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@10a9d961, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@130e116b, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@e383572, org.springframework.test.context.support.DirtiesContextTestExecutionListener@5ddf0d24, org.springframework.test.context.transaction.TransactionalTestExecutionListener@363a52f, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@60856961]
2018-12-14 22:10:50,919 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 9909 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 22:10:50,919 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 22:10:50,986 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 22:10:50 CET 2018]; root of context hierarchy
2018-12-14 22:10:51,369 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 22:10:52,045 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$b9e5abbd] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 22:10:53,356 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 22:10:53,363 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 22:10:53,419 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 22:10:53,420 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 22:10:53,421 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 22:10:53,567 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 22:10:53,613 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 22:10:53,738 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 22:10:53,954 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:10:53,964 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:10:54,330 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 22:10:54,505 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 22:10:54,544 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:10:54,544 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:10:54,547 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 22:10:54,832 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 25
2018-12-14 22:10:54,838 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 22:10:54,868 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:10:54,868 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:10:55,201 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 22:10:50 CET 2018]; root of context hierarchy
2018-12-14 22:10:55,256 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 22:10:55,257 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 22:10:55,278 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:10:55,278 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:10:55,307 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:10:55,550 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.281 seconds (JVM running for 6.739)
2018-12-14 22:10:55,553 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T21:10:55.546Z
2018-12-14 22:10:55,598 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:10:55,598 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 22:10:55,600 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Revoking previously assigned partitions []
2018-12-14 22:10:55,601 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] (Re-)joining group
2018-12-14 22:10:55,614 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Successfully joined group with generation 41
2018-12-14 22:10:55,616 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Setting newly assigned partitions [shop-items-0]
2018-12-14 22:10:55,699 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:10:56,027 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 22:10:50 CET 2018]; root of context hierarchy
2018-12-14 22:10:56,031 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 22:10:56,031 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:10:56,035 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:13:01,897 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 22:13:01,912 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 22:13:01,924 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ae42ce3, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4f5991f6, org.springframework.test.context.support.DirtiesContextTestExecutionListener@484094a5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@38234a38, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@63fbfaeb]
2018-12-14 22:13:02,665 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 9918 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 22:13:02,666 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 22:13:02,724 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Fri Dec 14 22:13:02 CET 2018]; root of context hierarchy
2018-12-14 22:13:03,100 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 22:13:03,797 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$ecee938] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 22:13:05,060 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 22:13:05,068 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 22:13:05,130 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 22:13:05,131 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 22:13:05,133 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 22:13:05,279 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 22:13:05,321 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 22:13:05,425 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 22:13:05,638 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:13:05,646 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:13:05,998 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 22:13:06,171 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 22:13:06,218 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:13:06,218 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:13:06,221 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 22:13:06,503 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 26
2018-12-14 22:13:06,508 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 22:13:06,534 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:13:06,534 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:13:06,863 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Fri Dec 14 22:13:02 CET 2018]; root of context hierarchy
2018-12-14 22:13:06,920 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 22:13:06,921 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 22:13:06,942 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:13:06,942 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:13:06,970 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:13:07,206 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.177 seconds (JVM running for 6.633)
2018-12-14 22:13:07,208 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T21:13:07.201Z
2018-12-14 22:13:07,258 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:13:07,259 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 22:13:07,260 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Revoking previously assigned partitions []
2018-12-14 22:13:07,261 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] (Re-)joining group
2018-12-14 22:13:07,272 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Successfully joined group with generation 43
2018-12-14 22:13:07,274 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Setting newly assigned partitions [shop-items-0]
2018-12-14 22:13:07,356 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:13:07,628 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Fri Dec 14 22:13:02 CET 2018]; root of context hierarchy
2018-12-14 22:13:07,633 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 22:13:07,633 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:13:07,637 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:13:13,704 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 22:13:13,718 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 22:13:13,732 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ae42ce3, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4f5991f6, org.springframework.test.context.support.DirtiesContextTestExecutionListener@484094a5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@38234a38, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@63fbfaeb]
2018-12-14 22:13:14,505 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 9921 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 22:13:14,505 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 22:13:14,561 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Fri Dec 14 22:13:14 CET 2018]; root of context hierarchy
2018-12-14 22:13:14,936 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 22:13:15,669 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$ecee938] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 22:13:17,037 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 22:13:17,045 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 22:13:17,103 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 22:13:17,104 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 22:13:17,105 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 22:13:17,253 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 22:13:17,299 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 22:13:17,414 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 22:13:17,634 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:13:17,643 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:13:18,011 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 22:13:18,183 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 22:13:18,223 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:13:18,223 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:13:18,225 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 22:13:18,490 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 27
2018-12-14 22:13:18,496 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 22:13:18,524 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:13:18,524 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:13:18,846 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Fri Dec 14 22:13:14 CET 2018]; root of context hierarchy
2018-12-14 22:13:18,901 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 22:13:18,902 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 22:13:18,921 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:13:18,921 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:13:18,948 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:13:19,205 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.369 seconds (JVM running for 6.758)
2018-12-14 22:13:19,207 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T21:13:19.201Z
2018-12-14 22:13:19,261 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:13:19,261 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 22:13:19,263 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Revoking previously assigned partitions []
2018-12-14 22:13:19,264 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] (Re-)joining group
2018-12-14 22:13:19,275 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Successfully joined group with generation 45
2018-12-14 22:13:19,277 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Setting newly assigned partitions [shop-items-0]
2018-12-14 22:13:19,357 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:13:19,631 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Fri Dec 14 22:13:14 CET 2018]; root of context hierarchy
2018-12-14 22:13:19,634 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 22:13:19,634 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:13:19,638 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:13:25,080 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 22:13:25,094 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 22:13:25,107 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ae42ce3, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4f5991f6, org.springframework.test.context.support.DirtiesContextTestExecutionListener@484094a5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@38234a38, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@63fbfaeb]
2018-12-14 22:13:25,859 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 9924 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 22:13:25,860 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 22:13:25,919 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Fri Dec 14 22:13:25 CET 2018]; root of context hierarchy
2018-12-14 22:13:26,291 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 22:13:27,011 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$ecee938] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 22:13:28,304 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 22:13:28,311 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 22:13:28,369 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 22:13:28,371 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 22:13:28,372 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 22:13:28,517 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 22:13:28,564 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 22:13:28,686 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 22:13:28,903 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:13:28,912 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:13:29,258 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 22:13:29,435 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 22:13:29,482 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:13:29,482 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:13:29,484 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 22:13:29,775 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 28
2018-12-14 22:13:29,779 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 22:13:29,805 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:13:29,805 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:13:30,137 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Fri Dec 14 22:13:25 CET 2018]; root of context hierarchy
2018-12-14 22:13:30,194 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 22:13:30,195 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 22:13:30,216 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:13:30,216 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:13:30,247 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:13:30,501 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.283 seconds (JVM running for 6.806)
2018-12-14 22:13:30,503 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T21:13:30.496Z
2018-12-14 22:13:30,555 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:13:30,556 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 22:13:30,557 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Revoking previously assigned partitions []
2018-12-14 22:13:30,557 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] (Re-)joining group
2018-12-14 22:13:30,569 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Successfully joined group with generation 47
2018-12-14 22:13:30,572 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Setting newly assigned partitions [shop-items-0]
2018-12-14 22:13:30,657 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Fri Dec 14 22:13:25 CET 2018]; root of context hierarchy
2018-12-14 22:13:30,661 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 22:13:30,661 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:13:30,665 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:14:50,604 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 22:14:50,619 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 22:14:50,636 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@255990cc, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@51c929ae, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3c8bdd5b, org.springframework.test.context.support.DirtiesContextTestExecutionListener@29d2d081, org.springframework.test.context.transaction.TransactionalTestExecutionListener@40e4ea87, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@58783f6c]
2018-12-14 22:14:51,478 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 9928 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 22:14:51,478 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 22:14:51,549 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@45cd7bc5: startup date [Fri Dec 14 22:14:51 CET 2018]; root of context hierarchy
2018-12-14 22:14:51,985 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 22:14:52,770 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$c8104c46] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 22:14:54,285 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 22:14:54,297 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 22:14:54,390 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 22:14:54,392 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 22:14:54,394 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 22:14:54,601 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 22:14:54,691 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 22:14:54,818 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 22:14:55,043 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:14:55,052 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:14:55,632 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 22:14:55,650 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 22:14:55,700 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:14:55,700 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:14:55,703 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 22:14:55,988 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 29
2018-12-14 22:14:55,994 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 22:14:56,026 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:14:56,026 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:14:56,398 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@45cd7bc5: startup date [Fri Dec 14 22:14:51 CET 2018]; root of context hierarchy
2018-12-14 22:14:56,464 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 22:14:56,465 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 22:14:56,492 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:14:56,492 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:14:56,525 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:14:56,870 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 6.084 seconds (JVM running for 7.968)
2018-12-14 22:14:56,873 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T21:14:56.864Z
2018-12-14 22:14:56,931 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:14:56,932 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 22:14:56,934 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Revoking previously assigned partitions []
2018-12-14 22:14:56,934 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] (Re-)joining group
2018-12-14 22:14:56,946 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Successfully joined group with generation 49
2018-12-14 22:14:56,949 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Setting newly assigned partitions [shop-items-0]
2018-12-14 22:15:12,156 INFO kafka-coordinator-heartbeat-thread | some-group-id  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2018-12-14 22:15:22,261 INFO kafka-coordinator-heartbeat-thread | some-group-id  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 22:15:24,588 INFO kafka-coordinator-heartbeat-thread | some-group-id  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Attempt to heartbeat failed for since member id order-details-service-consumer-64c6e00d-9926-4307-91d3-5db1cf4de5bf is not valid.
2018-12-14 22:15:41,792 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:15:41,838 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@45cd7bc5: startup date [Fri Dec 14 22:14:51 CET 2018]; root of context hierarchy
2018-12-14 22:15:41,844 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 22:15:41,844 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:15:41,849 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:16:03,076 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 22:16:03,091 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 22:16:03,105 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@10a9d961, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@130e116b, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@e383572, org.springframework.test.context.support.DirtiesContextTestExecutionListener@5ddf0d24, org.springframework.test.context.transaction.TransactionalTestExecutionListener@363a52f, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@60856961]
2018-12-14 22:16:03,878 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 9933 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 22:16:03,879 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 22:16:03,935 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 22:16:03 CET 2018]; root of context hierarchy
2018-12-14 22:16:04,318 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 22:16:05,028 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$bfe26f5e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 22:16:06,332 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 22:16:06,339 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 22:16:06,389 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 22:16:06,390 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 22:16:06,391 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 22:16:06,537 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 22:16:06,584 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 22:16:06,701 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 22:16:06,895 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:16:06,903 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:16:07,250 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 22:16:07,416 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 22:16:07,469 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:16:07,469 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:16:07,471 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 22:16:07,863 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 31
2018-12-14 22:16:07,867 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 22:16:07,895 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:16:07,896 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:16:08,223 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 22:16:03 CET 2018]; root of context hierarchy
2018-12-14 22:16:08,282 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 22:16:08,283 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 22:16:08,304 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:16:08,304 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:16:08,333 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:16:08,577 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.362 seconds (JVM running for 6.815)
2018-12-14 22:16:08,579 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T21:16:08.572Z
2018-12-14 22:16:08,628 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:16:08,628 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 22:16:08,630 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Revoking previously assigned partitions []
2018-12-14 22:16:08,630 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] (Re-)joining group
2018-12-14 22:16:08,641 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Successfully joined group with generation 51
2018-12-14 22:16:08,643 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Setting newly assigned partitions [shop-items-0]
2018-12-14 22:16:08,720 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:16:09,028 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 22:16:03 CET 2018]; root of context hierarchy
2018-12-14 22:16:09,033 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 22:16:09,033 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:16:09,038 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:16:18,359 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 22:16:18,376 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 22:16:18,395 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@255990cc, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@51c929ae, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3c8bdd5b, org.springframework.test.context.support.DirtiesContextTestExecutionListener@29d2d081, org.springframework.test.context.transaction.TransactionalTestExecutionListener@40e4ea87, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@58783f6c]
2018-12-14 22:16:19,228 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 9936 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 22:16:19,228 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 22:16:19,304 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@45cd7bc5: startup date [Fri Dec 14 22:16:19 CET 2018]; root of context hierarchy
2018-12-14 22:16:19,753 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 22:16:20,567 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$f0d09b20] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 22:16:22,133 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 22:16:22,145 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 22:16:22,235 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 22:16:22,237 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 22:16:22,239 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 22:16:22,460 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 22:16:22,518 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 22:16:22,658 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 22:16:22,932 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:16:22,942 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:16:23,507 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 22:16:23,524 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 22:16:23,569 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:16:23,569 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:16:23,571 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 22:16:23,829 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 32
2018-12-14 22:16:23,835 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 22:16:23,867 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:16:23,867 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:16:24,244 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@45cd7bc5: startup date [Fri Dec 14 22:16:19 CET 2018]; root of context hierarchy
2018-12-14 22:16:24,311 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 22:16:24,312 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 22:16:24,339 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:16:24,340 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:16:24,376 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:16:24,768 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 6.218 seconds (JVM running for 8.086)
2018-12-14 22:16:24,772 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T21:16:24.761Z
2018-12-14 22:16:24,832 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:16:24,832 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 22:16:24,835 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Revoking previously assigned partitions []
2018-12-14 22:16:24,835 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] (Re-)joining group
2018-12-14 22:16:24,847 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Successfully joined group with generation 53
2018-12-14 22:16:24,849 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Setting newly assigned partitions [shop-items-0]
2018-12-14 22:16:52,974 INFO kafka-coordinator-heartbeat-thread | some-group-id  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2018-12-14 22:16:58,060 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:16:58,163 INFO kafka-coordinator-heartbeat-thread | some-group-id  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 22:16:58,325 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Attempt to heartbeat failed for since member id order-details-service-consumer-a8f2a835-f170-4b03-92be-662957f80c2b is not valid.
2018-12-14 22:17:06,247 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Revoking previously assigned partitions [shop-items-0]
2018-12-14 22:17:06,248 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] (Re-)joining group
2018-12-14 22:17:06,251 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Successfully joined group with generation 55
2018-12-14 22:17:06,251 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Setting newly assigned partitions [shop-items-0]
2018-12-14 22:17:06,306 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@45cd7bc5: startup date [Fri Dec 14 22:16:19 CET 2018]; root of context hierarchy
2018-12-14 22:17:06,313 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 22:17:06,313 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:17:06,318 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:20:06,781 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 22:20:06,799 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 22:20:06,814 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ae42ce3, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4f5991f6, org.springframework.test.context.support.DirtiesContextTestExecutionListener@484094a5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@38234a38, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@63fbfaeb]
2018-12-14 22:20:07,594 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 9947 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 22:20:07,595 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 22:20:07,652 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Fri Dec 14 22:20:07 CET 2018]; root of context hierarchy
2018-12-14 22:20:08,054 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 22:20:08,831 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$ecee938] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 22:20:10,299 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 22:20:10,306 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 22:20:10,368 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 22:20:10,370 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 22:20:10,371 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 22:20:10,520 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 22:20:10,566 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 22:20:10,676 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 22:20:10,880 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:20:10,888 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:20:11,247 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 22:20:11,419 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 22:20:11,461 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:20:11,462 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:20:11,464 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 22:20:11,750 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 33
2018-12-14 22:20:11,754 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 22:20:11,783 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:20:11,784 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:20:12,108 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Fri Dec 14 22:20:07 CET 2018]; root of context hierarchy
2018-12-14 22:20:12,164 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 22:20:12,165 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 22:20:12,186 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:20:12,186 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:20:12,212 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:20:12,453 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.528 seconds (JVM running for 6.961)
2018-12-14 22:20:12,455 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T21:20:12.448Z
2018-12-14 22:20:12,505 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:20:12,506 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 22:20:12,507 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Revoking previously assigned partitions []
2018-12-14 22:20:12,508 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] (Re-)joining group
2018-12-14 22:20:12,519 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Successfully joined group with generation 57
2018-12-14 22:20:12,521 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id] Setting newly assigned partitions [shop-items-0]
2018-12-14 22:20:12,596 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:20:12,857 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Fri Dec 14 22:20:07 CET 2018]; root of context hierarchy
2018-12-14 22:20:12,861 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 22:20:12,861 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:20:12,865 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:21:36,546 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 22:21:36,562 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 22:21:36,578 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@47a64f7d, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@33d05366, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@27a0a5a2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@7692cd34, org.springframework.test.context.transaction.TransactionalTestExecutionListener@33aa93c, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@32c0915e]
2018-12-14 22:21:37,388 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 9951 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 22:21:37,388 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 22:21:37,459 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@279dd959: startup date [Fri Dec 14 22:21:37 CET 2018]; root of context hierarchy
2018-12-14 22:21:37,893 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 22:21:38,692 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$694102ce] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 22:21:40,289 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 22:21:40,301 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 22:21:40,399 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 22:21:40,401 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 22:21:40,403 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 22:21:40,611 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 22:21:40,659 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 22:21:40,801 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 22:21:41,109 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:21:41,119 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:21:41,686 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 22:21:41,703 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 22:21:41,754 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:21:41,754 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:21:41,757 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 22:21:42,047 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 34
2018-12-14 22:21:42,053 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-2
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 22:21:42,086 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:21:42,086 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:21:42,478 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@279dd959: startup date [Fri Dec 14 22:21:37 CET 2018]; root of context hierarchy
2018-12-14 22:21:42,546 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 22:21:42,547 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 22:21:42,575 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:21:42,575 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:21:42,610 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:21:42,936 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 6.226 seconds (JVM running for 8.038)
2018-12-14 22:21:42,940 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T21:21:42.930Z
2018-12-14 22:21:42,995 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:21:42,996 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-2] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 22:21:42,998 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-2] Revoking previously assigned partitions []
2018-12-14 22:21:42,998 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-2] (Re-)joining group
2018-12-14 22:21:43,011 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-2] Successfully joined group with generation 1
2018-12-14 22:21:43,013 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-2] Setting newly assigned partitions [shop-items-0]
2018-12-14 22:21:43,023 INFO main  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-2] Resetting offset for partition shop-items-0 to offset 0.
2018-12-14 22:22:19,782 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:22:34,664 INFO kafka-coordinator-heartbeat-thread | some-group-id-2  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-2] Group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2018-12-14 22:22:34,675 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-2] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 22:22:34,675 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-2] Group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2018-12-14 22:22:34,755 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@279dd959: startup date [Fri Dec 14 22:21:37 CET 2018]; root of context hierarchy
2018-12-14 22:22:34,761 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 22:22:34,762 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:22:34,767 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:22:46,660 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 22:22:46,678 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 22:22:46,696 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@47a64f7d, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@33d05366, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@27a0a5a2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@7692cd34, org.springframework.test.context.transaction.TransactionalTestExecutionListener@33aa93c, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@32c0915e]
2018-12-14 22:22:47,536 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 9954 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 22:22:47,537 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 22:22:47,611 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@279dd959: startup date [Fri Dec 14 22:22:47 CET 2018]; root of context hierarchy
2018-12-14 22:22:48,039 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 22:22:48,845 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$f1cb4ad4] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 22:22:50,372 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 22:22:50,384 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 22:22:50,489 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 22:22:50,492 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 22:22:50,495 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 22:22:50,795 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 22:22:50,854 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 22:22:50,994 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 22:22:51,330 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:22:51,340 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:22:51,952 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 22:22:51,971 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 22:22:52,020 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:22:52,020 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:22:52,023 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 22:22:52,286 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 35
2018-12-14 22:22:52,293 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-2
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 22:22:52,327 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:22:52,327 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:22:52,701 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@279dd959: startup date [Fri Dec 14 22:22:47 CET 2018]; root of context hierarchy
2018-12-14 22:22:52,769 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 22:22:52,769 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 22:22:52,794 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:22:52,794 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:22:52,827 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:22:53,160 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 6.321 seconds (JVM running for 8.228)
2018-12-14 22:22:53,163 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T21:22:53.154Z
2018-12-14 22:22:53,220 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:22:53,221 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-2] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 22:22:53,222 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-2] Revoking previously assigned partitions []
2018-12-14 22:22:53,223 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-2] (Re-)joining group
2018-12-14 22:22:53,235 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-2] Successfully joined group with generation 3
2018-12-14 22:22:53,237 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-2] Setting newly assigned partitions [shop-items-0]
2018-12-14 22:22:53,248 INFO main  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-2] Resetting offset for partition shop-items-0 to offset 0.
2018-12-14 22:23:25,124 INFO kafka-coordinator-heartbeat-thread | some-group-id-2  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-2] Group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2018-12-14 22:23:48,977 INFO kafka-coordinator-heartbeat-thread | some-group-id-2  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-2] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 22:24:02,237 INFO kafka-coordinator-heartbeat-thread | some-group-id-2  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-2] Group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2018-12-14 22:24:07,119 INFO kafka-coordinator-heartbeat-thread | some-group-id-2  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-2] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 22:24:10,704 INFO kafka-coordinator-heartbeat-thread | some-group-id-2  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-2] Attempt to heartbeat failed for since member id order-details-service-consumer-090ae58e-6206-4f2f-aa40-3f32e0bceb45 is not valid.
2018-12-14 22:24:48,453 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:25:05,486 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-2] Revoking previously assigned partitions [shop-items-0]
2018-12-14 22:25:05,486 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-2] (Re-)joining group
2018-12-14 22:25:05,490 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-2] Successfully joined group with generation 5
2018-12-14 22:25:05,491 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-2] Setting newly assigned partitions [shop-items-0]
2018-12-14 22:25:05,492 INFO main  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-2] Resetting offset for partition shop-items-0 to offset 0.
2018-12-14 22:25:05,527 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@279dd959: startup date [Fri Dec 14 22:22:47 CET 2018]; root of context hierarchy
2018-12-14 22:25:05,533 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 22:25:05,533 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:25:05,538 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:25:54,485 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 22:25:54,500 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 22:25:54,513 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ae42ce3, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4f5991f6, org.springframework.test.context.support.DirtiesContextTestExecutionListener@484094a5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@38234a38, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@63fbfaeb]
2018-12-14 22:25:55,352 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 9960 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 22:25:55,352 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 22:25:55,411 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Fri Dec 14 22:25:55 CET 2018]; root of context hierarchy
2018-12-14 22:25:55,777 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 22:25:56,471 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$ecee938] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 22:25:57,648 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 22:25:57,656 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 22:25:57,725 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 22:25:57,727 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 22:25:57,729 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 22:25:57,924 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 22:25:57,984 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 22:25:58,136 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 22:25:58,341 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:25:58,350 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:25:58,741 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 22:25:58,909 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 22:25:58,957 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:25:58,957 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:25:58,959 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 22:25:59,239 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 36
2018-12-14 22:25:59,245 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-2
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 22:25:59,278 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:25:59,279 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:25:59,643 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Fri Dec 14 22:25:55 CET 2018]; root of context hierarchy
2018-12-14 22:25:59,710 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 22:25:59,711 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 22:25:59,735 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:25:59,735 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:25:59,767 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:26:00,015 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.393 seconds (JVM running for 6.848)
2018-12-14 22:26:00,017 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T21:26:00.010Z
2018-12-14 22:26:00,066 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:26:00,066 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-2] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 22:26:00,068 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-2] Revoking previously assigned partitions []
2018-12-14 22:26:00,068 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-2] (Re-)joining group
2018-12-14 22:26:00,080 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-2] Successfully joined group with generation 7
2018-12-14 22:26:00,083 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-2] Setting newly assigned partitions [shop-items-0]
2018-12-14 22:26:00,093 INFO main  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-2] Resetting offset for partition shop-items-0 to offset 0.
2018-12-14 22:26:00,180 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:26:00,454 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Fri Dec 14 22:25:55 CET 2018]; root of context hierarchy
2018-12-14 22:26:00,459 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 22:26:00,459 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:26:00,463 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:26:17,339 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 22:26:17,355 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 22:26:17,370 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@47a64f7d, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@33d05366, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@27a0a5a2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@7692cd34, org.springframework.test.context.transaction.TransactionalTestExecutionListener@33aa93c, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@32c0915e]
2018-12-14 22:26:18,193 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 9964 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 22:26:18,193 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 22:26:18,262 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@279dd959: startup date [Fri Dec 14 22:26:18 CET 2018]; root of context hierarchy
2018-12-14 22:26:18,707 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 22:26:19,494 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$a7f09afa] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 22:26:21,063 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 22:26:21,076 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 22:26:21,170 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 22:26:21,172 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 22:26:21,175 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 22:26:21,391 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 22:26:21,447 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 22:26:21,584 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 22:26:21,863 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:26:21,873 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:26:22,489 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 22:26:22,510 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 22:26:22,564 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:26:22,564 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:26:22,567 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 22:26:22,834 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 37
2018-12-14 22:26:22,841 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 22:26:22,875 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:26:22,875 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:26:23,260 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@279dd959: startup date [Fri Dec 14 22:26:18 CET 2018]; root of context hierarchy
2018-12-14 22:26:23,324 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 22:26:23,325 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 22:26:23,351 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:26:23,351 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:26:23,384 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:26:23,726 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 6.214 seconds (JVM running for 8.06)
2018-12-14 22:26:23,729 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T21:26:23.720Z
2018-12-14 22:26:23,789 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:26:23,789 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 22:26:23,791 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Revoking previously assigned partitions []
2018-12-14 22:26:23,792 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] (Re-)joining group
2018-12-14 22:26:23,806 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Successfully joined group with generation 1
2018-12-14 22:26:23,808 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Setting newly assigned partitions [shop-items-0]
2018-12-14 22:26:23,819 INFO main  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Resetting offset for partition shop-items-0 to offset 0.
2018-12-14 22:26:34,264 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:26:34,539 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@279dd959: startup date [Fri Dec 14 22:26:18 CET 2018]; root of context hierarchy
2018-12-14 22:26:34,545 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 22:26:34,545 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:26:34,550 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:26:39,815 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 22:26:39,830 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 22:26:39,846 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@47a64f7d, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@33d05366, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@27a0a5a2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@7692cd34, org.springframework.test.context.transaction.TransactionalTestExecutionListener@33aa93c, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@32c0915e]
2018-12-14 22:26:40,689 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 9967 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 22:26:40,689 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 22:26:40,758 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@46383a78: startup date [Fri Dec 14 22:26:40 CET 2018]; root of context hierarchy
2018-12-14 22:26:41,206 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 22:26:41,976 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$5bb9de85] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 22:26:43,510 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 22:26:43,522 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 22:26:43,622 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 22:26:43,624 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 22:26:43,627 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 22:26:43,847 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 22:26:43,900 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 22:26:44,026 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 22:26:44,284 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:26:44,294 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:26:44,893 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 22:26:44,915 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 22:26:44,972 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:26:44,972 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:26:44,975 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 22:26:45,288 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 38
2018-12-14 22:26:45,292 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 22:26:45,324 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:26:45,324 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:26:45,724 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@46383a78: startup date [Fri Dec 14 22:26:40 CET 2018]; root of context hierarchy
2018-12-14 22:26:45,793 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 22:26:45,794 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 22:26:45,822 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:26:45,822 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:26:45,855 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:26:46,213 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 6.221 seconds (JVM running for 8.041)
2018-12-14 22:26:46,216 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T21:26:46.207Z
2018-12-14 22:26:46,276 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:26:46,277 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 22:26:46,278 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Revoking previously assigned partitions []
2018-12-14 22:26:46,279 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] (Re-)joining group
2018-12-14 22:26:46,291 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Successfully joined group with generation 3
2018-12-14 22:26:46,294 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Setting newly assigned partitions [shop-items-0]
2018-12-14 22:28:56,290 INFO kafka-coordinator-heartbeat-thread | some-group-id-3  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2018-12-14 22:28:56,419 INFO kafka-coordinator-heartbeat-thread | some-group-id-3  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 22:28:57,231 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:28:57,486 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Attempt to heartbeat failed for since member id order-details-service-consumer-84b59701-24c9-481e-97ab-99ce229ad129 is not valid.
2018-12-14 22:28:57,486 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Revoking previously assigned partitions [shop-items-0]
2018-12-14 22:28:57,486 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] (Re-)joining group
2018-12-14 22:28:57,489 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Successfully joined group with generation 5
2018-12-14 22:28:57,489 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Setting newly assigned partitions [shop-items-0]
2018-12-14 22:28:57,515 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@46383a78: startup date [Fri Dec 14 22:26:40 CET 2018]; root of context hierarchy
2018-12-14 22:28:57,520 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 22:28:57,520 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:28:57,524 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:29:21,178 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-14 22:29:21,190 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-14 22:29:21,202 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@10a9d961, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@130e116b, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@e383572, org.springframework.test.context.support.DirtiesContextTestExecutionListener@5ddf0d24, org.springframework.test.context.transaction.TransactionalTestExecutionListener@363a52f, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@60856961]
2018-12-14 22:29:21,966 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 9973 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-14 22:29:21,966 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-14 22:29:22,025 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 22:29:22 CET 2018]; root of context hierarchy
2018-12-14 22:29:22,380 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-14 22:29:23,121 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$b9e5abbd] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-14 22:29:24,408 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-14 22:29:24,415 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-14 22:29:24,471 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-14 22:29:24,472 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-14 22:29:24,474 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-14 22:29:24,623 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-14 22:29:24,679 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-14 22:29:24,816 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-14 22:29:25,023 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:29:25,030 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-14 22:29:25,391 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-14 22:29:25,567 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-14 22:29:25,617 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:29:25,617 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:29:25,621 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-14 22:29:25,906 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 39
2018-12-14 22:29:25,911 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-14 22:29:25,943 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-14 22:29:25,943 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-14 22:29:26,264 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 22:29:22 CET 2018]; root of context hierarchy
2018-12-14 22:29:26,322 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-14 22:29:26,323 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-14 22:29:26,344 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:29:26,345 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:29:26,373 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-14 22:29:26,617 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.299 seconds (JVM running for 6.751)
2018-12-14 22:29:26,619 INFO pool-2-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-14T21:29:26.611Z
2018-12-14 22:29:26,669 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:29:26,670 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-14 22:29:26,671 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Revoking previously assigned partitions []
2018-12-14 22:29:26,672 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] (Re-)joining group
2018-12-14 22:29:26,682 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Successfully joined group with generation 7
2018-12-14 22:29:26,684 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Setting newly assigned partitions [shop-items-0]
2018-12-14 22:29:26,763 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-14 22:29:27,075 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Fri Dec 14 22:29:22 CET 2018]; root of context hierarchy
2018-12-14 22:29:27,079 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-14 22:29:27,080 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-14 22:29:27,085 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 17:42:57,399 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 17:42:57,411 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 17:42:57,425 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ae42ce3, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4f5991f6, org.springframework.test.context.support.DirtiesContextTestExecutionListener@484094a5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@38234a38, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@63fbfaeb]
2018-12-15 17:42:58,166 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 10528 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 17:42:58,166 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 17:42:58,225 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 17:42:58 CET 2018]; root of context hierarchy
2018-12-15 17:42:58,601 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 17:42:59,291 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$2ad7275e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 17:43:00,561 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 17:43:00,568 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 17:43:00,617 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 17:43:00,618 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 17:43:00,619 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 17:43:00,770 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 17:43:00,817 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 17:43:00,937 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 17:43:01,149 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 17:43:01,158 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 17:43:01,720 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 17:43:01,753 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 17:43:01,803 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:43:01,804 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:43:01,810 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 17:43:01,812 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 17:43:01,853 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:43:01,854 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:43:01,855 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 17:43:01,857 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 17:43:01,882 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:43:01,883 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:43:01,891 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 17:43:01,893 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 17:43:01,901 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 17:43:01,901 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:43:01,901 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:43:01,913 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 17:43:01,920 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 17:43:01,922 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:43:01,923 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:43:01,923 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 17:43:01,924 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 17:43:01,927 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:43:01,928 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:43:01,931 WARN main  org.apache.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=my-client-id
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:62)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:425)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:316)
	at io.dddbyexamples.eventsource.boundary.ShopItems.createCommandProducer(ShopItems.java:130)
	at io.dddbyexamples.eventsource.boundary.ShopItems.<init>(ShopItems.java:83)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 17:43:01,932 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-15 17:43:01,936 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:43:01,936 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:43:01,939 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-15 17:43:02,199 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 40
2018-12-15 17:43:02,211 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 17:43:02,211 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 17:43:02,213 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Revoking previously assigned partitions []
2018-12-15 17:43:02,213 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] (Re-)joining group
2018-12-15 17:43:02,225 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Successfully joined group with generation 9
2018-12-15 17:43:02,227 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Setting newly assigned partitions [shop-items-0]
2018-12-15 17:43:02,278 WARN main  org.springframework.web.context.support.GenericWebApplicationContext - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'shopItems' defined in file [/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/production/classes/io/dddbyexamples/eventsource/boundary/ShopItems.class]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.dddbyexamples.eventsource.boundary.ShopItems]: Constructor threw exception; nested exception is org.apache.kafka.common.errors.SerializationException: Error deserializing key/value for partition shop-items-0 at offset 118. If needed, please seek past the record to continue consumption.
2018-12-15 17:43:02,278 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from CREATED to PENDING_SHUTDOWN
2018-12-15 17:43:02,279 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Informed to shut down
2018-12-15 17:43:02,279 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to PENDING_SHUTDOWN
2018-12-15 17:43:02,279 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutting down
2018-12-15 17:43:02,279 INFO kafka-streams-close-thread  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 17:43:02,279 INFO kafka-streams-close-thread  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=wordcount-lambda-example-client-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-12-15 17:43:02,285 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2018-12-15 17:43:02,285 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutdown complete
2018-12-15 17:43:02,289 INFO kafka-streams-close-thread  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from PENDING_SHUTDOWN to NOT_RUNNING
2018-12-15 17:43:02,290 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Streams client stopped completely
2018-12-15 17:43:02,290 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-15 17:43:02,290 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 17:43:02,294 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 17:43:02,297 ERROR main  org.springframework.boot.SpringApplication - Application startup failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'shopItems' defined in file [/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/production/classes/io/dddbyexamples/eventsource/boundary/ShopItems.class]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.dddbyexamples.eventsource.boundary.ShopItems]: Constructor threw exception; nested exception is org.apache.kafka.common.errors.SerializationException: Error deserializing key/value for partition shop-items-0 at offset 118. If needed, please seek past the record to continue consumption.
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:275)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.dddbyexamples.eventsource.boundary.ShopItems]: Constructor threw exception; nested exception is org.apache.kafka.common.errors.SerializationException: Error deserializing key/value for partition shop-items-0 at offset 118. If needed, please seek past the record to continue consumption.
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:163)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	... 53 common frames omitted
Caused by: org.apache.kafka.common.errors.SerializationException: Error deserializing key/value for partition shop-items-0 at offset 118. If needed, please seek past the record to continue consumption.
Caused by: org.apache.kafka.common.errors.SerializationException: Can't deserialize data [[123, 34, 116, 121, 112, 101, 34, 58, 34, 105, 116, 101, 109, 46, 98, 111, 117, 103, 104, 116, 34, 44, 34, 117, 117, 105, 100, 34, 58, 34, 55, 54, 50, 53, 97, 53, 98, 102, 45, 50, 55, 50, 48, 45, 52, 98, 51, 99, 45, 98, 56, 53, 54, 45, 55, 97, 48, 55, 97, 57, 54, 99, 100, 48, 97, 101, 34, 44, 34, 119, 104, 101, 110, 34, 58, 49, 53, 52, 52, 56, 50, 50, 57, 54, 55, 46, 48, 49, 56, 48, 48, 48, 48, 48, 48, 44, 34, 112, 97, 121, 109, 101, 110, 116, 84, 105, 109, 101, 111, 117, 116, 68, 97, 116, 101, 34, 58, 49, 53, 52, 52, 57, 48, 57, 51, 54, 55, 46, 48, 49, 56, 48, 48, 48, 48, 48, 48, 125]] from topic [shop-items]
Caused by: com.fasterxml.jackson.databind.JsonMappingException: Can not construct instance of io.dddbyexamples.eventsource.domain.shopitem.commands.Command, problem: abstract types either need to be mapped to concrete types, have custom deserializer, or be instantiated with additional type information
 at [Source: [B@70e8c019; line: 1, column: 1]
	at com.fasterxml.jackson.databind.JsonMappingException.from(JsonMappingException.java:255)
	at com.fasterxml.jackson.databind.DeserializationContext.instantiationException(DeserializationContext.java:1006)
	at com.fasterxml.jackson.databind.deser.AbstractDeserializer.deserialize(AbstractDeserializer.java:150)
	at com.fasterxml.jackson.databind.ObjectReader._bindAndClose(ObjectReader.java:1578)
	at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1217)
	at org.springframework.kafka.support.serializer.JsonDeserializer.deserialize(JsonDeserializer.java:328)
	at org.apache.kafka.clients.consumer.internals.Fetcher.parseRecord(Fetcher.java:1027)
	at org.apache.kafka.clients.consumer.internals.Fetcher.access$3300(Fetcher.java:110)
	at org.apache.kafka.clients.consumer.internals.Fetcher$PartitionRecords.fetchRecords(Fetcher.java:1247)
	at org.apache.kafka.clients.consumer.internals.Fetcher$PartitionRecords.access$1400(Fetcher.java:1096)
	at org.apache.kafka.clients.consumer.internals.Fetcher.fetchRecords(Fetcher.java:544)
	at org.apache.kafka.clients.consumer.internals.Fetcher.fetchedRecords(Fetcher.java:505)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollForFetches(KafkaConsumer.java:1256)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1188)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1123)
	at io.dddbyexamples.eventsource.boundary.ShopItems.proceedBuy(ShopItems.java:94)
	at io.dddbyexamples.eventsource.boundary.ShopItems.<init>(ShopItems.java:88)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 17:43:02,300 INFO main  org.springframework.boot.logging.ClasspathLoggingApplicationListener - Application failed to start with classpath: [file:/Applications/IntelliJ%20IDEA.app/Contents/lib/idea_rt.jar, file:/Applications/IntelliJ%20IDEA.app/Contents/plugins/junit/lib/junit-rt.jar, file:/Applications/IntelliJ%20IDEA.app/Contents/plugins/junit/lib/junit5-rt.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/charsets.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/deploy.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/cldrdata.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/dnsns.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/jaccess.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/jfxrt.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/localedata.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/nashorn.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/sunec.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/zipfs.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/javaws.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/jce.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/jfr.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/jfxswt.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/jsse.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/management-agent.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/plugin.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/resources.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/rt.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/ant-javafx.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/dt.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/javafx-mx.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/jconsole.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/packager.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/sa-jdi.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/tools.jar, file:/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes/, file:/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/resources/, file:/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/production/classes/, file:/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/production/resources/, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.kafka/spring-kafka/2.2.2.RELEASE/9b8d0fee9997197e80011c518f2f7fe1d95bb761/spring-kafka-2.2.2.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-web/1.3.5.RELEASE/1ad40f8edd1b502fb82bfae3a6feb8be3a2b44fa/spring-boot-starter-web-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-data-jpa/1.3.5.RELEASE/32f4449a9de903ec4e4acd9c8f6af7c6a1309571/spring-boot-starter-data-jpa-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.m2/repository/com/google/guava/guava/18.0/guava-18.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.projectlombok/lombok/1.16.8/2ce9de13f277ec1600e7e04231477e3e5f59d317/lombok-1.16.8.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-databind/2.7.4/1e9c6f3659644aeac84872c3b62d8e363bf4c96d/jackson-databind-2.7.4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.datatype/jackson-datatype-jsr310/2.7.4/390dbf17d4eb29a6157c6b9dcd9c93e7acac714/jackson-datatype-jsr310-2.7.4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-annotations/2.7.4/84b2f8e53bd8a077d402bc99d9bce816c2b2d0f9/jackson-annotations-2.7.4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.liquibase/liquibase-core/3.5.0/85834c6c100768cfe6351ea5e9c4d27523472390/liquibase-core-3.5.0.jar, file:/Users/pszymczyk/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.kafka/kafka-streams/2.1.0/ab1d9cf35cf0040a804266279faeaf082d3f66c3/kafka-streams-2.1.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-test/1.3.5.RELEASE/5c485e918b58741eccc0012c70062df5e5efa106/spring-boot-starter-test-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.spockframework/spock-spring/1.0-groovy-2.4/a07c753a95114872cd753ce3ae9166b64284b31d/spock-spring-1.0-groovy-2.4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-context/4.2.6.RELEASE/bbf3c8526fe37bb341507f28db17882d4348dbca/spring-context-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/cglib/cglib-nodep/3.2.1/dbee35a2ff88d175e8a321adae1f62b58cfd8a79/cglib-nodep-3.2.1.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.h2database/h2/1.4.191/dec3540178ea889b2871b0ed56db14bbec9cfdfc/h2-1.4.191.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-messaging/4.2.6.RELEASE/f7b3f8f875e055295f6ed2e552187f25b55c6920/spring-messaging-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-tx/4.2.6.RELEASE/ba7502c0644414748b1eeb65b4193b05d335a110/spring-tx-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.m2/repository/org/codehaus/groovy/groovy/2.4.15/groovy-2.4.15.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.retry/spring-retry/1.1.2.RELEASE/949a23beb82ebe31d7a1d47022353b8338c4da11/spring-retry-1.1.2.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter/1.3.5.RELEASE/188c658fabbce0d1ccc1ae18a1cf58f566208c78/spring-boot-starter-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-tomcat/1.3.5.RELEASE/b4c6277ccec38c51716659886efec073c4b386ea/spring-boot-starter-tomcat-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-validation/1.3.5.RELEASE/c83a6cc60a95faace7e03c524d60fc9de1329f57/spring-boot-starter-validation-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-web/4.2.6.RELEASE/d5ce949da3f3266f118ed899a153413613b503ad/spring-web-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-webmvc/4.2.6.RELEASE/7c7ea475d33287e0e3a92e98ccbe0ad6a0dbb9ca/spring-webmvc-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-aop/1.3.5.RELEASE/478a50b44faab2ada75583637b9f6e789809d069/spring-boot-starter-aop-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-jdbc/1.3.5.RELEASE/b427aa14a4f3a2fba114bcbb60eae6f83ee86706/spring-boot-starter-jdbc-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.hibernate/hibernate-entitymanager/4.3.11.Final/27a119fcc2b91c50e5285dd11158fac2c38c9d1b/hibernate-entitymanager-4.3.11.Final.jar, file:/Users/pszymczyk/.m2/repository/javax/transaction/javax.transaction-api/1.2/javax.transaction-api-1.2.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.data/spring-data-jpa/1.9.4.RELEASE/80b83510e67aa085b7d91d2d096d90133ec995de/spring-data-jpa-1.9.4.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-aspects/4.2.6.RELEASE/7ed7b15e95eedd551ac979bd8c295256d96cf2ff/spring-aspects-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-core/2.6.6/2eb801df67aacaf5b1deb4ac626e1964508e47b/jackson-core-2.6.6.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.yaml/snakeyaml/1.16/d64fb662c9e42789149f5078a62a22edda786c6a/snakeyaml-1.16.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.kafka/connect-json/2.1.0/6e2b621686935ee93e3f627477fcf7483769953d/connect-json-2.1.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-api/1.7.21/139535a69a4239db087de9bab0bee568bf8e0b70/slf4j-api-1.7.21.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.rocksdb/rocksdbjni/5.14.2/a6087318fab540ba0b4c6ff68475ffbedc0b3d10/rocksdbjni-5.14.2.jar, file:/Users/pszymczyk/.m2/repository/junit/junit/4.12/junit-4.12.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.mockito/mockito-core/1.10.19/e8546f5bef4e061d8dd73895b4e8f40e3fe6effe/mockito-core-1.10.19.jar, file:/Users/pszymczyk/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar, file:/Users/pszymczyk/.m2/repository/org/hamcrest/hamcrest-library/1.3/hamcrest-library-1.3.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-core/4.2.6.RELEASE/a1c6ef01f18888f51fc5054c65ef4787b7cf0a1e/spring-core-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-test/4.2.6.RELEASE/1f869333b3d64f17009a613368165978af575d8c/spring-test-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.spockframework/spock-core/1.0-groovy-2.4/ceaa8b69f274ed3de24da3e6a6c86f673b426d1a/spock-core-1.0-groovy-2.4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.codehaus.groovy/groovy-all/2.4.6/478feadca929a946b2f1fb962bb2179264759821/groovy-all-2.4.6.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-aop/4.2.6.RELEASE/5efbfccb19efda2956b8977561bf4da6b15b0d0e/spring-aop-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-beans/4.2.6.RELEASE/d4a319fb4d949fb6313f45c929947b9b4e26283e/spring-beans-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-expression/4.2.6.RELEASE/c0182d73f348ab11d51d45cbe29f3820c32d0ccc/spring-expression-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot/1.3.5.RELEASE/b218ba5f3bd01e657fbde9b085722da1fafa4f8a/spring-boot-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-autoconfigure/1.3.5.RELEASE/2bcfa86bb3afd95eff5252db6d78f2693b706997/spring-boot-autoconfigure-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-logging/1.3.5.RELEASE/a71e1d7fff512b1eadd3426ea1ce5b4cc703c429/spring-boot-starter-logging-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-core/8.0.33/4e7f547fbb2c364cb5e02a58790c5fb89e31efed/tomcat-embed-core-8.0.33.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-el/8.0.33/31423f2d493cf1f7cf5f0082c9f94640e93b8c1b/tomcat-embed-el-8.0.33.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-logging-juli/8.0.33/66bc309e0227c1ba2cf4417182d0b1583003d24b/tomcat-embed-logging-juli-8.0.33.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-websocket/8.0.33/be1f95e5d9ae00f9bc6138441d29cfe5c7c60256/tomcat-embed-websocket-8.0.33.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.hibernate/hibernate-validator/5.2.4.Final/fb18766b576aa6632bcfe9a20a023cbd52bf9769/hibernate-validator-5.2.4.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.aspectj/aspectjweaver/1.8.9/db28774f477f07220eac18d5ec9c4e01f48589d7/aspectjweaver-1.8.9.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat/tomcat-jdbc/8.0.33/7f1b6d609f9c2e045e8d7759e96605841fffdf82/tomcat-jdbc-8.0.33.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-jdbc/4.2.6.RELEASE/16075bfb0901a5b89c5be975365ff09b2df04abb/spring-jdbc-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.jboss.logging/jboss-logging/3.3.0.Final/3616bb87707910296e2c195dc016287080bba5af/jboss-logging-3.3.0.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.jboss.logging/jboss-logging-annotations/1.2.0.Beta1/2f437f37bb265d9f8f1392823dbca12d2bec06d6/jboss-logging-annotations-1.2.0.Beta1.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.hibernate/hibernate-core/4.3.11.Final/536ac0021240d97db99c7d2983067cef1a6f3af5/hibernate-core-4.3.11.Final.jar, file:/Users/pszymczyk/.m2/repository/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.hibernate.common/hibernate-commons-annotations/4.0.5.Final/2a581b9edb8168e45060d8bad8b7f46712d2c52c/hibernate-commons-annotations-4.0.5.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.hibernate.javax.persistence/hibernate-jpa-2.1-api/1.0.0.Final/5e731d961297e5a07290bfaf3db1fbc8bbbf405a/hibernate-jpa-2.1-api-1.0.0.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.javassist/javassist/3.18.1-GA/d9a09f7732226af26bf99f19e2cffe0ae219db5b/javassist-3.18.1-GA.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.data/spring-data-commons/1.11.4.RELEASE/c2b1fd4dbf7dff772d6124bb35892759e8bf088e/spring-data-commons-1.11.4.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-orm/4.2.6.RELEASE/2ef30e836028ebe4dbba0d8355929625a758ed8d/spring-orm-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.slf4j/jcl-over-slf4j/1.7.21/331b564a3a42f002a0004b039c1c430da89062cd/jcl-over-slf4j-1.7.21.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.kafka/connect-api/2.1.0/589e4d3a3f90446fd97059e4cc13975f01d9a1d0/connect-api-2.1.0.jar, file:/Users/pszymczyk/.m2/repository/org/objenesis/objenesis/2.1/objenesis-2.1.jar, file:/Users/pszymczyk/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/ch.qos.logback/logback-classic/1.1.7/9865cf6994f9ff13fce0bf93f2054ef6c65bb462/logback-classic-1.1.7.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.slf4j/jul-to-slf4j/1.7.21/2f22c882ffa479d1e9ff4eb0e8e2c29f2a0871ed/jul-to-slf4j-1.7.21.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.slf4j/log4j-over-slf4j/1.7.21/b3700d97464d99bdcd42c0177d6e7951c94d75ff/log4j-over-slf4j-1.7.21.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/javax.validation/validation-api/1.1.0.Final/8613ae82954779d518631e05daa73a6a954817d5/validation-api-1.1.0.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.fasterxml/classmate/1.1.0/dbbd699a1486ad0f2ed6f5af6cfed66acacb9056/classmate-1.1.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat/tomcat-juli/8.0.33/330aecfa895156cea91c576cb6609537152761f9/tomcat-juli-8.0.33.jar, file:/Users/pszymczyk/.m2/repository/antlr/antlr/2.7.7/antlr-2.7.7.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.jboss/jandex/1.1.0.Final/e84a2122e76f0b6503be78094ddf2108057ac15f/jandex-1.1.0.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/xml-apis/xml-apis/1.0.b2/3136ca936f64c9d68529f048c2618bd356bf85c9/xml-apis-1.0.b2.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/javax.ws.rs/javax.ws.rs-api/2.1.1/d3466bc9321fe84f268a1adb3b90373fc14b0eb5/javax.ws.rs-api-2.1.1.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/ch.qos.logback/logback-core/1.1.7/7873092d39ef741575ca91378a6a21c388363ac8/logback-core-1.1.7.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.kafka/kafka-clients/2.1.0/34d9983705c953b97abb01e1cd04647f47272fe5/kafka-clients-2.1.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.github.luben/zstd-jni/1.3.5-4/550b6393a007d0867c98611ca8cfbcf53f2eb991/zstd-jni-1.3.5-4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.lz4/lz4-java/1.5.0/d36fb639f06aaa4f17307625f80e2e32f815672a/lz4-java-1.5.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.xerial.snappy/snappy-java/1.1.7.2/307b286efd119ad2c6d4291128bf110bddc68088/snappy-java-1.1.7.2.jar, file:/Applications/IntelliJ%20IDEA.app/Contents/lib/idea_rt.jar]
2018-12-15 17:43:02,300 ERROR main  org.springframework.test.context.TestContextManager - Caught exception while allowing TestExecutionListener [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1] to prepare test instance [io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec@3c108c05]
java.lang.IllegalStateException: Failed to load ApplicationContext
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:124)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'shopItems' defined in file [/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/production/classes/io/dddbyexamples/eventsource/boundary/ShopItems.class]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.dddbyexamples.eventsource.boundary.ShopItems]: Constructor threw exception; nested exception is org.apache.kafka.common.errors.SerializationException: Error deserializing key/value for partition shop-items-0 at offset 118. If needed, please seek past the record to continue consumption.
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:275)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	... 36 common frames omitted
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.dddbyexamples.eventsource.boundary.ShopItems]: Constructor threw exception; nested exception is org.apache.kafka.common.errors.SerializationException: Error deserializing key/value for partition shop-items-0 at offset 118. If needed, please seek past the record to continue consumption.
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:163)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	... 53 common frames omitted
Caused by: org.apache.kafka.common.errors.SerializationException: Error deserializing key/value for partition shop-items-0 at offset 118. If needed, please seek past the record to continue consumption.
Caused by: org.apache.kafka.common.errors.SerializationException: Can't deserialize data [[123, 34, 116, 121, 112, 101, 34, 58, 34, 105, 116, 101, 109, 46, 98, 111, 117, 103, 104, 116, 34, 44, 34, 117, 117, 105, 100, 34, 58, 34, 55, 54, 50, 53, 97, 53, 98, 102, 45, 50, 55, 50, 48, 45, 52, 98, 51, 99, 45, 98, 56, 53, 54, 45, 55, 97, 48, 55, 97, 57, 54, 99, 100, 48, 97, 101, 34, 44, 34, 119, 104, 101, 110, 34, 58, 49, 53, 52, 52, 56, 50, 50, 57, 54, 55, 46, 48, 49, 56, 48, 48, 48, 48, 48, 48, 44, 34, 112, 97, 121, 109, 101, 110, 116, 84, 105, 109, 101, 111, 117, 116, 68, 97, 116, 101, 34, 58, 49, 53, 52, 52, 57, 48, 57, 51, 54, 55, 46, 48, 49, 56, 48, 48, 48, 48, 48, 48, 125]] from topic [shop-items]
Caused by: com.fasterxml.jackson.databind.JsonMappingException: Can not construct instance of io.dddbyexamples.eventsource.domain.shopitem.commands.Command, problem: abstract types either need to be mapped to concrete types, have custom deserializer, or be instantiated with additional type information
 at [Source: [B@70e8c019; line: 1, column: 1]
	at com.fasterxml.jackson.databind.JsonMappingException.from(JsonMappingException.java:255)
	at com.fasterxml.jackson.databind.DeserializationContext.instantiationException(DeserializationContext.java:1006)
	at com.fasterxml.jackson.databind.deser.AbstractDeserializer.deserialize(AbstractDeserializer.java:150)
	at com.fasterxml.jackson.databind.ObjectReader._bindAndClose(ObjectReader.java:1578)
	at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1217)
	at org.springframework.kafka.support.serializer.JsonDeserializer.deserialize(JsonDeserializer.java:328)
	at org.apache.kafka.clients.consumer.internals.Fetcher.parseRecord(Fetcher.java:1027)
	at org.apache.kafka.clients.consumer.internals.Fetcher.access$3300(Fetcher.java:110)
	at org.apache.kafka.clients.consumer.internals.Fetcher$PartitionRecords.fetchRecords(Fetcher.java:1247)
	at org.apache.kafka.clients.consumer.internals.Fetcher$PartitionRecords.access$1400(Fetcher.java:1096)
	at org.apache.kafka.clients.consumer.internals.Fetcher.fetchRecords(Fetcher.java:544)
	at org.apache.kafka.clients.consumer.internals.Fetcher.fetchedRecords(Fetcher.java:505)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollForFetches(KafkaConsumer.java:1256)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1188)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1123)
	at io.dddbyexamples.eventsource.boundary.ShopItems.proceedBuy(ShopItems.java:94)
	at io.dddbyexamples.eventsource.boundary.ShopItems.<init>(ShopItems.java:88)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 17:45:16,441 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 17:45:16,453 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 17:45:16,466 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ae42ce3, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4f5991f6, org.springframework.test.context.support.DirtiesContextTestExecutionListener@484094a5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@38234a38, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@63fbfaeb]
2018-12-15 17:45:17,216 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 10546 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 17:45:17,216 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 17:45:17,276 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 17:45:17 CET 2018]; root of context hierarchy
2018-12-15 17:45:17,635 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 17:45:18,283 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$2ad7275e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 17:45:19,599 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 17:45:19,607 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 17:45:19,669 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 17:45:19,670 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 17:45:19,671 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 17:45:19,836 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 17:45:19,890 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 17:45:20,060 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 17:45:20,294 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 17:45:20,303 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 17:45:20,829 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 17:45:20,861 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 17:45:20,910 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:45:20,910 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:45:20,916 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 17:45:20,919 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 17:45:20,955 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:45:20,955 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:45:20,957 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 17:45:20,959 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 17:45:20,983 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:45:20,983 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:45:20,991 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 17:45:20,992 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 17:45:21,000 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 17:45:21,001 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:45:21,001 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:45:21,013 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 17:45:21,019 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 17:45:21,022 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:45:21,022 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:45:21,023 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 17:45:21,024 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 17:45:21,026 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:45:21,026 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:45:21,029 WARN main  org.apache.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=my-client-id
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:62)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:425)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:316)
	at io.dddbyexamples.eventsource.boundary.ShopItems.createCommandProducer(ShopItems.java:130)
	at io.dddbyexamples.eventsource.boundary.ShopItems.<init>(ShopItems.java:83)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 17:45:21,030 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-15 17:45:21,033 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:45:21,033 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:45:21,035 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-15 17:45:21,296 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 41
2018-12-15 17:45:21,309 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 17:45:21,309 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 17:45:21,311 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Revoking previously assigned partitions []
2018-12-15 17:45:21,311 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] (Re-)joining group
2018-12-15 17:45:21,323 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Successfully joined group with generation 11
2018-12-15 17:45:21,325 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Setting newly assigned partitions [shop-items-0]
2018-12-15 17:45:21,367 WARN main  org.springframework.web.context.support.GenericWebApplicationContext - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'shopItems' defined in file [/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/production/classes/io/dddbyexamples/eventsource/boundary/ShopItems.class]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.dddbyexamples.eventsource.boundary.ShopItems]: Constructor threw exception; nested exception is org.apache.kafka.common.errors.SerializationException: Error deserializing key/value for partition shop-items-0 at offset 118. If needed, please seek past the record to continue consumption.
2018-12-15 17:45:21,367 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from CREATED to PENDING_SHUTDOWN
2018-12-15 17:45:21,368 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Informed to shut down
2018-12-15 17:45:21,368 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to PENDING_SHUTDOWN
2018-12-15 17:45:21,368 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutting down
2018-12-15 17:45:21,368 INFO kafka-streams-close-thread  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 17:45:21,368 INFO kafka-streams-close-thread  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=wordcount-lambda-example-client-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-12-15 17:45:21,373 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2018-12-15 17:45:21,373 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutdown complete
2018-12-15 17:45:21,377 INFO kafka-streams-close-thread  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from PENDING_SHUTDOWN to NOT_RUNNING
2018-12-15 17:45:21,377 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Streams client stopped completely
2018-12-15 17:45:21,378 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-15 17:45:21,378 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 17:45:21,381 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 17:45:21,384 ERROR main  org.springframework.boot.SpringApplication - Application startup failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'shopItems' defined in file [/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/production/classes/io/dddbyexamples/eventsource/boundary/ShopItems.class]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.dddbyexamples.eventsource.boundary.ShopItems]: Constructor threw exception; nested exception is org.apache.kafka.common.errors.SerializationException: Error deserializing key/value for partition shop-items-0 at offset 118. If needed, please seek past the record to continue consumption.
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:275)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.dddbyexamples.eventsource.boundary.ShopItems]: Constructor threw exception; nested exception is org.apache.kafka.common.errors.SerializationException: Error deserializing key/value for partition shop-items-0 at offset 118. If needed, please seek past the record to continue consumption.
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:163)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	... 53 common frames omitted
Caused by: org.apache.kafka.common.errors.SerializationException: Error deserializing key/value for partition shop-items-0 at offset 118. If needed, please seek past the record to continue consumption.
Caused by: org.apache.kafka.common.errors.SerializationException: Can't deserialize data [[123, 34, 116, 121, 112, 101, 34, 58, 34, 105, 116, 101, 109, 46, 98, 111, 117, 103, 104, 116, 34, 44, 34, 117, 117, 105, 100, 34, 58, 34, 55, 54, 50, 53, 97, 53, 98, 102, 45, 50, 55, 50, 48, 45, 52, 98, 51, 99, 45, 98, 56, 53, 54, 45, 55, 97, 48, 55, 97, 57, 54, 99, 100, 48, 97, 101, 34, 44, 34, 119, 104, 101, 110, 34, 58, 49, 53, 52, 52, 56, 50, 50, 57, 54, 55, 46, 48, 49, 56, 48, 48, 48, 48, 48, 48, 44, 34, 112, 97, 121, 109, 101, 110, 116, 84, 105, 109, 101, 111, 117, 116, 68, 97, 116, 101, 34, 58, 49, 53, 52, 52, 57, 48, 57, 51, 54, 55, 46, 48, 49, 56, 48, 48, 48, 48, 48, 48, 125]] from topic [shop-items]
Caused by: com.fasterxml.jackson.databind.JsonMappingException: Could not resolve type id 'item.bought' into a subtype of [simple type, class io.dddbyexamples.eventsource.domain.shopitem.commands.Command]: known type ids = [Command, MarkPaymentTimeout, Pay, buy]
 at [Source: [B@2a191f83; line: 1, column: 2]
	at com.fasterxml.jackson.databind.JsonMappingException.from(JsonMappingException.java:255)
	at com.fasterxml.jackson.databind.DeserializationContext.unknownTypeException(DeserializationContext.java:1082)
	at com.fasterxml.jackson.databind.jsontype.impl.TypeDeserializerBase._handleUnknownTypeId(TypeDeserializerBase.java:281)
	at com.fasterxml.jackson.databind.jsontype.impl.TypeDeserializerBase._findDeserializer(TypeDeserializerBase.java:163)
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer._deserializeTypedForId(AsPropertyTypeDeserializer.java:106)
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromObject(AsPropertyTypeDeserializer.java:91)
	at com.fasterxml.jackson.databind.deser.AbstractDeserializer.deserializeWithType(AbstractDeserializer.java:142)
	at com.fasterxml.jackson.databind.deser.impl.TypeWrappedDeserializer.deserialize(TypeWrappedDeserializer.java:42)
	at com.fasterxml.jackson.databind.ObjectReader._bindAndClose(ObjectReader.java:1578)
	at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1217)
	at org.springframework.kafka.support.serializer.JsonDeserializer.deserialize(JsonDeserializer.java:328)
	at org.apache.kafka.clients.consumer.internals.Fetcher.parseRecord(Fetcher.java:1027)
	at org.apache.kafka.clients.consumer.internals.Fetcher.access$3300(Fetcher.java:110)
	at org.apache.kafka.clients.consumer.internals.Fetcher$PartitionRecords.fetchRecords(Fetcher.java:1247)
	at org.apache.kafka.clients.consumer.internals.Fetcher$PartitionRecords.access$1400(Fetcher.java:1096)
	at org.apache.kafka.clients.consumer.internals.Fetcher.fetchRecords(Fetcher.java:544)
	at org.apache.kafka.clients.consumer.internals.Fetcher.fetchedRecords(Fetcher.java:505)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollForFetches(KafkaConsumer.java:1256)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1188)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1123)
	at io.dddbyexamples.eventsource.boundary.ShopItems.proceedBuy(ShopItems.java:94)
	at io.dddbyexamples.eventsource.boundary.ShopItems.<init>(ShopItems.java:88)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 17:45:21,386 INFO main  org.springframework.boot.logging.ClasspathLoggingApplicationListener - Application failed to start with classpath: [file:/Applications/IntelliJ%20IDEA.app/Contents/lib/idea_rt.jar, file:/Applications/IntelliJ%20IDEA.app/Contents/plugins/junit/lib/junit-rt.jar, file:/Applications/IntelliJ%20IDEA.app/Contents/plugins/junit/lib/junit5-rt.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/charsets.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/deploy.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/cldrdata.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/dnsns.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/jaccess.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/jfxrt.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/localedata.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/nashorn.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/sunec.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/zipfs.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/javaws.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/jce.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/jfr.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/jfxswt.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/jsse.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/management-agent.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/plugin.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/resources.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/rt.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/ant-javafx.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/dt.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/javafx-mx.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/jconsole.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/packager.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/sa-jdi.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/tools.jar, file:/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes/, file:/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/resources/, file:/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/production/classes/, file:/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/production/resources/, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.kafka/spring-kafka/2.2.2.RELEASE/9b8d0fee9997197e80011c518f2f7fe1d95bb761/spring-kafka-2.2.2.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-web/1.3.5.RELEASE/1ad40f8edd1b502fb82bfae3a6feb8be3a2b44fa/spring-boot-starter-web-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-data-jpa/1.3.5.RELEASE/32f4449a9de903ec4e4acd9c8f6af7c6a1309571/spring-boot-starter-data-jpa-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.m2/repository/com/google/guava/guava/18.0/guava-18.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.projectlombok/lombok/1.16.8/2ce9de13f277ec1600e7e04231477e3e5f59d317/lombok-1.16.8.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-databind/2.7.4/1e9c6f3659644aeac84872c3b62d8e363bf4c96d/jackson-databind-2.7.4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.datatype/jackson-datatype-jsr310/2.7.4/390dbf17d4eb29a6157c6b9dcd9c93e7acac714/jackson-datatype-jsr310-2.7.4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-annotations/2.7.4/84b2f8e53bd8a077d402bc99d9bce816c2b2d0f9/jackson-annotations-2.7.4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.liquibase/liquibase-core/3.5.0/85834c6c100768cfe6351ea5e9c4d27523472390/liquibase-core-3.5.0.jar, file:/Users/pszymczyk/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.kafka/kafka-streams/2.1.0/ab1d9cf35cf0040a804266279faeaf082d3f66c3/kafka-streams-2.1.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-test/1.3.5.RELEASE/5c485e918b58741eccc0012c70062df5e5efa106/spring-boot-starter-test-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.spockframework/spock-spring/1.0-groovy-2.4/a07c753a95114872cd753ce3ae9166b64284b31d/spock-spring-1.0-groovy-2.4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-context/4.2.6.RELEASE/bbf3c8526fe37bb341507f28db17882d4348dbca/spring-context-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/cglib/cglib-nodep/3.2.1/dbee35a2ff88d175e8a321adae1f62b58cfd8a79/cglib-nodep-3.2.1.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.h2database/h2/1.4.191/dec3540178ea889b2871b0ed56db14bbec9cfdfc/h2-1.4.191.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-messaging/4.2.6.RELEASE/f7b3f8f875e055295f6ed2e552187f25b55c6920/spring-messaging-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-tx/4.2.6.RELEASE/ba7502c0644414748b1eeb65b4193b05d335a110/spring-tx-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.m2/repository/org/codehaus/groovy/groovy/2.4.15/groovy-2.4.15.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.retry/spring-retry/1.1.2.RELEASE/949a23beb82ebe31d7a1d47022353b8338c4da11/spring-retry-1.1.2.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter/1.3.5.RELEASE/188c658fabbce0d1ccc1ae18a1cf58f566208c78/spring-boot-starter-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-tomcat/1.3.5.RELEASE/b4c6277ccec38c51716659886efec073c4b386ea/spring-boot-starter-tomcat-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-validation/1.3.5.RELEASE/c83a6cc60a95faace7e03c524d60fc9de1329f57/spring-boot-starter-validation-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-web/4.2.6.RELEASE/d5ce949da3f3266f118ed899a153413613b503ad/spring-web-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-webmvc/4.2.6.RELEASE/7c7ea475d33287e0e3a92e98ccbe0ad6a0dbb9ca/spring-webmvc-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-aop/1.3.5.RELEASE/478a50b44faab2ada75583637b9f6e789809d069/spring-boot-starter-aop-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-jdbc/1.3.5.RELEASE/b427aa14a4f3a2fba114bcbb60eae6f83ee86706/spring-boot-starter-jdbc-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.hibernate/hibernate-entitymanager/4.3.11.Final/27a119fcc2b91c50e5285dd11158fac2c38c9d1b/hibernate-entitymanager-4.3.11.Final.jar, file:/Users/pszymczyk/.m2/repository/javax/transaction/javax.transaction-api/1.2/javax.transaction-api-1.2.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.data/spring-data-jpa/1.9.4.RELEASE/80b83510e67aa085b7d91d2d096d90133ec995de/spring-data-jpa-1.9.4.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-aspects/4.2.6.RELEASE/7ed7b15e95eedd551ac979bd8c295256d96cf2ff/spring-aspects-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-core/2.6.6/2eb801df67aacaf5b1deb4ac626e1964508e47b/jackson-core-2.6.6.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.yaml/snakeyaml/1.16/d64fb662c9e42789149f5078a62a22edda786c6a/snakeyaml-1.16.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.kafka/connect-json/2.1.0/6e2b621686935ee93e3f627477fcf7483769953d/connect-json-2.1.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-api/1.7.21/139535a69a4239db087de9bab0bee568bf8e0b70/slf4j-api-1.7.21.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.rocksdb/rocksdbjni/5.14.2/a6087318fab540ba0b4c6ff68475ffbedc0b3d10/rocksdbjni-5.14.2.jar, file:/Users/pszymczyk/.m2/repository/junit/junit/4.12/junit-4.12.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.mockito/mockito-core/1.10.19/e8546f5bef4e061d8dd73895b4e8f40e3fe6effe/mockito-core-1.10.19.jar, file:/Users/pszymczyk/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar, file:/Users/pszymczyk/.m2/repository/org/hamcrest/hamcrest-library/1.3/hamcrest-library-1.3.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-core/4.2.6.RELEASE/a1c6ef01f18888f51fc5054c65ef4787b7cf0a1e/spring-core-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-test/4.2.6.RELEASE/1f869333b3d64f17009a613368165978af575d8c/spring-test-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.spockframework/spock-core/1.0-groovy-2.4/ceaa8b69f274ed3de24da3e6a6c86f673b426d1a/spock-core-1.0-groovy-2.4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.codehaus.groovy/groovy-all/2.4.6/478feadca929a946b2f1fb962bb2179264759821/groovy-all-2.4.6.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-aop/4.2.6.RELEASE/5efbfccb19efda2956b8977561bf4da6b15b0d0e/spring-aop-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-beans/4.2.6.RELEASE/d4a319fb4d949fb6313f45c929947b9b4e26283e/spring-beans-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-expression/4.2.6.RELEASE/c0182d73f348ab11d51d45cbe29f3820c32d0ccc/spring-expression-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot/1.3.5.RELEASE/b218ba5f3bd01e657fbde9b085722da1fafa4f8a/spring-boot-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-autoconfigure/1.3.5.RELEASE/2bcfa86bb3afd95eff5252db6d78f2693b706997/spring-boot-autoconfigure-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-logging/1.3.5.RELEASE/a71e1d7fff512b1eadd3426ea1ce5b4cc703c429/spring-boot-starter-logging-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-core/8.0.33/4e7f547fbb2c364cb5e02a58790c5fb89e31efed/tomcat-embed-core-8.0.33.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-el/8.0.33/31423f2d493cf1f7cf5f0082c9f94640e93b8c1b/tomcat-embed-el-8.0.33.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-logging-juli/8.0.33/66bc309e0227c1ba2cf4417182d0b1583003d24b/tomcat-embed-logging-juli-8.0.33.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-websocket/8.0.33/be1f95e5d9ae00f9bc6138441d29cfe5c7c60256/tomcat-embed-websocket-8.0.33.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.hibernate/hibernate-validator/5.2.4.Final/fb18766b576aa6632bcfe9a20a023cbd52bf9769/hibernate-validator-5.2.4.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.aspectj/aspectjweaver/1.8.9/db28774f477f07220eac18d5ec9c4e01f48589d7/aspectjweaver-1.8.9.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat/tomcat-jdbc/8.0.33/7f1b6d609f9c2e045e8d7759e96605841fffdf82/tomcat-jdbc-8.0.33.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-jdbc/4.2.6.RELEASE/16075bfb0901a5b89c5be975365ff09b2df04abb/spring-jdbc-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.jboss.logging/jboss-logging/3.3.0.Final/3616bb87707910296e2c195dc016287080bba5af/jboss-logging-3.3.0.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.jboss.logging/jboss-logging-annotations/1.2.0.Beta1/2f437f37bb265d9f8f1392823dbca12d2bec06d6/jboss-logging-annotations-1.2.0.Beta1.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.hibernate/hibernate-core/4.3.11.Final/536ac0021240d97db99c7d2983067cef1a6f3af5/hibernate-core-4.3.11.Final.jar, file:/Users/pszymczyk/.m2/repository/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.hibernate.common/hibernate-commons-annotations/4.0.5.Final/2a581b9edb8168e45060d8bad8b7f46712d2c52c/hibernate-commons-annotations-4.0.5.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.hibernate.javax.persistence/hibernate-jpa-2.1-api/1.0.0.Final/5e731d961297e5a07290bfaf3db1fbc8bbbf405a/hibernate-jpa-2.1-api-1.0.0.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.javassist/javassist/3.18.1-GA/d9a09f7732226af26bf99f19e2cffe0ae219db5b/javassist-3.18.1-GA.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.data/spring-data-commons/1.11.4.RELEASE/c2b1fd4dbf7dff772d6124bb35892759e8bf088e/spring-data-commons-1.11.4.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-orm/4.2.6.RELEASE/2ef30e836028ebe4dbba0d8355929625a758ed8d/spring-orm-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.slf4j/jcl-over-slf4j/1.7.21/331b564a3a42f002a0004b039c1c430da89062cd/jcl-over-slf4j-1.7.21.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.kafka/connect-api/2.1.0/589e4d3a3f90446fd97059e4cc13975f01d9a1d0/connect-api-2.1.0.jar, file:/Users/pszymczyk/.m2/repository/org/objenesis/objenesis/2.1/objenesis-2.1.jar, file:/Users/pszymczyk/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/ch.qos.logback/logback-classic/1.1.7/9865cf6994f9ff13fce0bf93f2054ef6c65bb462/logback-classic-1.1.7.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.slf4j/jul-to-slf4j/1.7.21/2f22c882ffa479d1e9ff4eb0e8e2c29f2a0871ed/jul-to-slf4j-1.7.21.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.slf4j/log4j-over-slf4j/1.7.21/b3700d97464d99bdcd42c0177d6e7951c94d75ff/log4j-over-slf4j-1.7.21.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/javax.validation/validation-api/1.1.0.Final/8613ae82954779d518631e05daa73a6a954817d5/validation-api-1.1.0.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.fasterxml/classmate/1.1.0/dbbd699a1486ad0f2ed6f5af6cfed66acacb9056/classmate-1.1.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat/tomcat-juli/8.0.33/330aecfa895156cea91c576cb6609537152761f9/tomcat-juli-8.0.33.jar, file:/Users/pszymczyk/.m2/repository/antlr/antlr/2.7.7/antlr-2.7.7.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.jboss/jandex/1.1.0.Final/e84a2122e76f0b6503be78094ddf2108057ac15f/jandex-1.1.0.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/xml-apis/xml-apis/1.0.b2/3136ca936f64c9d68529f048c2618bd356bf85c9/xml-apis-1.0.b2.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/javax.ws.rs/javax.ws.rs-api/2.1.1/d3466bc9321fe84f268a1adb3b90373fc14b0eb5/javax.ws.rs-api-2.1.1.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/ch.qos.logback/logback-core/1.1.7/7873092d39ef741575ca91378a6a21c388363ac8/logback-core-1.1.7.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.kafka/kafka-clients/2.1.0/34d9983705c953b97abb01e1cd04647f47272fe5/kafka-clients-2.1.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.github.luben/zstd-jni/1.3.5-4/550b6393a007d0867c98611ca8cfbcf53f2eb991/zstd-jni-1.3.5-4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.lz4/lz4-java/1.5.0/d36fb639f06aaa4f17307625f80e2e32f815672a/lz4-java-1.5.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.xerial.snappy/snappy-java/1.1.7.2/307b286efd119ad2c6d4291128bf110bddc68088/snappy-java-1.1.7.2.jar, file:/Applications/IntelliJ%20IDEA.app/Contents/lib/idea_rt.jar]
2018-12-15 17:45:21,386 ERROR main  org.springframework.test.context.TestContextManager - Caught exception while allowing TestExecutionListener [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1] to prepare test instance [io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec@7d0333c8]
java.lang.IllegalStateException: Failed to load ApplicationContext
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:124)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'shopItems' defined in file [/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/production/classes/io/dddbyexamples/eventsource/boundary/ShopItems.class]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.dddbyexamples.eventsource.boundary.ShopItems]: Constructor threw exception; nested exception is org.apache.kafka.common.errors.SerializationException: Error deserializing key/value for partition shop-items-0 at offset 118. If needed, please seek past the record to continue consumption.
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:275)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	... 36 common frames omitted
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.dddbyexamples.eventsource.boundary.ShopItems]: Constructor threw exception; nested exception is org.apache.kafka.common.errors.SerializationException: Error deserializing key/value for partition shop-items-0 at offset 118. If needed, please seek past the record to continue consumption.
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:163)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	... 53 common frames omitted
Caused by: org.apache.kafka.common.errors.SerializationException: Error deserializing key/value for partition shop-items-0 at offset 118. If needed, please seek past the record to continue consumption.
Caused by: org.apache.kafka.common.errors.SerializationException: Can't deserialize data [[123, 34, 116, 121, 112, 101, 34, 58, 34, 105, 116, 101, 109, 46, 98, 111, 117, 103, 104, 116, 34, 44, 34, 117, 117, 105, 100, 34, 58, 34, 55, 54, 50, 53, 97, 53, 98, 102, 45, 50, 55, 50, 48, 45, 52, 98, 51, 99, 45, 98, 56, 53, 54, 45, 55, 97, 48, 55, 97, 57, 54, 99, 100, 48, 97, 101, 34, 44, 34, 119, 104, 101, 110, 34, 58, 49, 53, 52, 52, 56, 50, 50, 57, 54, 55, 46, 48, 49, 56, 48, 48, 48, 48, 48, 48, 44, 34, 112, 97, 121, 109, 101, 110, 116, 84, 105, 109, 101, 111, 117, 116, 68, 97, 116, 101, 34, 58, 49, 53, 52, 52, 57, 48, 57, 51, 54, 55, 46, 48, 49, 56, 48, 48, 48, 48, 48, 48, 125]] from topic [shop-items]
Caused by: com.fasterxml.jackson.databind.JsonMappingException: Could not resolve type id 'item.bought' into a subtype of [simple type, class io.dddbyexamples.eventsource.domain.shopitem.commands.Command]: known type ids = [Command, MarkPaymentTimeout, Pay, buy]
 at [Source: [B@2a191f83; line: 1, column: 2]
	at com.fasterxml.jackson.databind.JsonMappingException.from(JsonMappingException.java:255)
	at com.fasterxml.jackson.databind.DeserializationContext.unknownTypeException(DeserializationContext.java:1082)
	at com.fasterxml.jackson.databind.jsontype.impl.TypeDeserializerBase._handleUnknownTypeId(TypeDeserializerBase.java:281)
	at com.fasterxml.jackson.databind.jsontype.impl.TypeDeserializerBase._findDeserializer(TypeDeserializerBase.java:163)
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer._deserializeTypedForId(AsPropertyTypeDeserializer.java:106)
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromObject(AsPropertyTypeDeserializer.java:91)
	at com.fasterxml.jackson.databind.deser.AbstractDeserializer.deserializeWithType(AbstractDeserializer.java:142)
	at com.fasterxml.jackson.databind.deser.impl.TypeWrappedDeserializer.deserialize(TypeWrappedDeserializer.java:42)
	at com.fasterxml.jackson.databind.ObjectReader._bindAndClose(ObjectReader.java:1578)
	at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1217)
	at org.springframework.kafka.support.serializer.JsonDeserializer.deserialize(JsonDeserializer.java:328)
	at org.apache.kafka.clients.consumer.internals.Fetcher.parseRecord(Fetcher.java:1027)
	at org.apache.kafka.clients.consumer.internals.Fetcher.access$3300(Fetcher.java:110)
	at org.apache.kafka.clients.consumer.internals.Fetcher$PartitionRecords.fetchRecords(Fetcher.java:1247)
	at org.apache.kafka.clients.consumer.internals.Fetcher$PartitionRecords.access$1400(Fetcher.java:1096)
	at org.apache.kafka.clients.consumer.internals.Fetcher.fetchRecords(Fetcher.java:544)
	at org.apache.kafka.clients.consumer.internals.Fetcher.fetchedRecords(Fetcher.java:505)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollForFetches(KafkaConsumer.java:1256)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1188)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1123)
	at io.dddbyexamples.eventsource.boundary.ShopItems.proceedBuy(ShopItems.java:94)
	at io.dddbyexamples.eventsource.boundary.ShopItems.<init>(ShopItems.java:88)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 17:46:17,348 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 17:46:17,361 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 17:46:17,373 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ae42ce3, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4f5991f6, org.springframework.test.context.support.DirtiesContextTestExecutionListener@484094a5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@38234a38, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@63fbfaeb]
2018-12-15 17:46:18,122 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 10554 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 17:46:18,123 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 17:46:18,182 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 17:46:18 CET 2018]; root of context hierarchy
2018-12-15 17:46:18,572 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 17:46:19,258 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$2ad7275e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 17:46:20,529 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 17:46:20,536 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 17:46:20,594 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 17:46:20,595 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 17:46:20,597 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 17:46:20,749 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 17:46:20,797 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 17:46:20,919 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 17:46:21,113 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 17:46:21,120 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 17:46:21,652 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 17:46:21,682 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 17:46:21,730 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:46:21,730 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:46:21,737 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 17:46:21,739 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 17:46:21,776 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:46:21,776 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:46:21,777 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 17:46:21,779 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 17:46:21,801 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:46:21,801 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:46:21,808 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 17:46:21,810 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 17:46:21,818 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 17:46:21,818 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:46:21,818 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:46:21,829 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 17:46:21,835 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 17:46:21,837 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:46:21,837 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:46:21,838 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 17:46:21,839 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 17:46:21,841 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:46:21,841 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:46:21,843 WARN main  org.apache.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=my-client-id
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:62)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:425)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:316)
	at io.dddbyexamples.eventsource.boundary.ShopItems.createCommandProducer(ShopItems.java:130)
	at io.dddbyexamples.eventsource.boundary.ShopItems.<init>(ShopItems.java:83)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 17:46:21,844 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-15 17:46:21,849 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:46:21,849 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:46:21,851 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-15 17:46:22,102 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 42
2018-12-15 17:46:22,112 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 17:46:22,113 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 17:46:22,114 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Revoking previously assigned partitions []
2018-12-15 17:46:22,115 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] (Re-)joining group
2018-12-15 17:46:22,125 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Successfully joined group with generation 13
2018-12-15 17:46:22,127 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Setting newly assigned partitions [shop-items-commands-0]
2018-12-15 17:46:22,136 INFO main  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Resetting offset for partition shop-items-commands-0 to offset 0.
2018-12-15 17:48:08,792 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 17:48:08,811 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 17:48:08,831 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@47a64f7d, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@33d05366, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@27a0a5a2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@7692cd34, org.springframework.test.context.transaction.TransactionalTestExecutionListener@33aa93c, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@32c0915e]
2018-12-15 17:48:09,700 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11091 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 17:48:09,701 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 17:48:09,772 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@279dd959: startup date [Sat Dec 15 17:48:09 CET 2018]; root of context hierarchy
2018-12-15 17:48:10,232 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 17:48:11,015 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$49970fda] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 17:48:12,600 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 17:48:12,612 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 17:48:12,705 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 17:48:12,707 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 17:48:12,709 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 17:48:12,922 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 17:48:12,997 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 17:48:13,112 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 17:48:13,349 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 17:48:13,357 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 17:48:14,020 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 17:48:14,052 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 17:48:14,101 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:48:14,101 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:48:14,107 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 17:48:14,109 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 17:48:14,147 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:48:14,147 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:48:14,149 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 17:48:14,151 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 17:48:14,172 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:48:14,173 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:48:14,181 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 17:48:14,182 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 17:48:14,192 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 17:48:14,193 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:48:14,193 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:48:14,206 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 17:48:14,212 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 17:48:14,215 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:48:14,215 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:48:14,216 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 17:48:14,217 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 17:48:14,220 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:48:14,220 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:48:14,223 WARN main  org.apache.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=my-client-id
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:62)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:425)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:316)
	at io.dddbyexamples.eventsource.boundary.ShopItems.createCommandProducer(ShopItems.java:130)
	at io.dddbyexamples.eventsource.boundary.ShopItems.<init>(ShopItems.java:83)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 17:48:14,223 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-15 17:48:14,228 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:48:14,228 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:48:14,230 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-15 17:48:14,508 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 43
2018-12-15 17:48:14,520 INFO main  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 17:48:14,520 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 17:48:14,522 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Revoking previously assigned partitions []
2018-12-15 17:48:14,522 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] (Re-)joining group
2018-12-15 17:48:14,533 INFO main  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Successfully joined group with generation 15
2018-12-15 17:48:14,535 INFO main  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Setting newly assigned partitions [shop-items-commands-0]
2018-12-15 17:48:14,544 INFO main  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Resetting offset for partition shop-items-commands-0 to offset 0.
2018-12-15 17:57:03,822 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 17:57:03,835 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 17:57:03,847 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@10a9d961, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@130e116b, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@e383572, org.springframework.test.context.support.DirtiesContextTestExecutionListener@5ddf0d24, org.springframework.test.context.transaction.TransactionalTestExecutionListener@363a52f, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@60856961]
2018-12-15 17:57:04,627 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11108 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 17:57:04,628 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 17:57:04,687 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@3f92c349: startup date [Sat Dec 15 17:57:04 CET 2018]; root of context hierarchy
2018-12-15 17:57:05,089 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 17:57:05,825 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$d9fed76f] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 17:57:07,134 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 17:57:07,141 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 17:57:07,199 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 17:57:07,201 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 17:57:07,202 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 17:57:07,351 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 17:57:07,397 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 17:57:07,518 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 17:57:07,727 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 17:57:07,734 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 17:57:08,241 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 17:57:08,266 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 17:57:08,308 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:57:08,308 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:57:08,313 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 17:57:08,316 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 17:57:08,348 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:57:08,348 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:57:08,349 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 17:57:08,351 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 17:57:08,369 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:57:08,369 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:57:08,375 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 17:57:08,377 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 17:57:08,384 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 17:57:08,384 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:57:08,384 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:57:08,389 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Starting
2018-12-15 17:57:08,389 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to RUNNING
2018-12-15 17:57:08,390 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 17:57:08,396 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 17:57:08,401 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 17:57:08,403 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:57:08,404 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:57:08,425 WARN main  org.springframework.web.context.support.GenericWebApplicationContext - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'commandsProcessor' defined in file [/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/production/classes/io/dddbyexamples/eventsource/kafka/CommandsProcessor.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.dddbyexamples.eventsource.kafka.CommandsProcessor]: Constructor threw exception; nested exception is java.lang.NullPointerException
2018-12-15 17:57:08,425 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 17:57:08,426 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Informed to shut down
2018-12-15 17:57:08,426 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 17:57:08,467 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 17:57:08,468 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 17:57:08,474 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Revoking previously assigned partitions []
2018-12-15 17:57:08,475 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] (Re-)joining group
2018-12-15 17:57:08,646 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wordcount-lambda-example-client-StreamThread-1-consumer] Assigned tasks to clients as {0580caa6-9985-4c5b-99ad-9895e0eb94ae=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) assignedTasks: ([0_0, 1_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2018-12-15 17:57:08,648 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] The following not-subscribed topics are assigned, and their metadata will be fetched from the brokers: [wordcount-lambda-example-shop-items-store-repartition]
2018-12-15 17:57:08,653 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutting down
2018-12-15 17:57:08,654 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 17:57:08,654 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=wordcount-lambda-example-client-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-12-15 17:57:08,658 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Successfully joined group with generation 1
2018-12-15 17:57:08,665 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2018-12-15 17:57:08,665 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutdown complete
2018-12-15 17:57:08,667 INFO kafka-streams-close-thread  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from PENDING_SHUTDOWN to NOT_RUNNING
2018-12-15 17:57:08,667 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Streams client stopped completely
2018-12-15 17:57:08,668 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-15 17:57:08,669 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 17:57:08,673 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 17:57:08,680 ERROR main  org.springframework.boot.SpringApplication - Application startup failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'commandsProcessor' defined in file [/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/production/classes/io/dddbyexamples/eventsource/kafka/CommandsProcessor.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.dddbyexamples.eventsource.kafka.CommandsProcessor]: Constructor threw exception; nested exception is java.lang.NullPointerException
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1105)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1050)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.dddbyexamples.eventsource.kafka.CommandsProcessor]: Constructor threw exception; nested exception is java.lang.NullPointerException
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:163)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:89)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1098)
	... 52 common frames omitted
Caused by: java.lang.NullPointerException: null
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.createConsumer(CommandsProcessor.java:70)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>(CommandsProcessor.java:56)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	... 54 common frames omitted
2018-12-15 17:57:08,682 INFO main  org.springframework.boot.logging.ClasspathLoggingApplicationListener - Application failed to start with classpath: [file:/Applications/IntelliJ%20IDEA.app/Contents/lib/idea_rt.jar, file:/Applications/IntelliJ%20IDEA.app/Contents/plugins/junit/lib/junit-rt.jar, file:/Applications/IntelliJ%20IDEA.app/Contents/plugins/junit/lib/junit5-rt.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/charsets.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/deploy.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/cldrdata.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/dnsns.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/jaccess.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/jfxrt.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/localedata.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/nashorn.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/sunec.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/zipfs.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/javaws.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/jce.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/jfr.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/jfxswt.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/jsse.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/management-agent.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/plugin.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/resources.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/rt.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/ant-javafx.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/dt.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/javafx-mx.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/jconsole.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/packager.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/sa-jdi.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/tools.jar, file:/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes/, file:/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/resources/, file:/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/production/classes/, file:/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/production/resources/, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.kafka/spring-kafka/2.2.2.RELEASE/9b8d0fee9997197e80011c518f2f7fe1d95bb761/spring-kafka-2.2.2.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-web/1.3.5.RELEASE/1ad40f8edd1b502fb82bfae3a6feb8be3a2b44fa/spring-boot-starter-web-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-data-jpa/1.3.5.RELEASE/32f4449a9de903ec4e4acd9c8f6af7c6a1309571/spring-boot-starter-data-jpa-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.m2/repository/com/google/guava/guava/18.0/guava-18.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.projectlombok/lombok/1.16.8/2ce9de13f277ec1600e7e04231477e3e5f59d317/lombok-1.16.8.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-databind/2.7.4/1e9c6f3659644aeac84872c3b62d8e363bf4c96d/jackson-databind-2.7.4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.datatype/jackson-datatype-jsr310/2.7.4/390dbf17d4eb29a6157c6b9dcd9c93e7acac714/jackson-datatype-jsr310-2.7.4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-annotations/2.7.4/84b2f8e53bd8a077d402bc99d9bce816c2b2d0f9/jackson-annotations-2.7.4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.liquibase/liquibase-core/3.5.0/85834c6c100768cfe6351ea5e9c4d27523472390/liquibase-core-3.5.0.jar, file:/Users/pszymczyk/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.kafka/kafka-streams/2.1.0/ab1d9cf35cf0040a804266279faeaf082d3f66c3/kafka-streams-2.1.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-test/1.3.5.RELEASE/5c485e918b58741eccc0012c70062df5e5efa106/spring-boot-starter-test-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.spockframework/spock-spring/1.0-groovy-2.4/a07c753a95114872cd753ce3ae9166b64284b31d/spock-spring-1.0-groovy-2.4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-context/4.2.6.RELEASE/bbf3c8526fe37bb341507f28db17882d4348dbca/spring-context-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/cglib/cglib-nodep/3.2.1/dbee35a2ff88d175e8a321adae1f62b58cfd8a79/cglib-nodep-3.2.1.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.h2database/h2/1.4.191/dec3540178ea889b2871b0ed56db14bbec9cfdfc/h2-1.4.191.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-messaging/4.2.6.RELEASE/f7b3f8f875e055295f6ed2e552187f25b55c6920/spring-messaging-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-tx/4.2.6.RELEASE/ba7502c0644414748b1eeb65b4193b05d335a110/spring-tx-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.m2/repository/org/codehaus/groovy/groovy/2.4.15/groovy-2.4.15.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.retry/spring-retry/1.1.2.RELEASE/949a23beb82ebe31d7a1d47022353b8338c4da11/spring-retry-1.1.2.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter/1.3.5.RELEASE/188c658fabbce0d1ccc1ae18a1cf58f566208c78/spring-boot-starter-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-tomcat/1.3.5.RELEASE/b4c6277ccec38c51716659886efec073c4b386ea/spring-boot-starter-tomcat-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-validation/1.3.5.RELEASE/c83a6cc60a95faace7e03c524d60fc9de1329f57/spring-boot-starter-validation-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-web/4.2.6.RELEASE/d5ce949da3f3266f118ed899a153413613b503ad/spring-web-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-webmvc/4.2.6.RELEASE/7c7ea475d33287e0e3a92e98ccbe0ad6a0dbb9ca/spring-webmvc-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-aop/1.3.5.RELEASE/478a50b44faab2ada75583637b9f6e789809d069/spring-boot-starter-aop-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-jdbc/1.3.5.RELEASE/b427aa14a4f3a2fba114bcbb60eae6f83ee86706/spring-boot-starter-jdbc-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.hibernate/hibernate-entitymanager/4.3.11.Final/27a119fcc2b91c50e5285dd11158fac2c38c9d1b/hibernate-entitymanager-4.3.11.Final.jar, file:/Users/pszymczyk/.m2/repository/javax/transaction/javax.transaction-api/1.2/javax.transaction-api-1.2.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.data/spring-data-jpa/1.9.4.RELEASE/80b83510e67aa085b7d91d2d096d90133ec995de/spring-data-jpa-1.9.4.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-aspects/4.2.6.RELEASE/7ed7b15e95eedd551ac979bd8c295256d96cf2ff/spring-aspects-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-core/2.6.6/2eb801df67aacaf5b1deb4ac626e1964508e47b/jackson-core-2.6.6.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.yaml/snakeyaml/1.16/d64fb662c9e42789149f5078a62a22edda786c6a/snakeyaml-1.16.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.kafka/connect-json/2.1.0/6e2b621686935ee93e3f627477fcf7483769953d/connect-json-2.1.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-api/1.7.21/139535a69a4239db087de9bab0bee568bf8e0b70/slf4j-api-1.7.21.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.rocksdb/rocksdbjni/5.14.2/a6087318fab540ba0b4c6ff68475ffbedc0b3d10/rocksdbjni-5.14.2.jar, file:/Users/pszymczyk/.m2/repository/junit/junit/4.12/junit-4.12.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.mockito/mockito-core/1.10.19/e8546f5bef4e061d8dd73895b4e8f40e3fe6effe/mockito-core-1.10.19.jar, file:/Users/pszymczyk/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar, file:/Users/pszymczyk/.m2/repository/org/hamcrest/hamcrest-library/1.3/hamcrest-library-1.3.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-core/4.2.6.RELEASE/a1c6ef01f18888f51fc5054c65ef4787b7cf0a1e/spring-core-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-test/4.2.6.RELEASE/1f869333b3d64f17009a613368165978af575d8c/spring-test-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.spockframework/spock-core/1.0-groovy-2.4/ceaa8b69f274ed3de24da3e6a6c86f673b426d1a/spock-core-1.0-groovy-2.4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.codehaus.groovy/groovy-all/2.4.6/478feadca929a946b2f1fb962bb2179264759821/groovy-all-2.4.6.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-aop/4.2.6.RELEASE/5efbfccb19efda2956b8977561bf4da6b15b0d0e/spring-aop-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-beans/4.2.6.RELEASE/d4a319fb4d949fb6313f45c929947b9b4e26283e/spring-beans-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-expression/4.2.6.RELEASE/c0182d73f348ab11d51d45cbe29f3820c32d0ccc/spring-expression-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot/1.3.5.RELEASE/b218ba5f3bd01e657fbde9b085722da1fafa4f8a/spring-boot-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-autoconfigure/1.3.5.RELEASE/2bcfa86bb3afd95eff5252db6d78f2693b706997/spring-boot-autoconfigure-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-logging/1.3.5.RELEASE/a71e1d7fff512b1eadd3426ea1ce5b4cc703c429/spring-boot-starter-logging-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-core/8.0.33/4e7f547fbb2c364cb5e02a58790c5fb89e31efed/tomcat-embed-core-8.0.33.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-el/8.0.33/31423f2d493cf1f7cf5f0082c9f94640e93b8c1b/tomcat-embed-el-8.0.33.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-logging-juli/8.0.33/66bc309e0227c1ba2cf4417182d0b1583003d24b/tomcat-embed-logging-juli-8.0.33.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-websocket/8.0.33/be1f95e5d9ae00f9bc6138441d29cfe5c7c60256/tomcat-embed-websocket-8.0.33.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.hibernate/hibernate-validator/5.2.4.Final/fb18766b576aa6632bcfe9a20a023cbd52bf9769/hibernate-validator-5.2.4.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.aspectj/aspectjweaver/1.8.9/db28774f477f07220eac18d5ec9c4e01f48589d7/aspectjweaver-1.8.9.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat/tomcat-jdbc/8.0.33/7f1b6d609f9c2e045e8d7759e96605841fffdf82/tomcat-jdbc-8.0.33.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-jdbc/4.2.6.RELEASE/16075bfb0901a5b89c5be975365ff09b2df04abb/spring-jdbc-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.jboss.logging/jboss-logging/3.3.0.Final/3616bb87707910296e2c195dc016287080bba5af/jboss-logging-3.3.0.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.jboss.logging/jboss-logging-annotations/1.2.0.Beta1/2f437f37bb265d9f8f1392823dbca12d2bec06d6/jboss-logging-annotations-1.2.0.Beta1.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.hibernate/hibernate-core/4.3.11.Final/536ac0021240d97db99c7d2983067cef1a6f3af5/hibernate-core-4.3.11.Final.jar, file:/Users/pszymczyk/.m2/repository/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.hibernate.common/hibernate-commons-annotations/4.0.5.Final/2a581b9edb8168e45060d8bad8b7f46712d2c52c/hibernate-commons-annotations-4.0.5.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.hibernate.javax.persistence/hibernate-jpa-2.1-api/1.0.0.Final/5e731d961297e5a07290bfaf3db1fbc8bbbf405a/hibernate-jpa-2.1-api-1.0.0.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.javassist/javassist/3.18.1-GA/d9a09f7732226af26bf99f19e2cffe0ae219db5b/javassist-3.18.1-GA.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.data/spring-data-commons/1.11.4.RELEASE/c2b1fd4dbf7dff772d6124bb35892759e8bf088e/spring-data-commons-1.11.4.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-orm/4.2.6.RELEASE/2ef30e836028ebe4dbba0d8355929625a758ed8d/spring-orm-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.slf4j/jcl-over-slf4j/1.7.21/331b564a3a42f002a0004b039c1c430da89062cd/jcl-over-slf4j-1.7.21.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.kafka/connect-api/2.1.0/589e4d3a3f90446fd97059e4cc13975f01d9a1d0/connect-api-2.1.0.jar, file:/Users/pszymczyk/.m2/repository/org/objenesis/objenesis/2.1/objenesis-2.1.jar, file:/Users/pszymczyk/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/ch.qos.logback/logback-classic/1.1.7/9865cf6994f9ff13fce0bf93f2054ef6c65bb462/logback-classic-1.1.7.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.slf4j/jul-to-slf4j/1.7.21/2f22c882ffa479d1e9ff4eb0e8e2c29f2a0871ed/jul-to-slf4j-1.7.21.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.slf4j/log4j-over-slf4j/1.7.21/b3700d97464d99bdcd42c0177d6e7951c94d75ff/log4j-over-slf4j-1.7.21.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/javax.validation/validation-api/1.1.0.Final/8613ae82954779d518631e05daa73a6a954817d5/validation-api-1.1.0.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.fasterxml/classmate/1.1.0/dbbd699a1486ad0f2ed6f5af6cfed66acacb9056/classmate-1.1.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat/tomcat-juli/8.0.33/330aecfa895156cea91c576cb6609537152761f9/tomcat-juli-8.0.33.jar, file:/Users/pszymczyk/.m2/repository/antlr/antlr/2.7.7/antlr-2.7.7.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.jboss/jandex/1.1.0.Final/e84a2122e76f0b6503be78094ddf2108057ac15f/jandex-1.1.0.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/xml-apis/xml-apis/1.0.b2/3136ca936f64c9d68529f048c2618bd356bf85c9/xml-apis-1.0.b2.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/javax.ws.rs/javax.ws.rs-api/2.1.1/d3466bc9321fe84f268a1adb3b90373fc14b0eb5/javax.ws.rs-api-2.1.1.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/ch.qos.logback/logback-core/1.1.7/7873092d39ef741575ca91378a6a21c388363ac8/logback-core-1.1.7.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.kafka/kafka-clients/2.1.0/34d9983705c953b97abb01e1cd04647f47272fe5/kafka-clients-2.1.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.github.luben/zstd-jni/1.3.5-4/550b6393a007d0867c98611ca8cfbcf53f2eb991/zstd-jni-1.3.5-4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.lz4/lz4-java/1.5.0/d36fb639f06aaa4f17307625f80e2e32f815672a/lz4-java-1.5.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.xerial.snappy/snappy-java/1.1.7.2/307b286efd119ad2c6d4291128bf110bddc68088/snappy-java-1.1.7.2.jar, file:/Applications/IntelliJ%20IDEA.app/Contents/lib/idea_rt.jar]
2018-12-15 17:57:08,683 ERROR main  org.springframework.test.context.TestContextManager - Caught exception while allowing TestExecutionListener [org.springframework.test.context.web.ServletTestExecutionListener@10a9d961] to prepare test instance [io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec@b889cb6]
java.lang.IllegalStateException: Failed to load ApplicationContext
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:124)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'commandsProcessor' defined in file [/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/production/classes/io/dddbyexamples/eventsource/kafka/CommandsProcessor.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.dddbyexamples.eventsource.kafka.CommandsProcessor]: Constructor threw exception; nested exception is java.lang.NullPointerException
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1105)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1050)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	... 36 common frames omitted
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.dddbyexamples.eventsource.kafka.CommandsProcessor]: Constructor threw exception; nested exception is java.lang.NullPointerException
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:163)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:89)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1098)
	... 52 common frames omitted
Caused by: java.lang.NullPointerException: null
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.createConsumer(CommandsProcessor.java:70)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>(CommandsProcessor.java:56)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	... 54 common frames omitted
2018-12-15 17:57:08,808 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11108 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 17:57:08,808 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 17:57:08,810 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@4b4228cf: startup date [Sat Dec 15 17:57:08 CET 2018]; root of context hierarchy
2018-12-15 17:57:09,198 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$d9fed76f] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 17:57:09,479 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 17:57:09,480 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 17:57:09,487 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 17:57:09,490 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 17:57:09,503 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 17:57:09,509 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 17:57:09,579 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 17:57:09,579 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 17:57:09,581 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:57:09,581 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:57:09,582 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-2] Creating restore consumer client
2018-12-15 17:57:09,582 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-2-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 17:57:09,586 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:57:09,587 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:57:09,587 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-2] Creating shared producer client
2018-12-15 17:57:09,587 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-2-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 17:57:09,590 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:57:09,590 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:57:09,591 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-2] Creating consumer client
2018-12-15 17:57:09,591 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-2-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 17:57:09,594 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 17:57:09,594 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:57:09,594 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:57:09,595 INFO wordcount-lambda-example-client-StreamThread-2  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-2] Starting
2018-12-15 17:57:09,595 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 17:57:09,596 INFO wordcount-lambda-example-client-StreamThread-2  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-2] State transition from CREATED to RUNNING
2018-12-15 17:57:09,601 INFO wordcount-lambda-example-client-StreamThread-2  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 17:57:09,601 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 17:57:09,602 INFO wordcount-lambda-example-client-StreamThread-2  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-2-consumer, groupId=wordcount-lambda-example] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 17:57:09,602 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 17:57:09,606 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:57:09,606 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:57:09,606 WARN main  org.apache.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=my-client-id
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:62)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:425)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:316)
	at io.dddbyexamples.eventsource.boundary.ShopItems.createCommandProducer(ShopItems.java:90)
	at io.dddbyexamples.eventsource.boundary.ShopItems.<init>(ShopItems.java:77)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 17:57:09,609 INFO wordcount-lambda-example-client-StreamThread-2  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-2-consumer, groupId=wordcount-lambda-example] Revoking previously assigned partitions []
2018-12-15 17:57:09,609 INFO wordcount-lambda-example-client-StreamThread-2  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-2] State transition from RUNNING to PARTITIONS_REVOKED
2018-12-15 17:57:09,609 INFO wordcount-lambda-example-client-StreamThread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to REBALANCING
2018-12-15 17:57:09,609 INFO wordcount-lambda-example-client-StreamThread-2  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-2-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 17:57:09,609 INFO wordcount-lambda-example-client-StreamThread-2  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-2] partition revocation took 0 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-12-15 17:57:09,609 INFO wordcount-lambda-example-client-StreamThread-2  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-2-consumer, groupId=wordcount-lambda-example] (Re-)joining group
2018-12-15 17:57:09,610 WARN main  org.springframework.web.context.support.GenericWebApplicationContext - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'commandsProcessor' defined in file [/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/production/classes/io/dddbyexamples/eventsource/kafka/CommandsProcessor.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.dddbyexamples.eventsource.kafka.CommandsProcessor]: Constructor threw exception; nested exception is java.lang.NullPointerException
2018-12-15 17:57:09,610 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from REBALANCING to PENDING_SHUTDOWN
2018-12-15 17:57:09,611 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-2] Informed to shut down
2018-12-15 17:57:09,611 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-2] State transition from PARTITIONS_REVOKED to PENDING_SHUTDOWN
2018-12-15 17:57:09,700 INFO wordcount-lambda-example-client-StreamThread-2  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-2] Shutting down
2018-12-15 17:57:09,701 INFO wordcount-lambda-example-client-StreamThread-2  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-2-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 17:57:09,701 INFO wordcount-lambda-example-client-StreamThread-2  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=wordcount-lambda-example-client-StreamThread-2-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-12-15 17:57:35,577 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 17:57:35,591 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 17:57:35,608 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@47a64f7d, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@33d05366, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@27a0a5a2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@7692cd34, org.springframework.test.context.transaction.TransactionalTestExecutionListener@33aa93c, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@32c0915e]
2018-12-15 17:57:36,461 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11113 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 17:57:36,461 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 17:57:36,535 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@46383a78: startup date [Sat Dec 15 17:57:36 CET 2018]; root of context hierarchy
2018-12-15 17:57:36,991 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 17:57:37,922 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$631a50d9] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 17:57:39,665 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 17:57:39,675 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 17:57:39,759 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 17:57:39,762 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 17:57:39,764 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 17:57:39,941 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 17:57:39,997 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 17:57:40,123 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 17:57:40,420 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 17:57:40,428 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 17:57:41,067 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 17:57:41,101 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 17:57:41,156 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:57:41,156 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:57:41,163 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 17:57:41,166 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 17:57:41,208 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:57:41,208 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:57:41,210 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 17:57:41,212 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 17:57:41,236 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:57:41,236 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:57:41,245 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 17:57:41,247 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 17:57:41,258 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 17:57:41,258 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:57:41,258 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:57:41,264 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Starting
2018-12-15 17:57:41,264 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to RUNNING
2018-12-15 17:57:41,265 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 17:57:41,274 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 17:57:41,282 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 17:57:41,286 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:57:41,286 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:57:41,320 WARN main  org.springframework.web.context.support.GenericWebApplicationContext - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'commandsProcessor' defined in file [/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/production/classes/io/dddbyexamples/eventsource/kafka/CommandsProcessor.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.dddbyexamples.eventsource.kafka.CommandsProcessor]: Constructor threw exception; nested exception is java.lang.NullPointerException
2018-12-15 17:57:41,321 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 17:57:41,322 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Informed to shut down
2018-12-15 17:57:41,323 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 17:57:41,381 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutting down
2018-12-15 17:57:41,381 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 17:57:41,381 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=wordcount-lambda-example-client-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-12-15 17:57:41,393 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2018-12-15 17:57:41,393 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutdown complete
2018-12-15 17:57:41,397 INFO kafka-streams-close-thread  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from PENDING_SHUTDOWN to NOT_RUNNING
2018-12-15 17:57:41,397 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Streams client stopped completely
2018-12-15 17:57:41,398 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-15 17:57:41,398 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 17:57:41,402 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 17:57:41,409 ERROR main  org.springframework.boot.SpringApplication - Application startup failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'commandsProcessor' defined in file [/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/production/classes/io/dddbyexamples/eventsource/kafka/CommandsProcessor.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.dddbyexamples.eventsource.kafka.CommandsProcessor]: Constructor threw exception; nested exception is java.lang.NullPointerException
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1105)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1050)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.dddbyexamples.eventsource.kafka.CommandsProcessor]: Constructor threw exception; nested exception is java.lang.NullPointerException
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:163)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:89)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1098)
	... 52 common frames omitted
Caused by: java.lang.NullPointerException: null
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.createConsumer(CommandsProcessor.java:70)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>(CommandsProcessor.java:56)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	... 54 common frames omitted
2018-12-15 17:57:41,411 INFO main  org.springframework.boot.logging.ClasspathLoggingApplicationListener - Application failed to start with classpath: [file:/Applications/IntelliJ%20IDEA.app/Contents/lib/idea_rt.jar, file:/Applications/IntelliJ%20IDEA.app/Contents/plugins/junit/lib/junit-rt.jar, file:/Applications/IntelliJ%20IDEA.app/Contents/plugins/junit/lib/junit5-rt.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/charsets.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/deploy.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/cldrdata.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/dnsns.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/jaccess.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/jfxrt.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/localedata.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/nashorn.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/sunec.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/zipfs.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/javaws.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/jce.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/jfr.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/jfxswt.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/jsse.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/management-agent.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/plugin.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/resources.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/rt.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/ant-javafx.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/dt.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/javafx-mx.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/jconsole.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/packager.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/sa-jdi.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/tools.jar, file:/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes/, file:/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/resources/, file:/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/production/classes/, file:/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/production/resources/, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.kafka/spring-kafka/2.2.2.RELEASE/9b8d0fee9997197e80011c518f2f7fe1d95bb761/spring-kafka-2.2.2.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-web/1.3.5.RELEASE/1ad40f8edd1b502fb82bfae3a6feb8be3a2b44fa/spring-boot-starter-web-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-data-jpa/1.3.5.RELEASE/32f4449a9de903ec4e4acd9c8f6af7c6a1309571/spring-boot-starter-data-jpa-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.m2/repository/com/google/guava/guava/18.0/guava-18.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.projectlombok/lombok/1.16.8/2ce9de13f277ec1600e7e04231477e3e5f59d317/lombok-1.16.8.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-databind/2.7.4/1e9c6f3659644aeac84872c3b62d8e363bf4c96d/jackson-databind-2.7.4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.datatype/jackson-datatype-jsr310/2.7.4/390dbf17d4eb29a6157c6b9dcd9c93e7acac714/jackson-datatype-jsr310-2.7.4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-annotations/2.7.4/84b2f8e53bd8a077d402bc99d9bce816c2b2d0f9/jackson-annotations-2.7.4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.liquibase/liquibase-core/3.5.0/85834c6c100768cfe6351ea5e9c4d27523472390/liquibase-core-3.5.0.jar, file:/Users/pszymczyk/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.kafka/kafka-streams/2.1.0/ab1d9cf35cf0040a804266279faeaf082d3f66c3/kafka-streams-2.1.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-test/1.3.5.RELEASE/5c485e918b58741eccc0012c70062df5e5efa106/spring-boot-starter-test-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.spockframework/spock-spring/1.0-groovy-2.4/a07c753a95114872cd753ce3ae9166b64284b31d/spock-spring-1.0-groovy-2.4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-context/4.2.6.RELEASE/bbf3c8526fe37bb341507f28db17882d4348dbca/spring-context-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/cglib/cglib-nodep/3.2.1/dbee35a2ff88d175e8a321adae1f62b58cfd8a79/cglib-nodep-3.2.1.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.h2database/h2/1.4.191/dec3540178ea889b2871b0ed56db14bbec9cfdfc/h2-1.4.191.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-messaging/4.2.6.RELEASE/f7b3f8f875e055295f6ed2e552187f25b55c6920/spring-messaging-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-tx/4.2.6.RELEASE/ba7502c0644414748b1eeb65b4193b05d335a110/spring-tx-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.m2/repository/org/codehaus/groovy/groovy/2.4.15/groovy-2.4.15.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.retry/spring-retry/1.1.2.RELEASE/949a23beb82ebe31d7a1d47022353b8338c4da11/spring-retry-1.1.2.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter/1.3.5.RELEASE/188c658fabbce0d1ccc1ae18a1cf58f566208c78/spring-boot-starter-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-tomcat/1.3.5.RELEASE/b4c6277ccec38c51716659886efec073c4b386ea/spring-boot-starter-tomcat-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-validation/1.3.5.RELEASE/c83a6cc60a95faace7e03c524d60fc9de1329f57/spring-boot-starter-validation-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-web/4.2.6.RELEASE/d5ce949da3f3266f118ed899a153413613b503ad/spring-web-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-webmvc/4.2.6.RELEASE/7c7ea475d33287e0e3a92e98ccbe0ad6a0dbb9ca/spring-webmvc-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-aop/1.3.5.RELEASE/478a50b44faab2ada75583637b9f6e789809d069/spring-boot-starter-aop-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-jdbc/1.3.5.RELEASE/b427aa14a4f3a2fba114bcbb60eae6f83ee86706/spring-boot-starter-jdbc-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.hibernate/hibernate-entitymanager/4.3.11.Final/27a119fcc2b91c50e5285dd11158fac2c38c9d1b/hibernate-entitymanager-4.3.11.Final.jar, file:/Users/pszymczyk/.m2/repository/javax/transaction/javax.transaction-api/1.2/javax.transaction-api-1.2.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.data/spring-data-jpa/1.9.4.RELEASE/80b83510e67aa085b7d91d2d096d90133ec995de/spring-data-jpa-1.9.4.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-aspects/4.2.6.RELEASE/7ed7b15e95eedd551ac979bd8c295256d96cf2ff/spring-aspects-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-core/2.6.6/2eb801df67aacaf5b1deb4ac626e1964508e47b/jackson-core-2.6.6.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.yaml/snakeyaml/1.16/d64fb662c9e42789149f5078a62a22edda786c6a/snakeyaml-1.16.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.kafka/connect-json/2.1.0/6e2b621686935ee93e3f627477fcf7483769953d/connect-json-2.1.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-api/1.7.21/139535a69a4239db087de9bab0bee568bf8e0b70/slf4j-api-1.7.21.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.rocksdb/rocksdbjni/5.14.2/a6087318fab540ba0b4c6ff68475ffbedc0b3d10/rocksdbjni-5.14.2.jar, file:/Users/pszymczyk/.m2/repository/junit/junit/4.12/junit-4.12.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.mockito/mockito-core/1.10.19/e8546f5bef4e061d8dd73895b4e8f40e3fe6effe/mockito-core-1.10.19.jar, file:/Users/pszymczyk/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar, file:/Users/pszymczyk/.m2/repository/org/hamcrest/hamcrest-library/1.3/hamcrest-library-1.3.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-core/4.2.6.RELEASE/a1c6ef01f18888f51fc5054c65ef4787b7cf0a1e/spring-core-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-test/4.2.6.RELEASE/1f869333b3d64f17009a613368165978af575d8c/spring-test-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.spockframework/spock-core/1.0-groovy-2.4/ceaa8b69f274ed3de24da3e6a6c86f673b426d1a/spock-core-1.0-groovy-2.4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.codehaus.groovy/groovy-all/2.4.6/478feadca929a946b2f1fb962bb2179264759821/groovy-all-2.4.6.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-aop/4.2.6.RELEASE/5efbfccb19efda2956b8977561bf4da6b15b0d0e/spring-aop-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-beans/4.2.6.RELEASE/d4a319fb4d949fb6313f45c929947b9b4e26283e/spring-beans-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-expression/4.2.6.RELEASE/c0182d73f348ab11d51d45cbe29f3820c32d0ccc/spring-expression-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot/1.3.5.RELEASE/b218ba5f3bd01e657fbde9b085722da1fafa4f8a/spring-boot-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-autoconfigure/1.3.5.RELEASE/2bcfa86bb3afd95eff5252db6d78f2693b706997/spring-boot-autoconfigure-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-logging/1.3.5.RELEASE/a71e1d7fff512b1eadd3426ea1ce5b4cc703c429/spring-boot-starter-logging-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-core/8.0.33/4e7f547fbb2c364cb5e02a58790c5fb89e31efed/tomcat-embed-core-8.0.33.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-el/8.0.33/31423f2d493cf1f7cf5f0082c9f94640e93b8c1b/tomcat-embed-el-8.0.33.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-logging-juli/8.0.33/66bc309e0227c1ba2cf4417182d0b1583003d24b/tomcat-embed-logging-juli-8.0.33.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-websocket/8.0.33/be1f95e5d9ae00f9bc6138441d29cfe5c7c60256/tomcat-embed-websocket-8.0.33.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.hibernate/hibernate-validator/5.2.4.Final/fb18766b576aa6632bcfe9a20a023cbd52bf9769/hibernate-validator-5.2.4.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.aspectj/aspectjweaver/1.8.9/db28774f477f07220eac18d5ec9c4e01f48589d7/aspectjweaver-1.8.9.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat/tomcat-jdbc/8.0.33/7f1b6d609f9c2e045e8d7759e96605841fffdf82/tomcat-jdbc-8.0.33.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-jdbc/4.2.6.RELEASE/16075bfb0901a5b89c5be975365ff09b2df04abb/spring-jdbc-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.jboss.logging/jboss-logging/3.3.0.Final/3616bb87707910296e2c195dc016287080bba5af/jboss-logging-3.3.0.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.jboss.logging/jboss-logging-annotations/1.2.0.Beta1/2f437f37bb265d9f8f1392823dbca12d2bec06d6/jboss-logging-annotations-1.2.0.Beta1.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.hibernate/hibernate-core/4.3.11.Final/536ac0021240d97db99c7d2983067cef1a6f3af5/hibernate-core-4.3.11.Final.jar, file:/Users/pszymczyk/.m2/repository/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.hibernate.common/hibernate-commons-annotations/4.0.5.Final/2a581b9edb8168e45060d8bad8b7f46712d2c52c/hibernate-commons-annotations-4.0.5.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.hibernate.javax.persistence/hibernate-jpa-2.1-api/1.0.0.Final/5e731d961297e5a07290bfaf3db1fbc8bbbf405a/hibernate-jpa-2.1-api-1.0.0.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.javassist/javassist/3.18.1-GA/d9a09f7732226af26bf99f19e2cffe0ae219db5b/javassist-3.18.1-GA.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.data/spring-data-commons/1.11.4.RELEASE/c2b1fd4dbf7dff772d6124bb35892759e8bf088e/spring-data-commons-1.11.4.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-orm/4.2.6.RELEASE/2ef30e836028ebe4dbba0d8355929625a758ed8d/spring-orm-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.slf4j/jcl-over-slf4j/1.7.21/331b564a3a42f002a0004b039c1c430da89062cd/jcl-over-slf4j-1.7.21.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.kafka/connect-api/2.1.0/589e4d3a3f90446fd97059e4cc13975f01d9a1d0/connect-api-2.1.0.jar, file:/Users/pszymczyk/.m2/repository/org/objenesis/objenesis/2.1/objenesis-2.1.jar, file:/Users/pszymczyk/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/ch.qos.logback/logback-classic/1.1.7/9865cf6994f9ff13fce0bf93f2054ef6c65bb462/logback-classic-1.1.7.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.slf4j/jul-to-slf4j/1.7.21/2f22c882ffa479d1e9ff4eb0e8e2c29f2a0871ed/jul-to-slf4j-1.7.21.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.slf4j/log4j-over-slf4j/1.7.21/b3700d97464d99bdcd42c0177d6e7951c94d75ff/log4j-over-slf4j-1.7.21.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/javax.validation/validation-api/1.1.0.Final/8613ae82954779d518631e05daa73a6a954817d5/validation-api-1.1.0.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.fasterxml/classmate/1.1.0/dbbd699a1486ad0f2ed6f5af6cfed66acacb9056/classmate-1.1.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat/tomcat-juli/8.0.33/330aecfa895156cea91c576cb6609537152761f9/tomcat-juli-8.0.33.jar, file:/Users/pszymczyk/.m2/repository/antlr/antlr/2.7.7/antlr-2.7.7.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.jboss/jandex/1.1.0.Final/e84a2122e76f0b6503be78094ddf2108057ac15f/jandex-1.1.0.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/xml-apis/xml-apis/1.0.b2/3136ca936f64c9d68529f048c2618bd356bf85c9/xml-apis-1.0.b2.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/javax.ws.rs/javax.ws.rs-api/2.1.1/d3466bc9321fe84f268a1adb3b90373fc14b0eb5/javax.ws.rs-api-2.1.1.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/ch.qos.logback/logback-core/1.1.7/7873092d39ef741575ca91378a6a21c388363ac8/logback-core-1.1.7.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.kafka/kafka-clients/2.1.0/34d9983705c953b97abb01e1cd04647f47272fe5/kafka-clients-2.1.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.github.luben/zstd-jni/1.3.5-4/550b6393a007d0867c98611ca8cfbcf53f2eb991/zstd-jni-1.3.5-4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.lz4/lz4-java/1.5.0/d36fb639f06aaa4f17307625f80e2e32f815672a/lz4-java-1.5.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.xerial.snappy/snappy-java/1.1.7.2/307b286efd119ad2c6d4291128bf110bddc68088/snappy-java-1.1.7.2.jar, file:/Users/pszymczyk/Library/Caches/IntelliJIdea2018.2/groovyHotSwap/gragent.jar, file:/Users/pszymczyk/Library/Caches/IntelliJIdea2018.2/captureAgent/debugger-agent.jar]
2018-12-15 17:57:41,412 ERROR main  org.springframework.test.context.TestContextManager - Caught exception while allowing TestExecutionListener [org.springframework.test.context.web.ServletTestExecutionListener@47a64f7d] to prepare test instance [io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec@77228160]
java.lang.IllegalStateException: Failed to load ApplicationContext
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:124)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'commandsProcessor' defined in file [/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/production/classes/io/dddbyexamples/eventsource/kafka/CommandsProcessor.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.dddbyexamples.eventsource.kafka.CommandsProcessor]: Constructor threw exception; nested exception is java.lang.NullPointerException
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1105)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1050)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	... 36 common frames omitted
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.dddbyexamples.eventsource.kafka.CommandsProcessor]: Constructor threw exception; nested exception is java.lang.NullPointerException
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:163)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:89)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1098)
	... 52 common frames omitted
Caused by: java.lang.NullPointerException: null
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.createConsumer(CommandsProcessor.java:70)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>(CommandsProcessor.java:56)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	... 54 common frames omitted
2018-12-15 17:57:47,484 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 17:57:47,501 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 17:57:47,520 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@47a64f7d, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@33d05366, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@27a0a5a2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@7692cd34, org.springframework.test.context.transaction.TransactionalTestExecutionListener@33aa93c, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@32c0915e]
2018-12-15 17:57:48,389 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11116 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 17:57:48,389 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 17:57:48,473 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@279dd959: startup date [Sat Dec 15 17:57:48 CET 2018]; root of context hierarchy
2018-12-15 17:57:48,925 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 17:57:49,726 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$4e33e610] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 17:57:51,246 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 17:57:51,258 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 17:57:51,349 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 17:57:51,351 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 17:57:51,353 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 17:57:51,580 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 17:57:51,631 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 17:57:51,738 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 17:57:51,953 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 17:57:51,962 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 17:57:52,602 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 17:57:52,635 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 17:57:52,685 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:57:52,686 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:57:52,691 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 17:57:52,694 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 17:57:52,731 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:57:52,731 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:57:52,732 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 17:57:52,734 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 17:57:52,756 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:57:52,756 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:57:52,763 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 17:57:52,765 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 17:57:52,773 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 17:57:52,773 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:57:52,773 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:57:52,779 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Starting
2018-12-15 17:57:52,779 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to RUNNING
2018-12-15 17:57:52,780 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 17:57:52,786 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 17:57:52,792 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 17:57:52,795 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:57:52,795 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:57:54,959 WARN main  org.springframework.web.context.support.GenericWebApplicationContext - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'commandsProcessor' defined in file [/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/production/classes/io/dddbyexamples/eventsource/kafka/CommandsProcessor.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.dddbyexamples.eventsource.kafka.CommandsProcessor]: Constructor threw exception; nested exception is java.lang.NullPointerException
2018-12-15 17:57:54,960 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 17:57:54,961 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Informed to shut down
2018-12-15 17:57:54,961 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 17:57:54,996 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutting down
2018-12-15 17:57:54,996 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 17:57:54,996 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=wordcount-lambda-example-client-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-12-15 17:57:55,008 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2018-12-15 17:57:55,008 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutdown complete
2018-12-15 17:57:55,009 INFO kafka-streams-close-thread  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from PENDING_SHUTDOWN to NOT_RUNNING
2018-12-15 17:57:55,009 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Streams client stopped completely
2018-12-15 17:57:55,010 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-15 17:57:55,010 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 17:58:30,090 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 17:58:30,102 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 17:58:30,115 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ae42ce3, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4f5991f6, org.springframework.test.context.support.DirtiesContextTestExecutionListener@484094a5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@38234a38, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@63fbfaeb]
2018-12-15 17:58:30,816 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11122 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 17:58:30,816 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 17:58:30,875 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 17:58:30 CET 2018]; root of context hierarchy
2018-12-15 17:58:31,252 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 17:58:31,986 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$8d40c7e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 17:58:33,353 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 17:58:33,360 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 17:58:33,413 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 17:58:33,415 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 17:58:33,416 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 17:58:33,562 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 17:58:33,604 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 17:58:33,717 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 17:58:33,935 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 17:58:33,945 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 17:58:34,498 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 17:58:34,526 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 17:58:34,573 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:58:34,573 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:58:34,579 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 17:58:34,582 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 17:58:34,615 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:58:34,615 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:58:34,616 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 17:58:34,618 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 17:58:34,636 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:58:34,636 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:58:34,642 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 17:58:34,644 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 17:58:34,652 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 17:58:34,652 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:58:34,652 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:58:34,657 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Starting
2018-12-15 17:58:34,657 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to RUNNING
2018-12-15 17:58:34,658 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 17:58:34,665 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 17:58:34,671 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 17:58:34,674 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:58:34,674 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:58:34,700 WARN main  org.springframework.web.context.support.GenericWebApplicationContext - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'commandsProcessor' defined in file [/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/production/classes/io/dddbyexamples/eventsource/kafka/CommandsProcessor.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.dddbyexamples.eventsource.kafka.CommandsProcessor]: No default constructor found; nested exception is java.lang.NoSuchMethodException: io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>()
2018-12-15 17:58:34,700 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 17:58:34,701 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Informed to shut down
2018-12-15 17:58:34,701 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 17:58:34,763 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 17:58:34,765 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutting down
2018-12-15 17:58:34,766 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 17:58:34,766 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=wordcount-lambda-example-client-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-12-15 17:58:34,778 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2018-12-15 17:58:34,778 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutdown complete
2018-12-15 17:58:34,780 INFO kafka-streams-close-thread  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from PENDING_SHUTDOWN to NOT_RUNNING
2018-12-15 17:58:34,780 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Streams client stopped completely
2018-12-15 17:58:34,781 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-15 17:58:34,781 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 17:58:34,785 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 17:58:34,790 ERROR main  org.springframework.boot.SpringApplication - Application startup failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'commandsProcessor' defined in file [/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/production/classes/io/dddbyexamples/eventsource/kafka/CommandsProcessor.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.dddbyexamples.eventsource.kafka.CommandsProcessor]: No default constructor found; nested exception is java.lang.NoSuchMethodException: io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>()
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1105)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1050)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.dddbyexamples.eventsource.kafka.CommandsProcessor]: No default constructor found; nested exception is java.lang.NoSuchMethodException: io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>()
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:85)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1098)
	... 52 common frames omitted
Caused by: java.lang.NoSuchMethodException: io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>()
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getDeclaredConstructor(Class.java:2178)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:80)
	... 53 common frames omitted
2018-12-15 17:58:34,792 INFO main  org.springframework.boot.logging.ClasspathLoggingApplicationListener - Application failed to start with classpath: [file:/Applications/IntelliJ%20IDEA.app/Contents/lib/idea_rt.jar, file:/Applications/IntelliJ%20IDEA.app/Contents/plugins/junit/lib/junit-rt.jar, file:/Applications/IntelliJ%20IDEA.app/Contents/plugins/junit/lib/junit5-rt.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/charsets.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/deploy.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/cldrdata.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/dnsns.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/jaccess.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/jfxrt.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/localedata.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/nashorn.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/sunec.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/zipfs.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/javaws.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/jce.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/jfr.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/jfxswt.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/jsse.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/management-agent.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/plugin.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/resources.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/rt.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/ant-javafx.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/dt.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/javafx-mx.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/jconsole.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/packager.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/sa-jdi.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/tools.jar, file:/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes/, file:/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/resources/, file:/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/production/classes/, file:/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/production/resources/, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.kafka/spring-kafka/2.2.2.RELEASE/9b8d0fee9997197e80011c518f2f7fe1d95bb761/spring-kafka-2.2.2.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-web/1.3.5.RELEASE/1ad40f8edd1b502fb82bfae3a6feb8be3a2b44fa/spring-boot-starter-web-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-data-jpa/1.3.5.RELEASE/32f4449a9de903ec4e4acd9c8f6af7c6a1309571/spring-boot-starter-data-jpa-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.m2/repository/com/google/guava/guava/18.0/guava-18.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.projectlombok/lombok/1.16.8/2ce9de13f277ec1600e7e04231477e3e5f59d317/lombok-1.16.8.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-databind/2.7.4/1e9c6f3659644aeac84872c3b62d8e363bf4c96d/jackson-databind-2.7.4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.datatype/jackson-datatype-jsr310/2.7.4/390dbf17d4eb29a6157c6b9dcd9c93e7acac714/jackson-datatype-jsr310-2.7.4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-annotations/2.7.4/84b2f8e53bd8a077d402bc99d9bce816c2b2d0f9/jackson-annotations-2.7.4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.liquibase/liquibase-core/3.5.0/85834c6c100768cfe6351ea5e9c4d27523472390/liquibase-core-3.5.0.jar, file:/Users/pszymczyk/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.kafka/kafka-streams/2.1.0/ab1d9cf35cf0040a804266279faeaf082d3f66c3/kafka-streams-2.1.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-test/1.3.5.RELEASE/5c485e918b58741eccc0012c70062df5e5efa106/spring-boot-starter-test-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.spockframework/spock-spring/1.0-groovy-2.4/a07c753a95114872cd753ce3ae9166b64284b31d/spock-spring-1.0-groovy-2.4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-context/4.2.6.RELEASE/bbf3c8526fe37bb341507f28db17882d4348dbca/spring-context-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/cglib/cglib-nodep/3.2.1/dbee35a2ff88d175e8a321adae1f62b58cfd8a79/cglib-nodep-3.2.1.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.h2database/h2/1.4.191/dec3540178ea889b2871b0ed56db14bbec9cfdfc/h2-1.4.191.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-messaging/4.2.6.RELEASE/f7b3f8f875e055295f6ed2e552187f25b55c6920/spring-messaging-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-tx/4.2.6.RELEASE/ba7502c0644414748b1eeb65b4193b05d335a110/spring-tx-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.m2/repository/org/codehaus/groovy/groovy/2.4.15/groovy-2.4.15.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.retry/spring-retry/1.1.2.RELEASE/949a23beb82ebe31d7a1d47022353b8338c4da11/spring-retry-1.1.2.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter/1.3.5.RELEASE/188c658fabbce0d1ccc1ae18a1cf58f566208c78/spring-boot-starter-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-tomcat/1.3.5.RELEASE/b4c6277ccec38c51716659886efec073c4b386ea/spring-boot-starter-tomcat-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-validation/1.3.5.RELEASE/c83a6cc60a95faace7e03c524d60fc9de1329f57/spring-boot-starter-validation-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-web/4.2.6.RELEASE/d5ce949da3f3266f118ed899a153413613b503ad/spring-web-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-webmvc/4.2.6.RELEASE/7c7ea475d33287e0e3a92e98ccbe0ad6a0dbb9ca/spring-webmvc-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-aop/1.3.5.RELEASE/478a50b44faab2ada75583637b9f6e789809d069/spring-boot-starter-aop-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-jdbc/1.3.5.RELEASE/b427aa14a4f3a2fba114bcbb60eae6f83ee86706/spring-boot-starter-jdbc-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.hibernate/hibernate-entitymanager/4.3.11.Final/27a119fcc2b91c50e5285dd11158fac2c38c9d1b/hibernate-entitymanager-4.3.11.Final.jar, file:/Users/pszymczyk/.m2/repository/javax/transaction/javax.transaction-api/1.2/javax.transaction-api-1.2.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.data/spring-data-jpa/1.9.4.RELEASE/80b83510e67aa085b7d91d2d096d90133ec995de/spring-data-jpa-1.9.4.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-aspects/4.2.6.RELEASE/7ed7b15e95eedd551ac979bd8c295256d96cf2ff/spring-aspects-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-core/2.6.6/2eb801df67aacaf5b1deb4ac626e1964508e47b/jackson-core-2.6.6.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.yaml/snakeyaml/1.16/d64fb662c9e42789149f5078a62a22edda786c6a/snakeyaml-1.16.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.kafka/connect-json/2.1.0/6e2b621686935ee93e3f627477fcf7483769953d/connect-json-2.1.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-api/1.7.21/139535a69a4239db087de9bab0bee568bf8e0b70/slf4j-api-1.7.21.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.rocksdb/rocksdbjni/5.14.2/a6087318fab540ba0b4c6ff68475ffbedc0b3d10/rocksdbjni-5.14.2.jar, file:/Users/pszymczyk/.m2/repository/junit/junit/4.12/junit-4.12.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.mockito/mockito-core/1.10.19/e8546f5bef4e061d8dd73895b4e8f40e3fe6effe/mockito-core-1.10.19.jar, file:/Users/pszymczyk/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar, file:/Users/pszymczyk/.m2/repository/org/hamcrest/hamcrest-library/1.3/hamcrest-library-1.3.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-core/4.2.6.RELEASE/a1c6ef01f18888f51fc5054c65ef4787b7cf0a1e/spring-core-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-test/4.2.6.RELEASE/1f869333b3d64f17009a613368165978af575d8c/spring-test-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.spockframework/spock-core/1.0-groovy-2.4/ceaa8b69f274ed3de24da3e6a6c86f673b426d1a/spock-core-1.0-groovy-2.4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.codehaus.groovy/groovy-all/2.4.6/478feadca929a946b2f1fb962bb2179264759821/groovy-all-2.4.6.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-aop/4.2.6.RELEASE/5efbfccb19efda2956b8977561bf4da6b15b0d0e/spring-aop-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-beans/4.2.6.RELEASE/d4a319fb4d949fb6313f45c929947b9b4e26283e/spring-beans-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-expression/4.2.6.RELEASE/c0182d73f348ab11d51d45cbe29f3820c32d0ccc/spring-expression-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot/1.3.5.RELEASE/b218ba5f3bd01e657fbde9b085722da1fafa4f8a/spring-boot-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-autoconfigure/1.3.5.RELEASE/2bcfa86bb3afd95eff5252db6d78f2693b706997/spring-boot-autoconfigure-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-logging/1.3.5.RELEASE/a71e1d7fff512b1eadd3426ea1ce5b4cc703c429/spring-boot-starter-logging-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-core/8.0.33/4e7f547fbb2c364cb5e02a58790c5fb89e31efed/tomcat-embed-core-8.0.33.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-el/8.0.33/31423f2d493cf1f7cf5f0082c9f94640e93b8c1b/tomcat-embed-el-8.0.33.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-logging-juli/8.0.33/66bc309e0227c1ba2cf4417182d0b1583003d24b/tomcat-embed-logging-juli-8.0.33.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-websocket/8.0.33/be1f95e5d9ae00f9bc6138441d29cfe5c7c60256/tomcat-embed-websocket-8.0.33.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.hibernate/hibernate-validator/5.2.4.Final/fb18766b576aa6632bcfe9a20a023cbd52bf9769/hibernate-validator-5.2.4.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.aspectj/aspectjweaver/1.8.9/db28774f477f07220eac18d5ec9c4e01f48589d7/aspectjweaver-1.8.9.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat/tomcat-jdbc/8.0.33/7f1b6d609f9c2e045e8d7759e96605841fffdf82/tomcat-jdbc-8.0.33.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-jdbc/4.2.6.RELEASE/16075bfb0901a5b89c5be975365ff09b2df04abb/spring-jdbc-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.jboss.logging/jboss-logging/3.3.0.Final/3616bb87707910296e2c195dc016287080bba5af/jboss-logging-3.3.0.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.jboss.logging/jboss-logging-annotations/1.2.0.Beta1/2f437f37bb265d9f8f1392823dbca12d2bec06d6/jboss-logging-annotations-1.2.0.Beta1.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.hibernate/hibernate-core/4.3.11.Final/536ac0021240d97db99c7d2983067cef1a6f3af5/hibernate-core-4.3.11.Final.jar, file:/Users/pszymczyk/.m2/repository/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.hibernate.common/hibernate-commons-annotations/4.0.5.Final/2a581b9edb8168e45060d8bad8b7f46712d2c52c/hibernate-commons-annotations-4.0.5.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.hibernate.javax.persistence/hibernate-jpa-2.1-api/1.0.0.Final/5e731d961297e5a07290bfaf3db1fbc8bbbf405a/hibernate-jpa-2.1-api-1.0.0.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.javassist/javassist/3.18.1-GA/d9a09f7732226af26bf99f19e2cffe0ae219db5b/javassist-3.18.1-GA.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.data/spring-data-commons/1.11.4.RELEASE/c2b1fd4dbf7dff772d6124bb35892759e8bf088e/spring-data-commons-1.11.4.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-orm/4.2.6.RELEASE/2ef30e836028ebe4dbba0d8355929625a758ed8d/spring-orm-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.slf4j/jcl-over-slf4j/1.7.21/331b564a3a42f002a0004b039c1c430da89062cd/jcl-over-slf4j-1.7.21.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.kafka/connect-api/2.1.0/589e4d3a3f90446fd97059e4cc13975f01d9a1d0/connect-api-2.1.0.jar, file:/Users/pszymczyk/.m2/repository/org/objenesis/objenesis/2.1/objenesis-2.1.jar, file:/Users/pszymczyk/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/ch.qos.logback/logback-classic/1.1.7/9865cf6994f9ff13fce0bf93f2054ef6c65bb462/logback-classic-1.1.7.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.slf4j/jul-to-slf4j/1.7.21/2f22c882ffa479d1e9ff4eb0e8e2c29f2a0871ed/jul-to-slf4j-1.7.21.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.slf4j/log4j-over-slf4j/1.7.21/b3700d97464d99bdcd42c0177d6e7951c94d75ff/log4j-over-slf4j-1.7.21.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/javax.validation/validation-api/1.1.0.Final/8613ae82954779d518631e05daa73a6a954817d5/validation-api-1.1.0.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.fasterxml/classmate/1.1.0/dbbd699a1486ad0f2ed6f5af6cfed66acacb9056/classmate-1.1.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat/tomcat-juli/8.0.33/330aecfa895156cea91c576cb6609537152761f9/tomcat-juli-8.0.33.jar, file:/Users/pszymczyk/.m2/repository/antlr/antlr/2.7.7/antlr-2.7.7.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.jboss/jandex/1.1.0.Final/e84a2122e76f0b6503be78094ddf2108057ac15f/jandex-1.1.0.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/xml-apis/xml-apis/1.0.b2/3136ca936f64c9d68529f048c2618bd356bf85c9/xml-apis-1.0.b2.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/javax.ws.rs/javax.ws.rs-api/2.1.1/d3466bc9321fe84f268a1adb3b90373fc14b0eb5/javax.ws.rs-api-2.1.1.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/ch.qos.logback/logback-core/1.1.7/7873092d39ef741575ca91378a6a21c388363ac8/logback-core-1.1.7.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.kafka/kafka-clients/2.1.0/34d9983705c953b97abb01e1cd04647f47272fe5/kafka-clients-2.1.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.github.luben/zstd-jni/1.3.5-4/550b6393a007d0867c98611ca8cfbcf53f2eb991/zstd-jni-1.3.5-4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.lz4/lz4-java/1.5.0/d36fb639f06aaa4f17307625f80e2e32f815672a/lz4-java-1.5.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.xerial.snappy/snappy-java/1.1.7.2/307b286efd119ad2c6d4291128bf110bddc68088/snappy-java-1.1.7.2.jar, file:/Applications/IntelliJ%20IDEA.app/Contents/lib/idea_rt.jar]
2018-12-15 17:58:34,793 ERROR main  org.springframework.test.context.TestContextManager - Caught exception while allowing TestExecutionListener [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1] to prepare test instance [io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec@41b2123e]
java.lang.IllegalStateException: Failed to load ApplicationContext
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:124)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'commandsProcessor' defined in file [/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/production/classes/io/dddbyexamples/eventsource/kafka/CommandsProcessor.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.dddbyexamples.eventsource.kafka.CommandsProcessor]: No default constructor found; nested exception is java.lang.NoSuchMethodException: io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>()
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1105)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1050)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	... 36 common frames omitted
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.dddbyexamples.eventsource.kafka.CommandsProcessor]: No default constructor found; nested exception is java.lang.NoSuchMethodException: io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>()
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:85)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1098)
	... 52 common frames omitted
Caused by: java.lang.NoSuchMethodException: io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>()
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getDeclaredConstructor(Class.java:2178)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:80)
	... 53 common frames omitted
2018-12-15 17:59:45,533 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 17:59:45,547 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 17:59:45,560 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ae42ce3, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4f5991f6, org.springframework.test.context.support.DirtiesContextTestExecutionListener@484094a5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@38234a38, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@63fbfaeb]
2018-12-15 17:59:46,366 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11126 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 17:59:46,366 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 17:59:46,431 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 17:59:46 CET 2018]; root of context hierarchy
2018-12-15 17:59:46,808 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 17:59:47,535 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$8d40c7e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 17:59:48,842 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 17:59:48,849 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 17:59:48,911 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 17:59:48,912 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 17:59:48,913 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 17:59:49,066 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 17:59:49,107 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 17:59:49,214 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 17:59:49,433 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 17:59:49,442 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 17:59:49,973 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 17:59:50,000 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 17:59:50,041 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:59:50,041 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:59:50,046 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 17:59:50,049 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 17:59:50,081 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:59:50,081 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:59:50,082 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 17:59:50,084 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 17:59:50,104 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:59:50,104 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:59:50,110 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 17:59:50,112 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 17:59:50,119 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 17:59:50,120 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:59:50,120 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:59:50,124 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Starting
2018-12-15 17:59:50,125 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to RUNNING
2018-12-15 17:59:50,125 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 17:59:50,132 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 17:59:50,137 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 17:59:50,139 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 17:59:50,140 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 17:59:50,164 WARN main  org.springframework.web.context.support.GenericWebApplicationContext - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'commandsProcessor' defined in file [/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/production/classes/io/dddbyexamples/eventsource/kafka/CommandsProcessor.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.dddbyexamples.eventsource.kafka.CommandsProcessor]: No default constructor found; nested exception is java.lang.NoSuchMethodException: io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>()
2018-12-15 17:59:50,164 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 17:59:50,166 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Informed to shut down
2018-12-15 17:59:50,166 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 17:59:50,221 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 17:59:50,222 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 17:59:50,226 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutting down
2018-12-15 17:59:50,226 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 17:59:50,226 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=wordcount-lambda-example-client-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-12-15 17:59:50,236 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2018-12-15 17:59:50,236 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutdown complete
2018-12-15 17:59:50,238 INFO kafka-streams-close-thread  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from PENDING_SHUTDOWN to NOT_RUNNING
2018-12-15 17:59:50,238 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Streams client stopped completely
2018-12-15 17:59:50,239 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-15 17:59:50,239 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 17:59:50,243 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 17:59:50,248 ERROR main  org.springframework.boot.SpringApplication - Application startup failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'commandsProcessor' defined in file [/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/production/classes/io/dddbyexamples/eventsource/kafka/CommandsProcessor.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.dddbyexamples.eventsource.kafka.CommandsProcessor]: No default constructor found; nested exception is java.lang.NoSuchMethodException: io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>()
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1105)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1050)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.dddbyexamples.eventsource.kafka.CommandsProcessor]: No default constructor found; nested exception is java.lang.NoSuchMethodException: io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>()
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:85)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1098)
	... 52 common frames omitted
Caused by: java.lang.NoSuchMethodException: io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>()
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getDeclaredConstructor(Class.java:2178)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:80)
	... 53 common frames omitted
2018-12-15 17:59:50,250 INFO main  org.springframework.boot.logging.ClasspathLoggingApplicationListener - Application failed to start with classpath: [file:/Applications/IntelliJ%20IDEA.app/Contents/lib/idea_rt.jar, file:/Applications/IntelliJ%20IDEA.app/Contents/plugins/junit/lib/junit-rt.jar, file:/Applications/IntelliJ%20IDEA.app/Contents/plugins/junit/lib/junit5-rt.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/charsets.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/deploy.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/cldrdata.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/dnsns.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/jaccess.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/jfxrt.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/localedata.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/nashorn.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/sunec.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/ext/zipfs.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/javaws.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/jce.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/jfr.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/jfxswt.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/jsse.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/management-agent.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/plugin.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/resources.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre/lib/rt.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/ant-javafx.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/dt.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/javafx-mx.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/jconsole.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/packager.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/sa-jdi.jar, file:/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/lib/tools.jar, file:/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes/, file:/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/resources/, file:/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/production/classes/, file:/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/production/resources/, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.kafka/spring-kafka/2.2.2.RELEASE/9b8d0fee9997197e80011c518f2f7fe1d95bb761/spring-kafka-2.2.2.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-web/1.3.5.RELEASE/1ad40f8edd1b502fb82bfae3a6feb8be3a2b44fa/spring-boot-starter-web-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-data-jpa/1.3.5.RELEASE/32f4449a9de903ec4e4acd9c8f6af7c6a1309571/spring-boot-starter-data-jpa-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.m2/repository/com/google/guava/guava/18.0/guava-18.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.projectlombok/lombok/1.16.8/2ce9de13f277ec1600e7e04231477e3e5f59d317/lombok-1.16.8.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-databind/2.7.4/1e9c6f3659644aeac84872c3b62d8e363bf4c96d/jackson-databind-2.7.4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.datatype/jackson-datatype-jsr310/2.7.4/390dbf17d4eb29a6157c6b9dcd9c93e7acac714/jackson-datatype-jsr310-2.7.4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-annotations/2.7.4/84b2f8e53bd8a077d402bc99d9bce816c2b2d0f9/jackson-annotations-2.7.4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.liquibase/liquibase-core/3.5.0/85834c6c100768cfe6351ea5e9c4d27523472390/liquibase-core-3.5.0.jar, file:/Users/pszymczyk/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.kafka/kafka-streams/2.1.0/ab1d9cf35cf0040a804266279faeaf082d3f66c3/kafka-streams-2.1.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-test/1.3.5.RELEASE/5c485e918b58741eccc0012c70062df5e5efa106/spring-boot-starter-test-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.spockframework/spock-spring/1.0-groovy-2.4/a07c753a95114872cd753ce3ae9166b64284b31d/spock-spring-1.0-groovy-2.4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-context/4.2.6.RELEASE/bbf3c8526fe37bb341507f28db17882d4348dbca/spring-context-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/cglib/cglib-nodep/3.2.1/dbee35a2ff88d175e8a321adae1f62b58cfd8a79/cglib-nodep-3.2.1.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.h2database/h2/1.4.191/dec3540178ea889b2871b0ed56db14bbec9cfdfc/h2-1.4.191.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-messaging/4.2.6.RELEASE/f7b3f8f875e055295f6ed2e552187f25b55c6920/spring-messaging-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-tx/4.2.6.RELEASE/ba7502c0644414748b1eeb65b4193b05d335a110/spring-tx-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.m2/repository/org/codehaus/groovy/groovy/2.4.15/groovy-2.4.15.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.retry/spring-retry/1.1.2.RELEASE/949a23beb82ebe31d7a1d47022353b8338c4da11/spring-retry-1.1.2.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter/1.3.5.RELEASE/188c658fabbce0d1ccc1ae18a1cf58f566208c78/spring-boot-starter-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-tomcat/1.3.5.RELEASE/b4c6277ccec38c51716659886efec073c4b386ea/spring-boot-starter-tomcat-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-validation/1.3.5.RELEASE/c83a6cc60a95faace7e03c524d60fc9de1329f57/spring-boot-starter-validation-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-web/4.2.6.RELEASE/d5ce949da3f3266f118ed899a153413613b503ad/spring-web-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-webmvc/4.2.6.RELEASE/7c7ea475d33287e0e3a92e98ccbe0ad6a0dbb9ca/spring-webmvc-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-aop/1.3.5.RELEASE/478a50b44faab2ada75583637b9f6e789809d069/spring-boot-starter-aop-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-jdbc/1.3.5.RELEASE/b427aa14a4f3a2fba114bcbb60eae6f83ee86706/spring-boot-starter-jdbc-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.hibernate/hibernate-entitymanager/4.3.11.Final/27a119fcc2b91c50e5285dd11158fac2c38c9d1b/hibernate-entitymanager-4.3.11.Final.jar, file:/Users/pszymczyk/.m2/repository/javax/transaction/javax.transaction-api/1.2/javax.transaction-api-1.2.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.data/spring-data-jpa/1.9.4.RELEASE/80b83510e67aa085b7d91d2d096d90133ec995de/spring-data-jpa-1.9.4.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-aspects/4.2.6.RELEASE/7ed7b15e95eedd551ac979bd8c295256d96cf2ff/spring-aspects-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-core/2.6.6/2eb801df67aacaf5b1deb4ac626e1964508e47b/jackson-core-2.6.6.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.yaml/snakeyaml/1.16/d64fb662c9e42789149f5078a62a22edda786c6a/snakeyaml-1.16.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.kafka/connect-json/2.1.0/6e2b621686935ee93e3f627477fcf7483769953d/connect-json-2.1.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-api/1.7.21/139535a69a4239db087de9bab0bee568bf8e0b70/slf4j-api-1.7.21.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.rocksdb/rocksdbjni/5.14.2/a6087318fab540ba0b4c6ff68475ffbedc0b3d10/rocksdbjni-5.14.2.jar, file:/Users/pszymczyk/.m2/repository/junit/junit/4.12/junit-4.12.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.mockito/mockito-core/1.10.19/e8546f5bef4e061d8dd73895b4e8f40e3fe6effe/mockito-core-1.10.19.jar, file:/Users/pszymczyk/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar, file:/Users/pszymczyk/.m2/repository/org/hamcrest/hamcrest-library/1.3/hamcrest-library-1.3.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-core/4.2.6.RELEASE/a1c6ef01f18888f51fc5054c65ef4787b7cf0a1e/spring-core-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-test/4.2.6.RELEASE/1f869333b3d64f17009a613368165978af575d8c/spring-test-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.spockframework/spock-core/1.0-groovy-2.4/ceaa8b69f274ed3de24da3e6a6c86f673b426d1a/spock-core-1.0-groovy-2.4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.codehaus.groovy/groovy-all/2.4.6/478feadca929a946b2f1fb962bb2179264759821/groovy-all-2.4.6.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-aop/4.2.6.RELEASE/5efbfccb19efda2956b8977561bf4da6b15b0d0e/spring-aop-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-beans/4.2.6.RELEASE/d4a319fb4d949fb6313f45c929947b9b4e26283e/spring-beans-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-expression/4.2.6.RELEASE/c0182d73f348ab11d51d45cbe29f3820c32d0ccc/spring-expression-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot/1.3.5.RELEASE/b218ba5f3bd01e657fbde9b085722da1fafa4f8a/spring-boot-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-autoconfigure/1.3.5.RELEASE/2bcfa86bb3afd95eff5252db6d78f2693b706997/spring-boot-autoconfigure-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-logging/1.3.5.RELEASE/a71e1d7fff512b1eadd3426ea1ce5b4cc703c429/spring-boot-starter-logging-1.3.5.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-core/8.0.33/4e7f547fbb2c364cb5e02a58790c5fb89e31efed/tomcat-embed-core-8.0.33.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-el/8.0.33/31423f2d493cf1f7cf5f0082c9f94640e93b8c1b/tomcat-embed-el-8.0.33.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-logging-juli/8.0.33/66bc309e0227c1ba2cf4417182d0b1583003d24b/tomcat-embed-logging-juli-8.0.33.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-websocket/8.0.33/be1f95e5d9ae00f9bc6138441d29cfe5c7c60256/tomcat-embed-websocket-8.0.33.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.hibernate/hibernate-validator/5.2.4.Final/fb18766b576aa6632bcfe9a20a023cbd52bf9769/hibernate-validator-5.2.4.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.aspectj/aspectjweaver/1.8.9/db28774f477f07220eac18d5ec9c4e01f48589d7/aspectjweaver-1.8.9.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat/tomcat-jdbc/8.0.33/7f1b6d609f9c2e045e8d7759e96605841fffdf82/tomcat-jdbc-8.0.33.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-jdbc/4.2.6.RELEASE/16075bfb0901a5b89c5be975365ff09b2df04abb/spring-jdbc-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.jboss.logging/jboss-logging/3.3.0.Final/3616bb87707910296e2c195dc016287080bba5af/jboss-logging-3.3.0.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.jboss.logging/jboss-logging-annotations/1.2.0.Beta1/2f437f37bb265d9f8f1392823dbca12d2bec06d6/jboss-logging-annotations-1.2.0.Beta1.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.hibernate/hibernate-core/4.3.11.Final/536ac0021240d97db99c7d2983067cef1a6f3af5/hibernate-core-4.3.11.Final.jar, file:/Users/pszymczyk/.m2/repository/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.hibernate.common/hibernate-commons-annotations/4.0.5.Final/2a581b9edb8168e45060d8bad8b7f46712d2c52c/hibernate-commons-annotations-4.0.5.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.hibernate.javax.persistence/hibernate-jpa-2.1-api/1.0.0.Final/5e731d961297e5a07290bfaf3db1fbc8bbbf405a/hibernate-jpa-2.1-api-1.0.0.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.javassist/javassist/3.18.1-GA/d9a09f7732226af26bf99f19e2cffe0ae219db5b/javassist-3.18.1-GA.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework.data/spring-data-commons/1.11.4.RELEASE/c2b1fd4dbf7dff772d6124bb35892759e8bf088e/spring-data-commons-1.11.4.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.springframework/spring-orm/4.2.6.RELEASE/2ef30e836028ebe4dbba0d8355929625a758ed8d/spring-orm-4.2.6.RELEASE.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.slf4j/jcl-over-slf4j/1.7.21/331b564a3a42f002a0004b039c1c430da89062cd/jcl-over-slf4j-1.7.21.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.kafka/connect-api/2.1.0/589e4d3a3f90446fd97059e4cc13975f01d9a1d0/connect-api-2.1.0.jar, file:/Users/pszymczyk/.m2/repository/org/objenesis/objenesis/2.1/objenesis-2.1.jar, file:/Users/pszymczyk/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/ch.qos.logback/logback-classic/1.1.7/9865cf6994f9ff13fce0bf93f2054ef6c65bb462/logback-classic-1.1.7.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.slf4j/jul-to-slf4j/1.7.21/2f22c882ffa479d1e9ff4eb0e8e2c29f2a0871ed/jul-to-slf4j-1.7.21.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.slf4j/log4j-over-slf4j/1.7.21/b3700d97464d99bdcd42c0177d6e7951c94d75ff/log4j-over-slf4j-1.7.21.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/javax.validation/validation-api/1.1.0.Final/8613ae82954779d518631e05daa73a6a954817d5/validation-api-1.1.0.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.fasterxml/classmate/1.1.0/dbbd699a1486ad0f2ed6f5af6cfed66acacb9056/classmate-1.1.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.tomcat/tomcat-juli/8.0.33/330aecfa895156cea91c576cb6609537152761f9/tomcat-juli-8.0.33.jar, file:/Users/pszymczyk/.m2/repository/antlr/antlr/2.7.7/antlr-2.7.7.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.jboss/jandex/1.1.0.Final/e84a2122e76f0b6503be78094ddf2108057ac15f/jandex-1.1.0.Final.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/xml-apis/xml-apis/1.0.b2/3136ca936f64c9d68529f048c2618bd356bf85c9/xml-apis-1.0.b2.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/javax.ws.rs/javax.ws.rs-api/2.1.1/d3466bc9321fe84f268a1adb3b90373fc14b0eb5/javax.ws.rs-api-2.1.1.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/ch.qos.logback/logback-core/1.1.7/7873092d39ef741575ca91378a6a21c388363ac8/logback-core-1.1.7.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.apache.kafka/kafka-clients/2.1.0/34d9983705c953b97abb01e1cd04647f47272fe5/kafka-clients-2.1.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/com.github.luben/zstd-jni/1.3.5-4/550b6393a007d0867c98611ca8cfbcf53f2eb991/zstd-jni-1.3.5-4.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.lz4/lz4-java/1.5.0/d36fb639f06aaa4f17307625f80e2e32f815672a/lz4-java-1.5.0.jar, file:/Users/pszymczyk/.gradle/caches/modules-2/files-2.1/org.xerial.snappy/snappy-java/1.1.7.2/307b286efd119ad2c6d4291128bf110bddc68088/snappy-java-1.1.7.2.jar, file:/Applications/IntelliJ%20IDEA.app/Contents/lib/idea_rt.jar]
2018-12-15 17:59:50,251 ERROR main  org.springframework.test.context.TestContextManager - Caught exception while allowing TestExecutionListener [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1] to prepare test instance [io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec@41b2123e]
java.lang.IllegalStateException: Failed to load ApplicationContext
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:124)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'commandsProcessor' defined in file [/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/production/classes/io/dddbyexamples/eventsource/kafka/CommandsProcessor.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.dddbyexamples.eventsource.kafka.CommandsProcessor]: No default constructor found; nested exception is java.lang.NoSuchMethodException: io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>()
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1105)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1050)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	... 36 common frames omitted
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [io.dddbyexamples.eventsource.kafka.CommandsProcessor]: No default constructor found; nested exception is java.lang.NoSuchMethodException: io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>()
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:85)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1098)
	... 52 common frames omitted
Caused by: java.lang.NoSuchMethodException: io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>()
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getDeclaredConstructor(Class.java:2178)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:80)
	... 53 common frames omitted
2018-12-15 18:00:10,634 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 18:00:10,647 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 18:00:10,660 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ae42ce3, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4f5991f6, org.springframework.test.context.support.DirtiesContextTestExecutionListener@484094a5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@38234a38, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@63fbfaeb]
2018-12-15 18:00:11,420 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11130 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 18:00:11,420 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 18:00:11,479 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:00:11 CET 2018]; root of context hierarchy
2018-12-15 18:00:11,846 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 18:00:12,593 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$d0b6a69] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 18:00:13,939 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 18:00:13,946 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 18:00:14,009 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 18:00:14,010 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 18:00:14,011 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 18:00:14,166 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 18:00:14,214 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 18:00:14,348 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 18:00:14,577 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:00:14,587 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:00:15,119 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 18:00:15,147 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 18:00:15,193 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:00:15,193 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:00:15,199 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 18:00:15,202 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:00:15,236 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:00:15,236 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:00:15,238 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 18:00:15,239 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 18:00:15,258 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:00:15,259 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:00:15,265 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 18:00:15,267 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:00:15,275 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 18:00:15,275 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:00:15,275 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:00:15,281 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Starting
2018-12-15 18:00:15,281 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to RUNNING
2018-12-15 18:00:15,282 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 18:00:15,289 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:00:15,295 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 18:00:15,297 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:00:15,298 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:00:15,335 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-15 18:00:15,338 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:00:15,338 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:00:15,339 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:00:15,340 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 18:00:15,342 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:00:15,342 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:00:15,345 WARN main  org.apache.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=my-client-id
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:62)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:425)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:316)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.createProducer(CommandsProcessor.java:83)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>(CommandsProcessor.java:53)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 18:00:15,347 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-15 18:00:15,387 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:00:15,388 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:00:15,396 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Revoking previously assigned partitions []
2018-12-15 18:00:15,396 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-12-15 18:00:15,396 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to REBALANCING
2018-12-15 18:00:15,397 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:00:15,397 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition revocation took 0 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-12-15 18:00:15,397 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] (Re-)joining group
2018-12-15 18:00:15,418 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wordcount-lambda-example-client-StreamThread-1-consumer] Assigned tasks to clients as {8c501eca-7418-4a5d-b9d1-7a03245a5519=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) assignedTasks: ([0_0, 1_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2018-12-15 18:00:15,423 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Successfully joined group with generation 4
2018-12-15 18:00:15,426 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Setting newly assigned partitions [wordcount-lambda-example-shop-items-store-repartition-0, shop-items-0]
2018-12-15 18:00:15,427 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2018-12-15 18:00:15,454 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition assignment took 27 ms.
	current active tasks: [0_0, 1_0]
	current standby tasks: []
	previous active tasks: []

2018-12-15 18:00:15,462 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Resetting offset for partition wordcount-lambda-example-shop-items-store-repartition-0 to offset 0.
2018-12-15 18:00:15,463 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Resetting offset for partition shop-items-0 to offset 0.
2018-12-15 18:00:15,511 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:00:15,517 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:00:15,519 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:00:15,519 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2018-12-15 18:00:15,519 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from REBALANCING to RUNNING
2018-12-15 18:00:15,549 ERROR wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.AssignedStreamsTasks - stream-thread [wordcount-lambda-example-client-StreamThread-1] Failed to process stream task 0_0 due to the following error:
java.lang.ClassCastException: [B cannot be cast to java.util.UUID
	at org.apache.kafka.streams.kstream.internals.KStreamImpl.lambda$internalSelectKey$29(KStreamImpl.java:185)
	at org.apache.kafka.streams.kstream.internals.KStreamMap$KStreamMapProcessor.process(KStreamMap.java:41)
	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:115)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:146)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:129)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:93)
	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:351)
	at org.apache.kafka.streams.processor.internals.AssignedStreamsTasks.process(AssignedStreamsTasks.java:104)
	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:413)
	at org.apache.kafka.streams.processor.internals.StreamThread.runOnce(StreamThread.java:862)
	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:777)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:747)
2018-12-15 18:00:15,549 ERROR wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Encountered the following error during processing:
java.lang.ClassCastException: [B cannot be cast to java.util.UUID
	at org.apache.kafka.streams.kstream.internals.KStreamImpl.lambda$internalSelectKey$29(KStreamImpl.java:185)
	at org.apache.kafka.streams.kstream.internals.KStreamMap$KStreamMapProcessor.process(KStreamMap.java:41)
	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:115)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:146)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:129)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:93)
	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:351)
	at org.apache.kafka.streams.processor.internals.AssignedStreamsTasks.process(AssignedStreamsTasks.java:104)
	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:413)
	at org.apache.kafka.streams.processor.internals.StreamThread.runOnce(StreamThread.java:862)
	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:777)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:747)
2018-12-15 18:00:15,549 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:00:15,549 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutting down
2018-12-15 18:00:15,556 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:00:15,556 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=wordcount-lambda-example-client-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-12-15 18:00:15,563 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2018-12-15 18:00:15,563 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to ERROR
2018-12-15 18:00:15,563 WARN wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] All stream threads have died. The instance will be in error state and should be closed.
2018-12-15 18:00:15,563 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutdown complete
2018-12-15 18:00:15,581 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 44
2018-12-15 18:00:15,586 INFO pool-2-thread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:00:15,587 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:00:15,587 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Revoking previously assigned partitions []
2018-12-15 18:00:15,587 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] (Re-)joining group
2018-12-15 18:00:15,593 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Successfully joined group with generation 17
2018-12-15 18:00:15,594 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Setting newly assigned partitions [shop-items-commands-0]
2018-12-15 18:00:15,600 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Resetting offset for partition shop-items-commands-0 to offset 0.
2018-12-15 18:00:15,912 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:00:11 CET 2018]; root of context hierarchy
2018-12-15 18:00:15,969 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-15 18:00:15,970 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-15 18:00:15,990 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:00:15,991 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:00:16,015 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:00:16,251 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.485 seconds (JVM running for 6.921)
2018-12-15 18:00:16,253 INFO pool-3-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-15T17:00:16.246Z
2018-12-15 18:00:16,296 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:00:16,325 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:00:11 CET 2018]; root of context hierarchy
2018-12-15 18:00:16,329 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from ERROR to PENDING_SHUTDOWN
2018-12-15 18:00:16,330 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Informed to shut down
2018-12-15 18:00:16,332 INFO kafka-streams-close-thread  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from PENDING_SHUTDOWN to NOT_RUNNING
2018-12-15 18:00:16,332 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Streams client stopped completely
2018-12-15 18:00:16,332 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-15 18:00:16,333 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:00:16,336 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:01:13,529 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 18:01:13,543 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 18:01:13,556 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ae42ce3, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4f5991f6, org.springframework.test.context.support.DirtiesContextTestExecutionListener@484094a5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@38234a38, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@63fbfaeb]
2018-12-15 18:01:14,330 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11135 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 18:01:14,330 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 18:01:14,387 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:01:14 CET 2018]; root of context hierarchy
2018-12-15 18:01:14,765 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 18:01:15,468 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$d0b6a69] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 18:01:16,770 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 18:01:16,778 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 18:01:16,842 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 18:01:16,843 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 18:01:16,844 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 18:01:17,003 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 18:01:17,046 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 18:01:17,149 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 18:01:17,351 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:01:17,359 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:01:17,904 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 18:01:17,929 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 18:01:17,971 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:01:17,971 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:01:17,976 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 18:01:17,979 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:01:18,012 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:01:18,012 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:01:18,014 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 18:01:18,016 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 18:01:18,036 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:01:18,036 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:01:18,043 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 18:01:18,045 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:01:18,052 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 18:01:18,053 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:01:18,053 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:01:18,058 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Starting
2018-12-15 18:01:18,058 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to RUNNING
2018-12-15 18:01:18,059 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 18:01:18,066 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-commands-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:01:18,072 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-commands-id] Instantiated a transactional producer.
2018-12-15 18:01:18,074 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-commands-id] Overriding the default acks to all since idempotence is enabled.
2018-12-15 18:01:18,075 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:01:18,075 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:01:18,107 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-15 18:01:18,110 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:01:18,110 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:01:18,111 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:01:18,111 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 18:01:18,113 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:01:18,114 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:01:18,116 WARN main  org.apache.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=my-client-id
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:62)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:425)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:316)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.createProducer(CommandsProcessor.java:83)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>(CommandsProcessor.java:53)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 18:01:18,118 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-15 18:01:18,153 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:01:18,154 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:01:18,160 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Revoking previously assigned partitions []
2018-12-15 18:01:18,161 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-12-15 18:01:18,161 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to REBALANCING
2018-12-15 18:01:18,162 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:01:18,162 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition revocation took 1 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-12-15 18:01:18,162 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] (Re-)joining group
2018-12-15 18:01:18,187 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wordcount-lambda-example-client-StreamThread-1-consumer] Assigned tasks to clients as {2029df7e-f8b5-462b-b744-9283348053f4=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) assignedTasks: ([0_0, 1_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2018-12-15 18:01:18,192 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Successfully joined group with generation 6
2018-12-15 18:01:18,195 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Setting newly assigned partitions [wordcount-lambda-example-shop-items-store-repartition-0, shop-items-0]
2018-12-15 18:01:18,196 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2018-12-15 18:01:18,222 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition assignment took 26 ms.
	current active tasks: [0_0, 1_0]
	current standby tasks: []
	previous active tasks: []

2018-12-15 18:01:18,231 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Resetting offset for partition wordcount-lambda-example-shop-items-store-repartition-0 to offset 0.
2018-12-15 18:01:18,231 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Resetting offset for partition shop-items-0 to offset 0.
2018-12-15 18:01:18,293 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:01:18,298 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:01:18,300 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:01:18,300 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2018-12-15 18:01:18,301 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from REBALANCING to RUNNING
2018-12-15 18:01:18,331 ERROR wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.AssignedStreamsTasks - stream-thread [wordcount-lambda-example-client-StreamThread-1] Failed to process stream task 0_0 due to the following error:
java.lang.ClassCastException: [B cannot be cast to java.util.UUID
	at org.apache.kafka.streams.kstream.internals.KStreamImpl.lambda$internalSelectKey$29(KStreamImpl.java:185)
	at org.apache.kafka.streams.kstream.internals.KStreamMap$KStreamMapProcessor.process(KStreamMap.java:41)
	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:115)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:146)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:129)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:93)
	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:351)
	at org.apache.kafka.streams.processor.internals.AssignedStreamsTasks.process(AssignedStreamsTasks.java:104)
	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:413)
	at org.apache.kafka.streams.processor.internals.StreamThread.runOnce(StreamThread.java:862)
	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:777)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:747)
2018-12-15 18:01:18,331 ERROR wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Encountered the following error during processing:
java.lang.ClassCastException: [B cannot be cast to java.util.UUID
	at org.apache.kafka.streams.kstream.internals.KStreamImpl.lambda$internalSelectKey$29(KStreamImpl.java:185)
	at org.apache.kafka.streams.kstream.internals.KStreamMap$KStreamMapProcessor.process(KStreamMap.java:41)
	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:115)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:146)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:129)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:93)
	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:351)
	at org.apache.kafka.streams.processor.internals.AssignedStreamsTasks.process(AssignedStreamsTasks.java:104)
	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:413)
	at org.apache.kafka.streams.processor.internals.StreamThread.runOnce(StreamThread.java:862)
	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:777)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:747)
2018-12-15 18:01:18,331 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:01:18,331 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutting down
2018-12-15 18:01:18,338 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:01:18,338 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=wordcount-lambda-example-client-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-12-15 18:01:18,344 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2018-12-15 18:01:18,344 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to ERROR
2018-12-15 18:01:18,345 WARN wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] All stream threads have died. The instance will be in error state and should be closed.
2018-12-15 18:01:18,345 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutdown complete
2018-12-15 18:01:18,348 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 45
2018-12-15 18:01:18,353 INFO pool-2-thread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:01:18,354 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:01:18,354 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Revoking previously assigned partitions []
2018-12-15 18:01:18,355 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] (Re-)joining group
2018-12-15 18:01:18,360 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Successfully joined group with generation 19
2018-12-15 18:01:18,361 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Setting newly assigned partitions [shop-items-commands-0]
2018-12-15 18:01:18,365 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Resetting offset for partition shop-items-commands-0 to offset 0.
2018-12-15 18:01:18,676 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:01:14 CET 2018]; root of context hierarchy
2018-12-15 18:01:18,731 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-15 18:01:18,732 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-15 18:01:18,752 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:01:18,752 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:01:18,780 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:01:19,025 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.356 seconds (JVM running for 6.773)
2018-12-15 18:01:19,027 INFO pool-3-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-15T17:01:19.019Z
2018-12-15 18:01:19,068 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:01:19,096 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:01:14 CET 2018]; root of context hierarchy
2018-12-15 18:01:19,101 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from ERROR to PENDING_SHUTDOWN
2018-12-15 18:01:19,102 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Informed to shut down
2018-12-15 18:01:19,103 INFO kafka-streams-close-thread  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from PENDING_SHUTDOWN to NOT_RUNNING
2018-12-15 18:01:19,103 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Streams client stopped completely
2018-12-15 18:01:19,104 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-15 18:01:19,104 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:01:19,108 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:01:38,697 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 18:01:38,708 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 18:01:38,719 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ae42ce3, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4f5991f6, org.springframework.test.context.support.DirtiesContextTestExecutionListener@484094a5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@38234a38, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@63fbfaeb]
2018-12-15 18:01:39,399 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11139 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 18:01:39,399 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 18:01:39,457 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:01:39 CET 2018]; root of context hierarchy
2018-12-15 18:01:39,838 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 18:01:40,557 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$d0b6a69] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 18:01:41,867 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 18:01:41,876 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 18:01:41,951 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 18:01:41,952 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 18:01:41,954 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 18:01:42,106 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 18:01:42,154 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 18:01:42,273 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 18:01:42,461 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:01:42,469 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:01:43,008 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 18:01:43,040 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 18:01:43,089 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:01:43,089 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:01:43,096 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 18:01:43,099 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:01:43,136 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:01:43,136 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:01:43,138 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 18:01:43,140 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 18:01:43,160 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:01:43,160 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:01:43,167 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 18:01:43,168 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:01:43,176 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 18:01:43,176 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:01:43,176 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:01:43,181 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Starting
2018-12-15 18:01:43,182 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to RUNNING
2018-12-15 18:01:43,182 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 18:01:43,189 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:01:43,192 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:01:43,193 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:01:43,227 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-15 18:01:43,230 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:01:43,230 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:01:43,231 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:01:43,237 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 18:01:43,240 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:01:43,240 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:01:43,243 WARN main  org.apache.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=my-client-id
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:62)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:425)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:316)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.createProducer(CommandsProcessor.java:83)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>(CommandsProcessor.java:53)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 18:01:43,244 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-15 18:01:43,281 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:01:43,282 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:01:43,291 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Revoking previously assigned partitions []
2018-12-15 18:01:43,291 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-12-15 18:01:43,291 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to REBALANCING
2018-12-15 18:01:43,291 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:01:43,291 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition revocation took 0 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-12-15 18:01:43,292 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] (Re-)joining group
2018-12-15 18:01:43,313 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wordcount-lambda-example-client-StreamThread-1-consumer] Assigned tasks to clients as {8df158b3-3126-4ecd-b4df-6d36f797dee8=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) assignedTasks: ([0_0, 1_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2018-12-15 18:01:43,319 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Successfully joined group with generation 8
2018-12-15 18:01:43,322 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Setting newly assigned partitions [wordcount-lambda-example-shop-items-store-repartition-0, shop-items-0]
2018-12-15 18:01:43,323 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2018-12-15 18:01:43,347 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition assignment took 24 ms.
	current active tasks: [0_0, 1_0]
	current standby tasks: []
	previous active tasks: []

2018-12-15 18:01:43,354 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Resetting offset for partition wordcount-lambda-example-shop-items-store-repartition-0 to offset 0.
2018-12-15 18:01:43,355 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Resetting offset for partition shop-items-0 to offset 0.
2018-12-15 18:01:43,407 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:01:43,412 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:01:43,413 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:01:43,414 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2018-12-15 18:01:43,414 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from REBALANCING to RUNNING
2018-12-15 18:01:43,443 ERROR wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.AssignedStreamsTasks - stream-thread [wordcount-lambda-example-client-StreamThread-1] Failed to process stream task 0_0 due to the following error:
java.lang.ClassCastException: [B cannot be cast to java.util.UUID
	at org.apache.kafka.streams.kstream.internals.KStreamImpl.lambda$internalSelectKey$29(KStreamImpl.java:185)
	at org.apache.kafka.streams.kstream.internals.KStreamMap$KStreamMapProcessor.process(KStreamMap.java:41)
	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:115)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:146)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:129)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:93)
	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:351)
	at org.apache.kafka.streams.processor.internals.AssignedStreamsTasks.process(AssignedStreamsTasks.java:104)
	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:413)
	at org.apache.kafka.streams.processor.internals.StreamThread.runOnce(StreamThread.java:862)
	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:777)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:747)
2018-12-15 18:01:43,443 ERROR wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Encountered the following error during processing:
java.lang.ClassCastException: [B cannot be cast to java.util.UUID
	at org.apache.kafka.streams.kstream.internals.KStreamImpl.lambda$internalSelectKey$29(KStreamImpl.java:185)
	at org.apache.kafka.streams.kstream.internals.KStreamMap$KStreamMapProcessor.process(KStreamMap.java:41)
	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:115)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:146)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:129)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:93)
	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:351)
	at org.apache.kafka.streams.processor.internals.AssignedStreamsTasks.process(AssignedStreamsTasks.java:104)
	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:413)
	at org.apache.kafka.streams.processor.internals.StreamThread.runOnce(StreamThread.java:862)
	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:777)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:747)
2018-12-15 18:01:43,443 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:01:43,443 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutting down
2018-12-15 18:01:43,450 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:01:43,450 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=wordcount-lambda-example-client-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-12-15 18:01:43,456 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2018-12-15 18:01:43,457 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to ERROR
2018-12-15 18:01:43,457 WARN wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] All stream threads have died. The instance will be in error state and should be closed.
2018-12-15 18:01:43,457 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutdown complete
2018-12-15 18:01:43,476 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 46
2018-12-15 18:01:43,482 INFO pool-2-thread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:01:43,482 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:01:43,483 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Revoking previously assigned partitions []
2018-12-15 18:01:43,483 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] (Re-)joining group
2018-12-15 18:01:43,490 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Successfully joined group with generation 21
2018-12-15 18:01:43,491 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Setting newly assigned partitions [shop-items-commands-0]
2018-12-15 18:01:43,495 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Resetting offset for partition shop-items-commands-0 to offset 0.
2018-12-15 18:01:43,793 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:01:39 CET 2018]; root of context hierarchy
2018-12-15 18:01:43,848 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-15 18:01:43,848 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-15 18:01:43,869 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:01:43,869 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:01:43,896 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:01:44,151 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.339 seconds (JVM running for 6.718)
2018-12-15 18:01:44,153 INFO pool-3-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-15T17:01:44.146Z
2018-12-15 18:01:44,194 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:01:44,229 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:01:39 CET 2018]; root of context hierarchy
2018-12-15 18:01:44,236 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from ERROR to PENDING_SHUTDOWN
2018-12-15 18:01:44,239 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Informed to shut down
2018-12-15 18:01:44,240 INFO kafka-streams-close-thread  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from PENDING_SHUTDOWN to NOT_RUNNING
2018-12-15 18:01:44,241 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Streams client stopped completely
2018-12-15 18:01:44,241 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-15 18:01:44,242 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:01:44,245 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:01:59,048 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 18:01:59,063 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 18:01:59,074 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ae42ce3, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4f5991f6, org.springframework.test.context.support.DirtiesContextTestExecutionListener@484094a5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@38234a38, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@63fbfaeb]
2018-12-15 18:01:59,805 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11143 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 18:01:59,807 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 18:01:59,867 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:01:59 CET 2018]; root of context hierarchy
2018-12-15 18:02:00,243 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 18:02:00,948 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$d0b6a69] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 18:02:02,214 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 18:02:02,222 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 18:02:02,298 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 18:02:02,299 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 18:02:02,301 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 18:02:02,449 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 18:02:02,497 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 18:02:02,618 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 18:02:02,818 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:02:02,826 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:02:03,352 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 18:02:03,380 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 18:02:03,424 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:02:03,424 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:02:03,429 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 18:02:03,432 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:02:03,465 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:02:03,465 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:02:03,466 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 18:02:03,468 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 18:02:03,486 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:02:03,486 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:02:03,492 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 18:02:03,494 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:02:03,502 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 18:02:03,502 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:02:03,502 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:02:03,507 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Starting
2018-12-15 18:02:03,508 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to RUNNING
2018-12-15 18:02:03,509 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 18:02:03,516 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:02:03,519 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:02:03,519 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:02:03,552 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-15 18:02:03,554 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:02:03,555 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:02:03,555 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:02:03,562 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 18:02:03,566 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:02:03,566 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:02:03,569 WARN main  org.apache.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=my-client-id
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:62)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:425)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:316)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.createProducer(CommandsProcessor.java:83)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>(CommandsProcessor.java:53)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 18:02:03,570 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-15 18:02:03,595 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:02:03,596 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:02:03,603 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Revoking previously assigned partitions []
2018-12-15 18:02:03,603 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-12-15 18:02:03,603 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to REBALANCING
2018-12-15 18:02:03,604 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:02:03,604 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition revocation took 1 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-12-15 18:02:03,604 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] (Re-)joining group
2018-12-15 18:02:03,627 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wordcount-lambda-example-client-StreamThread-1-consumer] Assigned tasks to clients as {fe626a08-27c2-45d9-afec-ed7e22eb097a=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) assignedTasks: ([0_0, 1_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2018-12-15 18:02:03,633 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Successfully joined group with generation 10
2018-12-15 18:02:03,636 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Setting newly assigned partitions [wordcount-lambda-example-shop-items-store-repartition-0, shop-items-0]
2018-12-15 18:02:03,636 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2018-12-15 18:02:03,662 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition assignment took 26 ms.
	current active tasks: [0_0, 1_0]
	current standby tasks: []
	previous active tasks: []

2018-12-15 18:02:03,670 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Resetting offset for partition wordcount-lambda-example-shop-items-store-repartition-0 to offset 0.
2018-12-15 18:02:03,670 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Resetting offset for partition shop-items-0 to offset 0.
2018-12-15 18:02:03,731 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:02:03,736 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:02:03,738 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:02:03,738 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2018-12-15 18:02:03,739 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from REBALANCING to RUNNING
2018-12-15 18:02:03,767 ERROR wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.AssignedStreamsTasks - stream-thread [wordcount-lambda-example-client-StreamThread-1] Failed to process stream task 0_0 due to the following error:
java.lang.ClassCastException: [B cannot be cast to java.util.UUID
	at org.apache.kafka.streams.kstream.internals.KStreamImpl.lambda$internalSelectKey$29(KStreamImpl.java:185)
	at org.apache.kafka.streams.kstream.internals.KStreamMap$KStreamMapProcessor.process(KStreamMap.java:41)
	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:115)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:146)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:129)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:93)
	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:351)
	at org.apache.kafka.streams.processor.internals.AssignedStreamsTasks.process(AssignedStreamsTasks.java:104)
	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:413)
	at org.apache.kafka.streams.processor.internals.StreamThread.runOnce(StreamThread.java:862)
	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:777)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:747)
2018-12-15 18:02:03,767 ERROR wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Encountered the following error during processing:
java.lang.ClassCastException: [B cannot be cast to java.util.UUID
	at org.apache.kafka.streams.kstream.internals.KStreamImpl.lambda$internalSelectKey$29(KStreamImpl.java:185)
	at org.apache.kafka.streams.kstream.internals.KStreamMap$KStreamMapProcessor.process(KStreamMap.java:41)
	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:115)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:146)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:129)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:93)
	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:351)
	at org.apache.kafka.streams.processor.internals.AssignedStreamsTasks.process(AssignedStreamsTasks.java:104)
	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:413)
	at org.apache.kafka.streams.processor.internals.StreamThread.runOnce(StreamThread.java:862)
	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:777)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:747)
2018-12-15 18:02:03,767 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:02:03,767 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutting down
2018-12-15 18:02:03,773 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:02:03,774 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=wordcount-lambda-example-client-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-12-15 18:02:03,780 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2018-12-15 18:02:03,781 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to ERROR
2018-12-15 18:02:03,781 WARN wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] All stream threads have died. The instance will be in error state and should be closed.
2018-12-15 18:02:03,781 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutdown complete
2018-12-15 18:02:03,792 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 47
2018-12-15 18:02:03,797 INFO pool-2-thread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:02:03,798 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:02:03,798 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Revoking previously assigned partitions []
2018-12-15 18:02:03,799 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] (Re-)joining group
2018-12-15 18:02:03,804 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Successfully joined group with generation 23
2018-12-15 18:02:03,804 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Setting newly assigned partitions [shop-items-commands-0]
2018-12-15 18:02:03,808 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Resetting offset for partition shop-items-commands-0 to offset 0.
2018-12-15 18:02:04,118 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:01:59 CET 2018]; root of context hierarchy
2018-12-15 18:02:04,177 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-15 18:02:04,177 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-15 18:02:04,199 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:02:04,199 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:02:04,227 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:02:04,476 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.295 seconds (JVM running for 6.72)
2018-12-15 18:02:04,478 INFO pool-3-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-15T17:02:04.471Z
2018-12-15 18:02:04,519 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:02:04,652 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:01:59 CET 2018]; root of context hierarchy
2018-12-15 18:02:04,656 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from ERROR to PENDING_SHUTDOWN
2018-12-15 18:02:04,657 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Informed to shut down
2018-12-15 18:02:04,659 INFO kafka-streams-close-thread  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from PENDING_SHUTDOWN to NOT_RUNNING
2018-12-15 18:02:04,659 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Streams client stopped completely
2018-12-15 18:02:04,659 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-15 18:02:04,660 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:02:04,663 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:04:05,001 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 18:04:05,017 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 18:04:05,032 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@47a64f7d, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@33d05366, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@27a0a5a2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@7692cd34, org.springframework.test.context.transaction.TransactionalTestExecutionListener@33aa93c, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@32c0915e]
2018-12-15 18:04:05,842 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11151 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 18:04:05,842 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 18:04:05,912 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@279dd959: startup date [Sat Dec 15 18:04:05 CET 2018]; root of context hierarchy
2018-12-15 18:04:06,372 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 18:04:07,160 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$657885fc] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 18:04:08,731 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 18:04:08,744 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 18:04:08,838 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 18:04:08,840 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 18:04:08,843 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 18:04:09,053 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 18:04:09,138 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 18:04:09,272 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 18:04:09,504 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:04:09,513 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:04:10,154 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 18:04:10,184 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 18:04:10,229 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:04:10,229 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:04:10,235 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 18:04:10,238 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:04:10,275 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:04:10,276 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:04:10,277 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 18:04:10,279 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 18:04:10,300 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:04:10,300 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:04:10,307 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 18:04:10,308 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:04:10,317 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 18:04:10,317 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:04:10,317 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:04:10,323 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Starting
2018-12-15 18:04:10,323 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to RUNNING
2018-12-15 18:04:10,325 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 18:04:10,332 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:04:10,335 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:04:10,336 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:04:14,495 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-15 18:04:14,499 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:04:14,500 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:04:14,500 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:04:14,507 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 18:04:14,510 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:04:14,510 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:04:14,513 WARN main  org.apache.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=my-client-id
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:62)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:425)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:316)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.createProducer(CommandsProcessor.java:83)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>(CommandsProcessor.java:53)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 18:04:14,514 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-15 18:04:14,548 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:04:14,549 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:04:14,555 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Revoking previously assigned partitions []
2018-12-15 18:04:14,555 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-12-15 18:04:14,556 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to REBALANCING
2018-12-15 18:04:14,556 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:04:14,556 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition revocation took 0 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-12-15 18:04:14,556 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] (Re-)joining group
2018-12-15 18:04:14,577 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wordcount-lambda-example-client-StreamThread-1-consumer] Assigned tasks to clients as {6cf4bc35-71f2-43b8-b8eb-49a4bec89b20=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) assignedTasks: ([0_0, 1_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2018-12-15 18:04:14,582 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Successfully joined group with generation 12
2018-12-15 18:04:14,585 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Setting newly assigned partitions [wordcount-lambda-example-shop-items-store-repartition-0, shop-items-0]
2018-12-15 18:04:14,585 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2018-12-15 18:04:14,609 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition assignment took 24 ms.
	current active tasks: [0_0, 1_0]
	current standby tasks: []
	previous active tasks: []

2018-12-15 18:04:14,616 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Resetting offset for partition wordcount-lambda-example-shop-items-store-repartition-0 to offset 0.
2018-12-15 18:04:14,617 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Resetting offset for partition shop-items-0 to offset 0.
2018-12-15 18:04:14,655 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:04:14,661 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:04:14,663 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:04:14,663 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2018-12-15 18:04:14,664 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from REBALANCING to RUNNING
2018-12-15 18:04:14,697 ERROR wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.AssignedStreamsTasks - stream-thread [wordcount-lambda-example-client-StreamThread-1] Failed to process stream task 0_0 due to the following error:
java.lang.ClassCastException: [B cannot be cast to java.util.UUID
	at org.apache.kafka.streams.kstream.internals.KStreamImpl.lambda$internalSelectKey$29(KStreamImpl.java:185)
	at org.apache.kafka.streams.kstream.internals.KStreamMap$KStreamMapProcessor.process(KStreamMap.java:41)
	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:115)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:146)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:129)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:93)
	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:351)
	at org.apache.kafka.streams.processor.internals.AssignedStreamsTasks.process(AssignedStreamsTasks.java:104)
	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:413)
	at org.apache.kafka.streams.processor.internals.StreamThread.runOnce(StreamThread.java:862)
	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:777)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:747)
2018-12-15 18:04:14,697 ERROR wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Encountered the following error during processing:
java.lang.ClassCastException: [B cannot be cast to java.util.UUID
	at org.apache.kafka.streams.kstream.internals.KStreamImpl.lambda$internalSelectKey$29(KStreamImpl.java:185)
	at org.apache.kafka.streams.kstream.internals.KStreamMap$KStreamMapProcessor.process(KStreamMap.java:41)
	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:115)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:146)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:129)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:93)
	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:351)
	at org.apache.kafka.streams.processor.internals.AssignedStreamsTasks.process(AssignedStreamsTasks.java:104)
	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:413)
	at org.apache.kafka.streams.processor.internals.StreamThread.runOnce(StreamThread.java:862)
	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:777)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:747)
2018-12-15 18:04:14,697 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:04:14,697 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutting down
2018-12-15 18:04:14,703 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:04:14,703 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=wordcount-lambda-example-client-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-12-15 18:04:14,709 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2018-12-15 18:04:14,710 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to ERROR
2018-12-15 18:04:14,710 WARN wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] All stream threads have died. The instance will be in error state and should be closed.
2018-12-15 18:04:14,710 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutdown complete
2018-12-15 18:04:14,739 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 48
2018-12-15 18:04:14,744 INFO pool-2-thread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:04:14,745 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:04:14,745 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Revoking previously assigned partitions []
2018-12-15 18:04:14,745 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] (Re-)joining group
2018-12-15 18:04:14,750 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Successfully joined group with generation 25
2018-12-15 18:04:14,751 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Setting newly assigned partitions [shop-items-commands-0]
2018-12-15 18:04:14,754 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Resetting offset for partition shop-items-commands-0 to offset 0.
2018-12-15 18:04:19,740 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@279dd959: startup date [Sat Dec 15 18:04:05 CET 2018]; root of context hierarchy
2018-12-15 18:04:19,805 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-15 18:04:19,806 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-15 18:04:19,832 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:04:19,832 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:04:19,865 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:04:20,243 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 15.086 seconds (JVM running for 16.876)
2018-12-15 18:04:20,246 INFO pool-3-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-15T17:04:20.237Z
2018-12-15 18:04:20,294 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:04:40,336 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@279dd959: startup date [Sat Dec 15 18:04:05 CET 2018]; root of context hierarchy
2018-12-15 18:04:40,339 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from ERROR to PENDING_SHUTDOWN
2018-12-15 18:04:40,340 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Informed to shut down
2018-12-15 18:04:40,342 INFO kafka-streams-close-thread  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from PENDING_SHUTDOWN to NOT_RUNNING
2018-12-15 18:04:40,342 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Streams client stopped completely
2018-12-15 18:04:40,342 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-15 18:04:40,343 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:04:40,348 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:06:19,860 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 18:06:19,870 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 18:06:19,881 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ae42ce3, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4f5991f6, org.springframework.test.context.support.DirtiesContextTestExecutionListener@484094a5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@38234a38, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@63fbfaeb]
2018-12-15 18:06:20,558 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11163 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 18:06:20,559 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 18:06:20,616 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:06:20 CET 2018]; root of context hierarchy
2018-12-15 18:06:21,008 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 18:06:21,713 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$d0b6a69] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 18:06:22,979 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 18:06:22,986 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 18:06:23,039 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 18:06:23,041 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 18:06:23,042 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 18:06:23,192 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 18:06:23,238 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 18:06:23,351 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 18:06:23,535 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:06:23,543 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:06:24,097 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 18:06:24,130 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 18:06:24,181 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:06:24,181 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:06:24,188 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 18:06:24,192 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:06:24,230 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:06:24,230 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:06:24,231 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 18:06:24,233 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 18:06:24,254 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:06:24,254 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:06:24,262 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 18:06:24,263 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:06:24,271 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 18:06:24,271 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:06:24,271 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:06:24,276 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Starting
2018-12-15 18:06:24,276 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to RUNNING
2018-12-15 18:06:24,277 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 18:06:24,284 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:06:24,287 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:06:24,288 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:06:24,327 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-15 18:06:24,330 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:06:24,331 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:06:24,332 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:06:24,339 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 18:06:24,343 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:06:24,343 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:06:24,346 WARN main  org.apache.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=my-client-id
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:62)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:425)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:316)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.createProducer(CommandsProcessor.java:83)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>(CommandsProcessor.java:53)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 18:06:24,347 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-15 18:06:24,384 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:06:24,386 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:06:24,395 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Revoking previously assigned partitions []
2018-12-15 18:06:24,395 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-12-15 18:06:24,395 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to REBALANCING
2018-12-15 18:06:24,395 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:06:24,396 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition revocation took 1 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-12-15 18:06:24,396 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] (Re-)joining group
2018-12-15 18:06:24,419 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wordcount-lambda-example-client-StreamThread-1-consumer] Assigned tasks to clients as {b28ac47a-72bb-4a69-a4ff-789005e86749=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) assignedTasks: ([0_0, 1_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2018-12-15 18:06:24,424 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Successfully joined group with generation 1
2018-12-15 18:06:24,428 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Setting newly assigned partitions [wordcount-lambda-example-shop-items-store-repartition-0, shop-items-0]
2018-12-15 18:06:24,428 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2018-12-15 18:06:24,453 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition assignment took 25 ms.
	current active tasks: [0_0, 1_0]
	current standby tasks: []
	previous active tasks: []

2018-12-15 18:06:24,460 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Resetting offset for partition wordcount-lambda-example-shop-items-store-repartition-0 to offset 0.
2018-12-15 18:06:24,460 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Resetting offset for partition shop-items-0 to offset 0.
2018-12-15 18:06:24,508 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:06:24,513 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:06:24,515 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:06:24,515 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2018-12-15 18:06:24,515 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from REBALANCING to RUNNING
2018-12-15 18:06:24,542 ERROR wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.AssignedStreamsTasks - stream-thread [wordcount-lambda-example-client-StreamThread-1] Failed to process stream task 0_0 due to the following error:
java.lang.ClassCastException: [B cannot be cast to java.util.UUID
	at org.apache.kafka.streams.kstream.internals.KStreamImpl.lambda$internalSelectKey$29(KStreamImpl.java:185)
	at org.apache.kafka.streams.kstream.internals.KStreamMap$KStreamMapProcessor.process(KStreamMap.java:41)
	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:115)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:146)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:129)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:93)
	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:351)
	at org.apache.kafka.streams.processor.internals.AssignedStreamsTasks.process(AssignedStreamsTasks.java:104)
	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:413)
	at org.apache.kafka.streams.processor.internals.StreamThread.runOnce(StreamThread.java:862)
	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:777)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:747)
2018-12-15 18:06:24,542 ERROR wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Encountered the following error during processing:
java.lang.ClassCastException: [B cannot be cast to java.util.UUID
	at org.apache.kafka.streams.kstream.internals.KStreamImpl.lambda$internalSelectKey$29(KStreamImpl.java:185)
	at org.apache.kafka.streams.kstream.internals.KStreamMap$KStreamMapProcessor.process(KStreamMap.java:41)
	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:115)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:146)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:129)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:93)
	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:351)
	at org.apache.kafka.streams.processor.internals.AssignedStreamsTasks.process(AssignedStreamsTasks.java:104)
	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:413)
	at org.apache.kafka.streams.processor.internals.StreamThread.runOnce(StreamThread.java:862)
	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:777)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:747)
2018-12-15 18:06:24,542 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:06:24,542 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutting down
2018-12-15 18:06:24,548 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:06:24,549 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=wordcount-lambda-example-client-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-12-15 18:06:24,555 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2018-12-15 18:06:24,555 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to ERROR
2018-12-15 18:06:24,555 WARN wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] All stream threads have died. The instance will be in error state and should be closed.
2018-12-15 18:06:24,556 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutdown complete
2018-12-15 18:06:24,569 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 49
2018-12-15 18:06:24,575 INFO pool-2-thread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:06:24,576 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:06:24,576 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Revoking previously assigned partitions []
2018-12-15 18:06:24,576 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] (Re-)joining group
2018-12-15 18:06:24,584 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Successfully joined group with generation 27
2018-12-15 18:06:24,585 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Setting newly assigned partitions [shop-items-commands-0]
2018-12-15 18:06:24,589 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Resetting offset for partition shop-items-commands-0 to offset 0.
2018-12-15 18:06:24,902 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:06:20 CET 2018]; root of context hierarchy
2018-12-15 18:06:24,959 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-15 18:06:24,960 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-15 18:06:24,981 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:06:24,981 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:06:25,009 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:06:25,247 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.268 seconds (JVM running for 6.666)
2018-12-15 18:06:25,249 INFO pool-3-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-15T17:06:25.242Z
2018-12-15 18:06:25,288 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:06:32,650 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:06:20 CET 2018]; root of context hierarchy
2018-12-15 18:06:32,653 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from ERROR to PENDING_SHUTDOWN
2018-12-15 18:06:32,654 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Informed to shut down
2018-12-15 18:06:32,655 INFO kafka-streams-close-thread  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from PENDING_SHUTDOWN to NOT_RUNNING
2018-12-15 18:06:32,656 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Streams client stopped completely
2018-12-15 18:06:32,656 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-15 18:06:32,656 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:06:32,660 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:07:31,474 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 18:07:31,488 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 18:07:31,501 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ae42ce3, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4f5991f6, org.springframework.test.context.support.DirtiesContextTestExecutionListener@484094a5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@38234a38, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@63fbfaeb]
2018-12-15 18:07:32,274 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11170 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 18:07:32,274 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 18:07:32,333 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:07:32 CET 2018]; root of context hierarchy
2018-12-15 18:07:32,720 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 18:07:33,465 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$d0b6a69] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 18:07:34,818 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 18:07:34,825 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 18:07:34,882 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 18:07:34,884 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 18:07:34,885 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 18:07:35,042 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 18:07:35,088 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 18:07:35,205 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 18:07:35,411 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:07:35,419 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:07:35,927 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 18:07:35,952 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 18:07:35,988 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:07:35,988 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:07:35,993 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 18:07:35,995 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:07:36,022 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:07:36,022 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:07:36,023 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 18:07:36,025 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 18:07:36,043 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:07:36,043 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:07:36,049 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 18:07:36,051 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:07:36,059 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 18:07:36,059 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:07:36,059 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:07:36,063 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Starting
2018-12-15 18:07:36,064 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to RUNNING
2018-12-15 18:07:36,064 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 18:07:36,070 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:07:36,073 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:07:36,073 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:07:36,106 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-15 18:07:36,108 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:07:36,109 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:07:36,109 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:07:36,115 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 18:07:36,118 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:07:36,118 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:07:36,120 WARN main  org.apache.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=my-client-id
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:62)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:425)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:316)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.createProducer(CommandsProcessor.java:83)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>(CommandsProcessor.java:53)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 18:07:36,121 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-15 18:07:36,150 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:07:36,150 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:07:36,156 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Revoking previously assigned partitions []
2018-12-15 18:07:36,156 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-12-15 18:07:36,157 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to REBALANCING
2018-12-15 18:07:36,157 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:07:36,157 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition revocation took 0 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-12-15 18:07:36,157 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] (Re-)joining group
2018-12-15 18:07:36,177 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wordcount-lambda-example-client-StreamThread-1-consumer] Assigned tasks to clients as {189aabe4-f1cd-4da9-b05c-120040ece69a=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) assignedTasks: ([0_0, 1_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2018-12-15 18:07:36,183 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Successfully joined group with generation 3
2018-12-15 18:07:36,186 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Setting newly assigned partitions [wordcount-lambda-example-shop-items-store-repartition-0, shop-items-0]
2018-12-15 18:07:36,186 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2018-12-15 18:07:36,213 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition assignment took 27 ms.
	current active tasks: [0_0, 1_0]
	current standby tasks: []
	previous active tasks: []

2018-12-15 18:07:36,222 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Resetting offset for partition wordcount-lambda-example-shop-items-store-repartition-0 to offset 0.
2018-12-15 18:07:36,222 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Resetting offset for partition shop-items-0 to offset 0.
2018-12-15 18:07:36,304 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:07:36,308 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:07:36,311 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:07:36,311 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2018-12-15 18:07:36,311 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from REBALANCING to RUNNING
2018-12-15 18:07:36,342 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 50
2018-12-15 18:07:36,349 INFO pool-2-thread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:07:36,349 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:07:36,350 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Revoking previously assigned partitions []
2018-12-15 18:07:36,351 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] (Re-)joining group
2018-12-15 18:07:36,357 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Successfully joined group with generation 29
2018-12-15 18:07:36,359 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Setting newly assigned partitions [shop-items-commands-0]
2018-12-15 18:07:36,363 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Resetting offset for partition shop-items-commands-0 to offset 0.
2018-12-15 18:07:36,366 ERROR wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.AssignedStreamsTasks - stream-thread [wordcount-lambda-example-client-StreamThread-1] Failed to process stream task 0_0 due to the following error:
org.apache.kafka.streams.errors.StreamsException: Exception caught in process. taskId=0_0, processor=KSTREAM-SOURCE-0000000000, topic=shop-items, partition=0, offset=0
	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:367)
	at org.apache.kafka.streams.processor.internals.AssignedStreamsTasks.process(AssignedStreamsTasks.java:104)
	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:413)
	at org.apache.kafka.streams.processor.internals.StreamThread.runOnce(StreamThread.java:862)
	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:777)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:747)
Caused by: org.apache.kafka.streams.errors.StreamsException: A serializer (key: org.apache.kafka.common.serialization.ByteArraySerializer / value: org.springframework.kafka.support.serializer.JsonSerializer) is not compatible to the actual key or value type (key type: java.util.UUID / value type: io.dddbyexamples.eventsource.domain.shopitem.events.ItemBought). Change the default Serdes in StreamConfig or provide correct Serdes via method parameters.
	at org.apache.kafka.streams.processor.internals.SinkNode.process(SinkNode.java:94)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:146)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:129)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:93)
	at org.apache.kafka.streams.kstream.internals.KStreamFilter$KStreamFilterProcessor.process(KStreamFilter.java:43)
	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:115)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:146)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:129)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:93)
	at org.apache.kafka.streams.kstream.internals.KStreamMap$KStreamMapProcessor.process(KStreamMap.java:42)
	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:115)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:146)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:129)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:93)
	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:351)
	... 5 common frames omitted
Caused by: java.lang.ClassCastException: java.util.UUID cannot be cast to [B
	at org.apache.kafka.common.serialization.ByteArraySerializer.serialize(ByteArraySerializer.java:21)
	at org.apache.kafka.common.serialization.Serializer.serialize(Serializer.java:60)
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.send(RecordCollectorImpl.java:156)
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.send(RecordCollectorImpl.java:101)
	at org.apache.kafka.streams.processor.internals.SinkNode.process(SinkNode.java:89)
	... 20 common frames omitted
2018-12-15 18:07:36,366 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:07:36,366 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutting down
2018-12-15 18:07:36,374 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:07:36,374 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=wordcount-lambda-example-client-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-12-15 18:07:36,381 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2018-12-15 18:07:36,381 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to ERROR
2018-12-15 18:07:36,381 WARN wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] All stream threads have died. The instance will be in error state and should be closed.
2018-12-15 18:07:36,381 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutdown complete
2018-12-15 18:07:36,675 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:07:32 CET 2018]; root of context hierarchy
2018-12-15 18:07:36,736 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-15 18:07:36,737 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-15 18:07:36,759 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:07:36,759 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:07:36,786 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:07:37,032 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.415 seconds (JVM running for 6.857)
2018-12-15 18:07:37,035 INFO pool-3-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-15T17:07:37.028Z
2018-12-15 18:07:37,076 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:07:39,835 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:07:32 CET 2018]; root of context hierarchy
2018-12-15 18:07:39,840 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from ERROR to PENDING_SHUTDOWN
2018-12-15 18:07:39,841 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Informed to shut down
2018-12-15 18:07:39,843 INFO kafka-streams-close-thread  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from PENDING_SHUTDOWN to NOT_RUNNING
2018-12-15 18:07:39,843 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Streams client stopped completely
2018-12-15 18:07:39,844 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-15 18:07:39,844 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:07:39,848 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:08:59,822 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 18:08:59,836 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 18:08:59,848 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ae42ce3, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4f5991f6, org.springframework.test.context.support.DirtiesContextTestExecutionListener@484094a5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@38234a38, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@63fbfaeb]
2018-12-15 18:09:00,593 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11176 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 18:09:00,594 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 18:09:00,653 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:09:00 CET 2018]; root of context hierarchy
2018-12-15 18:09:01,033 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 18:09:01,708 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$fe9865e4] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 18:09:02,971 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 18:09:02,980 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 18:09:03,049 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 18:09:03,050 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 18:09:03,051 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 18:09:03,219 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 18:09:03,275 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 18:09:03,422 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 18:09:03,643 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:09:03,652 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:09:04,162 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 18:09:04,196 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 18:09:04,243 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:09:04,243 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:09:04,249 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 18:09:04,252 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:09:04,289 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:09:04,289 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:09:04,290 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 18:09:04,292 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 18:09:04,312 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:09:04,312 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:09:04,319 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 18:09:04,320 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:09:04,329 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 18:09:04,329 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:09:04,329 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:09:04,334 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Starting
2018-12-15 18:09:04,334 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to RUNNING
2018-12-15 18:09:04,335 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 18:09:04,342 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:09:04,345 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:09:04,345 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:09:04,380 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-15 18:09:04,383 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:09:04,383 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:09:04,384 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:09:04,390 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 18:09:04,393 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:09:04,393 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:09:04,395 WARN main  org.apache.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=my-client-id
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:62)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:425)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:316)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.createProducer(CommandsProcessor.java:83)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>(CommandsProcessor.java:53)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 18:09:04,396 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-15 18:09:04,426 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:09:04,426 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:09:04,433 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Revoking previously assigned partitions []
2018-12-15 18:09:04,433 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-12-15 18:09:04,433 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to REBALANCING
2018-12-15 18:09:04,434 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:09:04,434 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition revocation took 1 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-12-15 18:09:04,434 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] (Re-)joining group
2018-12-15 18:09:04,456 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wordcount-lambda-example-client-StreamThread-1-consumer] Assigned tasks to clients as {c0a8798c-268d-4125-b981-a925ecf06be4=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) assignedTasks: ([0_0, 1_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2018-12-15 18:09:04,461 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Successfully joined group with generation 5
2018-12-15 18:09:04,464 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Setting newly assigned partitions [wordcount-lambda-example-shop-items-store-repartition-0, shop-items-0]
2018-12-15 18:09:04,464 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2018-12-15 18:09:04,489 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition assignment took 25 ms.
	current active tasks: [0_0, 1_0]
	current standby tasks: []
	previous active tasks: []

2018-12-15 18:09:04,496 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Resetting offset for partition wordcount-lambda-example-shop-items-store-repartition-0 to offset 0.
2018-12-15 18:09:04,497 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Resetting offset for partition shop-items-0 to offset 0.
2018-12-15 18:09:04,561 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:09:04,566 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:09:04,568 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:09:04,568 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2018-12-15 18:09:04,568 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from REBALANCING to RUNNING
2018-12-15 18:09:04,620 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 51
2018-12-15 18:09:04,626 INFO pool-2-thread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:09:04,626 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:09:04,627 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Revoking previously assigned partitions []
2018-12-15 18:09:04,627 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] (Re-)joining group
2018-12-15 18:09:04,633 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Successfully joined group with generation 31
2018-12-15 18:09:04,634 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Setting newly assigned partitions [shop-items-commands-0]
2018-12-15 18:09:04,634 INFO kafka-producer-network-thread | wordcount-lambda-example-client-StreamThread-1-producer  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:09:04,639 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Resetting offset for partition shop-items-commands-0 to offset 0.
2018-12-15 18:09:04,711 ERROR wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.AssignedStreamsTasks - stream-thread [wordcount-lambda-example-client-StreamThread-1] Failed to process stream task 1_0 due to the following error:
org.apache.kafka.streams.errors.StreamsException: Exception caught in process. taskId=1_0, processor=KSTREAM-SOURCE-0000000005, topic=wordcount-lambda-example-shop-items-store-repartition, partition=0, offset=11
	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:367)
	at org.apache.kafka.streams.processor.internals.AssignedStreamsTasks.process(AssignedStreamsTasks.java:104)
	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:413)
	at org.apache.kafka.streams.processor.internals.StreamThread.runOnce(StreamThread.java:862)
	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:777)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:747)
Caused by: org.apache.kafka.common.errors.SerializationException: Can't deserialize data [[123, 34, 117, 117, 105, 100, 34, 58, 34, 53, 57, 98, 55, 100, 100, 100, 99, 45, 98, 51, 52, 49, 45, 52, 101, 51, 97, 45, 57, 48, 57, 98, 45, 100, 52, 51, 55, 49, 54, 48, 56, 57, 51, 51, 57, 34, 44, 34, 99, 104, 97, 110, 103, 101, 115, 34, 58, 91, 93, 44, 34, 115, 116, 97, 116, 101, 34, 58, 34, 66, 79, 85, 71, 72, 84, 34, 44, 34, 117, 110, 99, 111, 109, 109, 105, 116, 116, 101, 100, 67, 104, 97, 110, 103, 101, 115, 34, 58, 91, 93, 125]] from topic [wordcount-lambda-example-shop-items-store-changelog]
Caused by: com.fasterxml.jackson.databind.JsonMappingException: Can not find a deserializer for non-concrete Collection type [collection type; class com.google.common.collect.ImmutableList, contains [simple type, class io.dddbyexamples.eventsource.domain.shopitem.events.DomainEvent]]
 at [Source: [B@e68e0be; line: 1, column: 1]
	at com.fasterxml.jackson.databind.JsonMappingException.from(JsonMappingException.java:290)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCache2(DeserializerCache.java:269)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCacheValueDeserializer(DeserializerCache.java:244)
	at com.fasterxml.jackson.databind.deser.DeserializerCache.findValueDeserializer(DeserializerCache.java:142)
	at com.fasterxml.jackson.databind.DeserializationContext.findContextualValueDeserializer(DeserializationContext.java:444)
	at com.fasterxml.jackson.databind.deser.std.StdDeserializer.findDeserializer(StdDeserializer.java:948)
	at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.resolve(BeanDeserializerBase.java:446)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCache2(DeserializerCache.java:296)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCacheValueDeserializer(DeserializerCache.java:244)
	at com.fasterxml.jackson.databind.deser.DeserializerCache.findValueDeserializer(DeserializerCache.java:142)
	at com.fasterxml.jackson.databind.DeserializationContext.findRootValueDeserializer(DeserializationContext.java:477)
	at com.fasterxml.jackson.databind.ObjectReader._findRootDeserializer(ObjectReader.java:1816)
	at com.fasterxml.jackson.databind.ObjectReader._bindAndClose(ObjectReader.java:1573)
	at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1217)
	at org.springframework.kafka.support.serializer.JsonDeserializer.deserialize(JsonDeserializer.java:343)
	at org.apache.kafka.streams.state.StateSerdes.valueFrom(StateSerdes.java:159)
	at org.apache.kafka.streams.state.internals.MeteredKeyValueStore.outerValue(MeteredKeyValueStore.java:245)
	at org.apache.kafka.streams.state.internals.MeteredKeyValueStore.get(MeteredKeyValueStore.java:137)
	at org.apache.kafka.streams.kstream.internals.KStreamAggregate$KStreamAggregateProcessor.process(KStreamAggregate.java:82)
	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:115)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:146)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:129)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:93)
	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:351)
	at org.apache.kafka.streams.processor.internals.AssignedStreamsTasks.process(AssignedStreamsTasks.java:104)
	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:413)
	at org.apache.kafka.streams.processor.internals.StreamThread.runOnce(StreamThread.java:862)
	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:777)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:747)
Caused by: java.lang.IllegalArgumentException: Can not find a deserializer for non-concrete Collection type [collection type; class com.google.common.collect.ImmutableList, contains [simple type, class io.dddbyexamples.eventsource.domain.shopitem.events.DomainEvent]]
	at com.fasterxml.jackson.databind.deser.BasicDeserializerFactory.createCollectionDeserializer(BasicDeserializerFactory.java:1014)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createDeserializer2(DeserializerCache.java:394)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createDeserializer(DeserializerCache.java:352)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCache2(DeserializerCache.java:264)
	... 28 common frames omitted
2018-12-15 18:09:04,711 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:09:04,711 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutting down
2018-12-15 18:09:04,717 ERROR wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.ProcessorStateManager - task [1_0] Failed to close state store shop-items-store: 
org.apache.kafka.common.errors.SerializationException: Can't deserialize data [[123, 34, 117, 117, 105, 100, 34, 58, 34, 52, 52, 100, 57, 102, 102, 48, 54, 45, 102, 52, 51, 101, 45, 52, 50, 49, 54, 45, 57, 51, 52, 54, 45, 56, 48, 98, 57, 50, 49, 53, 52, 99, 101, 53, 98, 34, 44, 34, 99, 104, 97, 110, 103, 101, 115, 34, 58, 91, 93, 44, 34, 115, 116, 97, 116, 101, 34, 58, 34, 66, 79, 85, 71, 72, 84, 34, 44, 34, 117, 110, 99, 111, 109, 109, 105, 116, 116, 101, 100, 67, 104, 97, 110, 103, 101, 115, 34, 58, 91, 93, 125]] from topic [wordcount-lambda-example-shop-items-store-changelog]
Caused by: com.fasterxml.jackson.databind.JsonMappingException: Can not find a deserializer for non-concrete Collection type [collection type; class com.google.common.collect.ImmutableList, contains [simple type, class io.dddbyexamples.eventsource.domain.shopitem.events.DomainEvent]]
 at [Source: [B@3a5cf284; line: 1, column: 1]
	at com.fasterxml.jackson.databind.JsonMappingException.from(JsonMappingException.java:290)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCache2(DeserializerCache.java:269)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCacheValueDeserializer(DeserializerCache.java:244)
	at com.fasterxml.jackson.databind.deser.DeserializerCache.findValueDeserializer(DeserializerCache.java:142)
	at com.fasterxml.jackson.databind.DeserializationContext.findContextualValueDeserializer(DeserializationContext.java:444)
	at com.fasterxml.jackson.databind.deser.std.StdDeserializer.findDeserializer(StdDeserializer.java:948)
	at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.resolve(BeanDeserializerBase.java:446)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCache2(DeserializerCache.java:296)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCacheValueDeserializer(DeserializerCache.java:244)
	at com.fasterxml.jackson.databind.deser.DeserializerCache.findValueDeserializer(DeserializerCache.java:142)
	at com.fasterxml.jackson.databind.DeserializationContext.findRootValueDeserializer(DeserializationContext.java:477)
	at com.fasterxml.jackson.databind.ObjectReader._findRootDeserializer(ObjectReader.java:1816)
	at com.fasterxml.jackson.databind.ObjectReader._bindAndClose(ObjectReader.java:1573)
	at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1217)
	at org.springframework.kafka.support.serializer.JsonDeserializer.deserialize(JsonDeserializer.java:343)
	at org.apache.kafka.streams.state.StateSerdes.valueFrom(StateSerdes.java:159)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.putAndMaybeForward(CachingKeyValueStore.java:102)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.access$000(CachingKeyValueStore.java:38)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore$1.apply(CachingKeyValueStore.java:83)
	at org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:141)
	at org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:99)
	at org.apache.kafka.streams.state.internals.ThreadCache.flush(ThreadCache.java:124)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.flush(CachingKeyValueStore.java:123)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.close(CachingKeyValueStore.java:133)
	at org.apache.kafka.streams.state.internals.WrappedStateStore$AbstractStateStore.close(WrappedStateStore.java:90)
	at org.apache.kafka.streams.state.internals.MeteredKeyValueStore.close(MeteredKeyValueStore.java:122)
	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.close(ProcessorStateManager.java:247)
	at org.apache.kafka.streams.processor.internals.AbstractTask.closeStateManager(AbstractTask.java:251)
	at org.apache.kafka.streams.processor.internals.StreamTask.closeSuspended(StreamTask.java:648)
	at org.apache.kafka.streams.processor.internals.StreamTask.close(StreamTask.java:698)
	at org.apache.kafka.streams.processor.internals.AssignedTasks.close(AssignedTasks.java:397)
	at org.apache.kafka.streams.processor.internals.TaskManager.shutdown(TaskManager.java:260)
	at org.apache.kafka.streams.processor.internals.StreamThread.completeShutdown(StreamThread.java:1181)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:758)
Caused by: java.lang.IllegalArgumentException: Can not find a deserializer for non-concrete Collection type [collection type; class com.google.common.collect.ImmutableList, contains [simple type, class io.dddbyexamples.eventsource.domain.shopitem.events.DomainEvent]]
	at com.fasterxml.jackson.databind.deser.BasicDeserializerFactory.createCollectionDeserializer(BasicDeserializerFactory.java:1014)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createDeserializer2(DeserializerCache.java:394)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createDeserializer(DeserializerCache.java:352)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCache2(DeserializerCache.java:264)
	... 32 common frames omitted
2018-12-15 18:09:04,721 ERROR wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamTask - task [1_0] Could not close state manager due to the following error:
org.apache.kafka.streams.errors.ProcessorStateException: task [1_0] Failed to close state store shop-items-store
	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.close(ProcessorStateManager.java:250)
	at org.apache.kafka.streams.processor.internals.AbstractTask.closeStateManager(AbstractTask.java:251)
	at org.apache.kafka.streams.processor.internals.StreamTask.closeSuspended(StreamTask.java:648)
	at org.apache.kafka.streams.processor.internals.StreamTask.close(StreamTask.java:698)
	at org.apache.kafka.streams.processor.internals.AssignedTasks.close(AssignedTasks.java:397)
	at org.apache.kafka.streams.processor.internals.TaskManager.shutdown(TaskManager.java:260)
	at org.apache.kafka.streams.processor.internals.StreamThread.completeShutdown(StreamThread.java:1181)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:758)
Caused by: org.apache.kafka.common.errors.SerializationException: Can't deserialize data [[123, 34, 117, 117, 105, 100, 34, 58, 34, 52, 52, 100, 57, 102, 102, 48, 54, 45, 102, 52, 51, 101, 45, 52, 50, 49, 54, 45, 57, 51, 52, 54, 45, 56, 48, 98, 57, 50, 49, 53, 52, 99, 101, 53, 98, 34, 44, 34, 99, 104, 97, 110, 103, 101, 115, 34, 58, 91, 93, 44, 34, 115, 116, 97, 116, 101, 34, 58, 34, 66, 79, 85, 71, 72, 84, 34, 44, 34, 117, 110, 99, 111, 109, 109, 105, 116, 116, 101, 100, 67, 104, 97, 110, 103, 101, 115, 34, 58, 91, 93, 125]] from topic [wordcount-lambda-example-shop-items-store-changelog]
Caused by: com.fasterxml.jackson.databind.JsonMappingException: Can not find a deserializer for non-concrete Collection type [collection type; class com.google.common.collect.ImmutableList, contains [simple type, class io.dddbyexamples.eventsource.domain.shopitem.events.DomainEvent]]
 at [Source: [B@3a5cf284; line: 1, column: 1]
	at com.fasterxml.jackson.databind.JsonMappingException.from(JsonMappingException.java:290)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCache2(DeserializerCache.java:269)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCacheValueDeserializer(DeserializerCache.java:244)
	at com.fasterxml.jackson.databind.deser.DeserializerCache.findValueDeserializer(DeserializerCache.java:142)
	at com.fasterxml.jackson.databind.DeserializationContext.findContextualValueDeserializer(DeserializationContext.java:444)
	at com.fasterxml.jackson.databind.deser.std.StdDeserializer.findDeserializer(StdDeserializer.java:948)
	at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.resolve(BeanDeserializerBase.java:446)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCache2(DeserializerCache.java:296)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCacheValueDeserializer(DeserializerCache.java:244)
	at com.fasterxml.jackson.databind.deser.DeserializerCache.findValueDeserializer(DeserializerCache.java:142)
	at com.fasterxml.jackson.databind.DeserializationContext.findRootValueDeserializer(DeserializationContext.java:477)
	at com.fasterxml.jackson.databind.ObjectReader._findRootDeserializer(ObjectReader.java:1816)
	at com.fasterxml.jackson.databind.ObjectReader._bindAndClose(ObjectReader.java:1573)
	at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1217)
	at org.springframework.kafka.support.serializer.JsonDeserializer.deserialize(JsonDeserializer.java:343)
	at org.apache.kafka.streams.state.StateSerdes.valueFrom(StateSerdes.java:159)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.putAndMaybeForward(CachingKeyValueStore.java:102)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.access$000(CachingKeyValueStore.java:38)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore$1.apply(CachingKeyValueStore.java:83)
	at org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:141)
	at org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:99)
	at org.apache.kafka.streams.state.internals.ThreadCache.flush(ThreadCache.java:124)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.flush(CachingKeyValueStore.java:123)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.close(CachingKeyValueStore.java:133)
	at org.apache.kafka.streams.state.internals.WrappedStateStore$AbstractStateStore.close(WrappedStateStore.java:90)
	at org.apache.kafka.streams.state.internals.MeteredKeyValueStore.close(MeteredKeyValueStore.java:122)
	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.close(ProcessorStateManager.java:247)
	at org.apache.kafka.streams.processor.internals.AbstractTask.closeStateManager(AbstractTask.java:251)
	at org.apache.kafka.streams.processor.internals.StreamTask.closeSuspended(StreamTask.java:648)
	at org.apache.kafka.streams.processor.internals.StreamTask.close(StreamTask.java:698)
	at org.apache.kafka.streams.processor.internals.AssignedTasks.close(AssignedTasks.java:397)
	at org.apache.kafka.streams.processor.internals.TaskManager.shutdown(TaskManager.java:260)
	at org.apache.kafka.streams.processor.internals.StreamThread.completeShutdown(StreamThread.java:1181)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:758)
Caused by: java.lang.IllegalArgumentException: Can not find a deserializer for non-concrete Collection type [collection type; class com.google.common.collect.ImmutableList, contains [simple type, class io.dddbyexamples.eventsource.domain.shopitem.events.DomainEvent]]
	at com.fasterxml.jackson.databind.deser.BasicDeserializerFactory.createCollectionDeserializer(BasicDeserializerFactory.java:1014)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createDeserializer2(DeserializerCache.java:394)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createDeserializer(DeserializerCache.java:352)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCache2(DeserializerCache.java:264)
	... 32 common frames omitted
2018-12-15 18:09:04,722 ERROR wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.AssignedStreamsTasks - stream-thread [wordcount-lambda-example-client-StreamThread-1] Failed while closing StreamTask 1_0 due to the following error:
org.apache.kafka.streams.errors.ProcessorStateException: task [1_0] Failed to close state store shop-items-store
	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.close(ProcessorStateManager.java:250)
	at org.apache.kafka.streams.processor.internals.AbstractTask.closeStateManager(AbstractTask.java:251)
	at org.apache.kafka.streams.processor.internals.StreamTask.closeSuspended(StreamTask.java:648)
	at org.apache.kafka.streams.processor.internals.StreamTask.close(StreamTask.java:698)
	at org.apache.kafka.streams.processor.internals.AssignedTasks.close(AssignedTasks.java:397)
	at org.apache.kafka.streams.processor.internals.TaskManager.shutdown(TaskManager.java:260)
	at org.apache.kafka.streams.processor.internals.StreamThread.completeShutdown(StreamThread.java:1181)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:758)
Caused by: org.apache.kafka.common.errors.SerializationException: Can't deserialize data [[123, 34, 117, 117, 105, 100, 34, 58, 34, 52, 52, 100, 57, 102, 102, 48, 54, 45, 102, 52, 51, 101, 45, 52, 50, 49, 54, 45, 57, 51, 52, 54, 45, 56, 48, 98, 57, 50, 49, 53, 52, 99, 101, 53, 98, 34, 44, 34, 99, 104, 97, 110, 103, 101, 115, 34, 58, 91, 93, 44, 34, 115, 116, 97, 116, 101, 34, 58, 34, 66, 79, 85, 71, 72, 84, 34, 44, 34, 117, 110, 99, 111, 109, 109, 105, 116, 116, 101, 100, 67, 104, 97, 110, 103, 101, 115, 34, 58, 91, 93, 125]] from topic [wordcount-lambda-example-shop-items-store-changelog]
Caused by: com.fasterxml.jackson.databind.JsonMappingException: Can not find a deserializer for non-concrete Collection type [collection type; class com.google.common.collect.ImmutableList, contains [simple type, class io.dddbyexamples.eventsource.domain.shopitem.events.DomainEvent]]
 at [Source: [B@3a5cf284; line: 1, column: 1]
	at com.fasterxml.jackson.databind.JsonMappingException.from(JsonMappingException.java:290)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCache2(DeserializerCache.java:269)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCacheValueDeserializer(DeserializerCache.java:244)
	at com.fasterxml.jackson.databind.deser.DeserializerCache.findValueDeserializer(DeserializerCache.java:142)
	at com.fasterxml.jackson.databind.DeserializationContext.findContextualValueDeserializer(DeserializationContext.java:444)
	at com.fasterxml.jackson.databind.deser.std.StdDeserializer.findDeserializer(StdDeserializer.java:948)
	at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.resolve(BeanDeserializerBase.java:446)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCache2(DeserializerCache.java:296)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCacheValueDeserializer(DeserializerCache.java:244)
	at com.fasterxml.jackson.databind.deser.DeserializerCache.findValueDeserializer(DeserializerCache.java:142)
	at com.fasterxml.jackson.databind.DeserializationContext.findRootValueDeserializer(DeserializationContext.java:477)
	at com.fasterxml.jackson.databind.ObjectReader._findRootDeserializer(ObjectReader.java:1816)
	at com.fasterxml.jackson.databind.ObjectReader._bindAndClose(ObjectReader.java:1573)
	at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1217)
	at org.springframework.kafka.support.serializer.JsonDeserializer.deserialize(JsonDeserializer.java:343)
	at org.apache.kafka.streams.state.StateSerdes.valueFrom(StateSerdes.java:159)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.putAndMaybeForward(CachingKeyValueStore.java:102)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.access$000(CachingKeyValueStore.java:38)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore$1.apply(CachingKeyValueStore.java:83)
	at org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:141)
	at org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:99)
	at org.apache.kafka.streams.state.internals.ThreadCache.flush(ThreadCache.java:124)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.flush(CachingKeyValueStore.java:123)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.close(CachingKeyValueStore.java:133)
	at org.apache.kafka.streams.state.internals.WrappedStateStore$AbstractStateStore.close(WrappedStateStore.java:90)
	at org.apache.kafka.streams.state.internals.MeteredKeyValueStore.close(MeteredKeyValueStore.java:122)
	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.close(ProcessorStateManager.java:247)
	at org.apache.kafka.streams.processor.internals.AbstractTask.closeStateManager(AbstractTask.java:251)
	at org.apache.kafka.streams.processor.internals.StreamTask.closeSuspended(StreamTask.java:648)
	at org.apache.kafka.streams.processor.internals.StreamTask.close(StreamTask.java:698)
	at org.apache.kafka.streams.processor.internals.AssignedTasks.close(AssignedTasks.java:397)
	at org.apache.kafka.streams.processor.internals.TaskManager.shutdown(TaskManager.java:260)
	at org.apache.kafka.streams.processor.internals.StreamThread.completeShutdown(StreamThread.java:1181)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:758)
Caused by: java.lang.IllegalArgumentException: Can not find a deserializer for non-concrete Collection type [collection type; class com.google.common.collect.ImmutableList, contains [simple type, class io.dddbyexamples.eventsource.domain.shopitem.events.DomainEvent]]
	at com.fasterxml.jackson.databind.deser.BasicDeserializerFactory.createCollectionDeserializer(BasicDeserializerFactory.java:1014)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createDeserializer2(DeserializerCache.java:394)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createDeserializer(DeserializerCache.java:352)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCache2(DeserializerCache.java:264)
	... 32 common frames omitted
2018-12-15 18:09:04,723 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:09:04,723 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=wordcount-lambda-example-client-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-12-15 18:09:04,731 ERROR wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Failed to close task manager due to the following error:
org.apache.kafka.streams.errors.ProcessorStateException: task [1_0] Failed to close state store shop-items-store
	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.close(ProcessorStateManager.java:250)
	at org.apache.kafka.streams.processor.internals.AbstractTask.closeStateManager(AbstractTask.java:251)
	at org.apache.kafka.streams.processor.internals.StreamTask.closeSuspended(StreamTask.java:648)
	at org.apache.kafka.streams.processor.internals.StreamTask.close(StreamTask.java:698)
	at org.apache.kafka.streams.processor.internals.AssignedTasks.close(AssignedTasks.java:397)
	at org.apache.kafka.streams.processor.internals.TaskManager.shutdown(TaskManager.java:260)
	at org.apache.kafka.streams.processor.internals.StreamThread.completeShutdown(StreamThread.java:1181)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:758)
Caused by: org.apache.kafka.common.errors.SerializationException: Can't deserialize data [[123, 34, 117, 117, 105, 100, 34, 58, 34, 52, 52, 100, 57, 102, 102, 48, 54, 45, 102, 52, 51, 101, 45, 52, 50, 49, 54, 45, 57, 51, 52, 54, 45, 56, 48, 98, 57, 50, 49, 53, 52, 99, 101, 53, 98, 34, 44, 34, 99, 104, 97, 110, 103, 101, 115, 34, 58, 91, 93, 44, 34, 115, 116, 97, 116, 101, 34, 58, 34, 66, 79, 85, 71, 72, 84, 34, 44, 34, 117, 110, 99, 111, 109, 109, 105, 116, 116, 101, 100, 67, 104, 97, 110, 103, 101, 115, 34, 58, 91, 93, 125]] from topic [wordcount-lambda-example-shop-items-store-changelog]
Caused by: com.fasterxml.jackson.databind.JsonMappingException: Can not find a deserializer for non-concrete Collection type [collection type; class com.google.common.collect.ImmutableList, contains [simple type, class io.dddbyexamples.eventsource.domain.shopitem.events.DomainEvent]]
 at [Source: [B@3a5cf284; line: 1, column: 1]
	at com.fasterxml.jackson.databind.JsonMappingException.from(JsonMappingException.java:290)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCache2(DeserializerCache.java:269)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCacheValueDeserializer(DeserializerCache.java:244)
	at com.fasterxml.jackson.databind.deser.DeserializerCache.findValueDeserializer(DeserializerCache.java:142)
	at com.fasterxml.jackson.databind.DeserializationContext.findContextualValueDeserializer(DeserializationContext.java:444)
	at com.fasterxml.jackson.databind.deser.std.StdDeserializer.findDeserializer(StdDeserializer.java:948)
	at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.resolve(BeanDeserializerBase.java:446)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCache2(DeserializerCache.java:296)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCacheValueDeserializer(DeserializerCache.java:244)
	at com.fasterxml.jackson.databind.deser.DeserializerCache.findValueDeserializer(DeserializerCache.java:142)
	at com.fasterxml.jackson.databind.DeserializationContext.findRootValueDeserializer(DeserializationContext.java:477)
	at com.fasterxml.jackson.databind.ObjectReader._findRootDeserializer(ObjectReader.java:1816)
	at com.fasterxml.jackson.databind.ObjectReader._bindAndClose(ObjectReader.java:1573)
	at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1217)
	at org.springframework.kafka.support.serializer.JsonDeserializer.deserialize(JsonDeserializer.java:343)
	at org.apache.kafka.streams.state.StateSerdes.valueFrom(StateSerdes.java:159)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.putAndMaybeForward(CachingKeyValueStore.java:102)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.access$000(CachingKeyValueStore.java:38)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore$1.apply(CachingKeyValueStore.java:83)
	at org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:141)
	at org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:99)
	at org.apache.kafka.streams.state.internals.ThreadCache.flush(ThreadCache.java:124)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.flush(CachingKeyValueStore.java:123)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.close(CachingKeyValueStore.java:133)
	at org.apache.kafka.streams.state.internals.WrappedStateStore$AbstractStateStore.close(WrappedStateStore.java:90)
	at org.apache.kafka.streams.state.internals.MeteredKeyValueStore.close(MeteredKeyValueStore.java:122)
	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.close(ProcessorStateManager.java:247)
	at org.apache.kafka.streams.processor.internals.AbstractTask.closeStateManager(AbstractTask.java:251)
	at org.apache.kafka.streams.processor.internals.StreamTask.closeSuspended(StreamTask.java:648)
	at org.apache.kafka.streams.processor.internals.StreamTask.close(StreamTask.java:698)
	at org.apache.kafka.streams.processor.internals.AssignedTasks.close(AssignedTasks.java:397)
	at org.apache.kafka.streams.processor.internals.TaskManager.shutdown(TaskManager.java:260)
	at org.apache.kafka.streams.processor.internals.StreamThread.completeShutdown(StreamThread.java:1181)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:758)
Caused by: java.lang.IllegalArgumentException: Can not find a deserializer for non-concrete Collection type [collection type; class com.google.common.collect.ImmutableList, contains [simple type, class io.dddbyexamples.eventsource.domain.shopitem.events.DomainEvent]]
	at com.fasterxml.jackson.databind.deser.BasicDeserializerFactory.createCollectionDeserializer(BasicDeserializerFactory.java:1014)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createDeserializer2(DeserializerCache.java:394)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createDeserializer(DeserializerCache.java:352)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCache2(DeserializerCache.java:264)
	... 32 common frames omitted
2018-12-15 18:09:04,734 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2018-12-15 18:09:04,734 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to ERROR
2018-12-15 18:09:04,734 WARN wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] All stream threads have died. The instance will be in error state and should be closed.
2018-12-15 18:09:04,734 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutdown complete
2018-12-15 18:09:04,955 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:09:00 CET 2018]; root of context hierarchy
2018-12-15 18:09:05,015 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-15 18:09:05,016 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-15 18:09:05,037 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:09:05,037 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:09:05,064 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:09:05,313 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.359 seconds (JVM running for 6.859)
2018-12-15 18:09:05,316 INFO pool-3-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-15T17:09:05.308Z
2018-12-15 18:09:05,363 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:09:17,575 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:09:00 CET 2018]; root of context hierarchy
2018-12-15 18:09:17,578 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from ERROR to PENDING_SHUTDOWN
2018-12-15 18:09:17,579 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Informed to shut down
2018-12-15 18:09:17,581 INFO kafka-streams-close-thread  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from PENDING_SHUTDOWN to NOT_RUNNING
2018-12-15 18:09:17,581 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Streams client stopped completely
2018-12-15 18:09:17,581 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-15 18:09:17,582 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:09:17,586 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:10:50,971 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 18:10:50,983 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 18:10:50,994 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ae42ce3, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4f5991f6, org.springframework.test.context.support.DirtiesContextTestExecutionListener@484094a5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@38234a38, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@63fbfaeb]
2018-12-15 18:10:51,622 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11183 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 18:10:51,622 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 18:10:51,681 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:10:51 CET 2018]; root of context hierarchy
2018-12-15 18:10:52,062 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 18:10:52,756 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$d0b6a69] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 18:10:54,088 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 18:10:54,097 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 18:10:54,149 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 18:10:54,150 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 18:10:54,151 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 18:10:54,293 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 18:10:54,341 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 18:10:54,461 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 18:10:54,682 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:10:54,692 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:10:55,239 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 18:10:55,266 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 18:10:55,314 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:10:55,314 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:10:55,321 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 18:10:55,324 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:10:55,359 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:10:55,359 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:10:55,361 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 18:10:55,363 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 18:10:55,383 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:10:55,383 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:10:55,390 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 18:10:55,392 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:10:55,400 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 18:10:55,400 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:10:55,400 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:10:55,405 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Starting
2018-12-15 18:10:55,405 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to RUNNING
2018-12-15 18:10:55,406 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 18:10:55,413 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:10:55,416 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:10:55,416 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:10:55,449 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-15 18:10:55,453 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:10:55,453 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:10:55,454 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:10:55,461 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 18:10:55,463 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:10:55,464 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:10:55,467 WARN main  org.apache.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=my-client-id
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:62)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:425)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:316)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.createProducer(CommandsProcessor.java:83)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>(CommandsProcessor.java:53)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 18:10:55,468 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-15 18:10:55,505 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:10:55,505 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:10:55,513 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Revoking previously assigned partitions []
2018-12-15 18:10:55,513 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-12-15 18:10:55,513 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to REBALANCING
2018-12-15 18:10:55,513 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:10:55,513 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition revocation took 0 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-12-15 18:10:55,513 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] (Re-)joining group
2018-12-15 18:10:55,534 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wordcount-lambda-example-client-StreamThread-1-consumer] Assigned tasks to clients as {d16318b6-e913-4edc-91eb-f43ac4a297ee=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) assignedTasks: ([0_0, 1_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2018-12-15 18:10:55,539 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Successfully joined group with generation 7
2018-12-15 18:10:55,542 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Setting newly assigned partitions [wordcount-lambda-example-shop-items-store-repartition-0, shop-items-0]
2018-12-15 18:10:55,542 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2018-12-15 18:10:55,568 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition assignment took 26 ms.
	current active tasks: [0_0, 1_0]
	current standby tasks: []
	previous active tasks: []

2018-12-15 18:10:55,575 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Resetting offset for partition wordcount-lambda-example-shop-items-store-repartition-0 to offset 0.
2018-12-15 18:10:55,576 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Resetting offset for partition shop-items-0 to offset 0.
2018-12-15 18:10:55,632 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:10:55,638 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StoreChangelogReader - stream-thread [wordcount-lambda-example-client-StreamThread-1] Restoring task 1_0's state store shop-items-store from beginning of the changelog wordcount-lambda-example-shop-items-store-changelog-0 
2018-12-15 18:10:55,639 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Resetting offset for partition wordcount-lambda-example-shop-items-store-changelog-0 to offset 0.
2018-12-15 18:10:55,663 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:10:55,666 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:10:55,666 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2018-12-15 18:10:55,666 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from REBALANCING to RUNNING
2018-12-15 18:10:55,698 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 52
2018-12-15 18:10:55,704 INFO pool-2-thread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:10:55,705 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:10:55,705 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Revoking previously assigned partitions []
2018-12-15 18:10:55,706 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] (Re-)joining group
2018-12-15 18:10:55,712 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Successfully joined group with generation 33
2018-12-15 18:10:55,714 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Setting newly assigned partitions [shop-items-commands-0]
2018-12-15 18:10:55,715 INFO kafka-producer-network-thread | wordcount-lambda-example-client-StreamThread-1-producer  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:10:55,718 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Resetting offset for partition shop-items-commands-0 to offset 0.
2018-12-15 18:10:56,042 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:10:51 CET 2018]; root of context hierarchy
2018-12-15 18:10:56,099 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-15 18:10:56,100 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-15 18:10:56,120 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:10:56,120 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:10:56,148 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:10:56,396 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.312 seconds (JVM running for 6.711)
2018-12-15 18:10:56,398 INFO pool-3-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-15T17:10:56.391Z
2018-12-15 18:10:56,440 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:11:10,269 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:10:51 CET 2018]; root of context hierarchy
2018-12-15 18:11:10,272 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:11:10,273 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Informed to shut down
2018-12-15 18:11:10,273 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:11:10,339 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutting down
2018-12-15 18:11:10,362 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:11:10,362 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=wordcount-lambda-example-client-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-12-15 18:11:10,368 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2018-12-15 18:11:10,369 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutdown complete
2018-12-15 18:11:10,370 INFO kafka-streams-close-thread  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from PENDING_SHUTDOWN to NOT_RUNNING
2018-12-15 18:11:10,370 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Streams client stopped completely
2018-12-15 18:11:10,370 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-15 18:11:10,371 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:11:10,374 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:11:33,229 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 18:11:33,241 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 18:11:33,253 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ae42ce3, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4f5991f6, org.springframework.test.context.support.DirtiesContextTestExecutionListener@484094a5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@38234a38, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@63fbfaeb]
2018-12-15 18:11:33,918 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11453 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 18:11:33,918 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 18:11:33,975 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:11:33 CET 2018]; root of context hierarchy
2018-12-15 18:11:34,314 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 18:11:34,961 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$d0b6a69] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 18:11:36,145 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 18:11:36,152 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 18:11:36,208 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 18:11:36,209 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 18:11:36,210 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 18:11:36,344 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 18:11:36,393 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 18:11:36,523 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 18:11:36,722 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:11:36,730 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:11:37,258 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 18:11:37,288 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 18:11:37,337 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:11:37,337 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:11:37,343 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 18:11:37,347 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:11:37,383 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:11:37,383 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:11:37,384 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 18:11:37,386 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 18:11:37,406 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:11:37,406 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:11:37,413 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 18:11:37,415 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:11:37,423 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 18:11:37,423 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:11:37,423 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:11:37,428 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Starting
2018-12-15 18:11:37,429 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to RUNNING
2018-12-15 18:11:37,429 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 18:11:37,436 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:11:37,439 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:11:37,439 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:11:37,472 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-15 18:11:37,476 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:11:37,476 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:11:37,476 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:11:37,482 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 18:11:37,485 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:11:37,485 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:11:37,487 WARN main  org.apache.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=my-client-id
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:62)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:425)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:316)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.createProducer(CommandsProcessor.java:83)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>(CommandsProcessor.java:53)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 18:11:37,489 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-15 18:11:37,523 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:11:37,524 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:11:37,530 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Revoking previously assigned partitions []
2018-12-15 18:11:37,531 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-12-15 18:11:37,531 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to REBALANCING
2018-12-15 18:11:37,531 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:11:37,532 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition revocation took 1 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-12-15 18:11:37,532 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] (Re-)joining group
2018-12-15 18:11:37,556 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wordcount-lambda-example-client-StreamThread-1-consumer] Assigned tasks to clients as {1a037afc-db01-44d4-9826-8f25a96ad6ec=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) assignedTasks: ([0_0, 1_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2018-12-15 18:11:37,563 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Successfully joined group with generation 9
2018-12-15 18:11:37,565 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Setting newly assigned partitions [wordcount-lambda-example-shop-items-store-repartition-0, shop-items-0]
2018-12-15 18:11:37,566 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2018-12-15 18:11:37,589 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition assignment took 23 ms.
	current active tasks: [0_0, 1_0]
	current standby tasks: []
	previous active tasks: []

2018-12-15 18:11:37,663 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:11:37,670 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StoreChangelogReader - stream-thread [wordcount-lambda-example-client-StreamThread-1] Restoring task 1_0's state store shop-items-store from beginning of the changelog wordcount-lambda-example-shop-items-store-changelog-0 
2018-12-15 18:11:37,672 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Resetting offset for partition wordcount-lambda-example-shop-items-store-changelog-0 to offset 0.
2018-12-15 18:11:37,697 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:11:37,699 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:11:37,700 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2018-12-15 18:11:37,700 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from REBALANCING to RUNNING
2018-12-15 18:11:37,717 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 53
2018-12-15 18:11:37,722 INFO pool-2-thread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:11:37,722 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:11:37,723 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Revoking previously assigned partitions []
2018-12-15 18:11:37,723 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] (Re-)joining group
2018-12-15 18:11:37,728 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Successfully joined group with generation 35
2018-12-15 18:11:37,729 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Setting newly assigned partitions [shop-items-commands-0]
2018-12-15 18:11:37,732 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Resetting offset for partition shop-items-commands-0 to offset 0.
2018-12-15 18:11:38,009 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:11:33 CET 2018]; root of context hierarchy
2018-12-15 18:11:38,067 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-15 18:11:38,068 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-15 18:11:38,089 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:11:38,089 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:11:38,115 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:11:38,348 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.002 seconds (JVM running for 6.487)
2018-12-15 18:11:38,351 INFO pool-3-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-15T17:11:38.343Z
2018-12-15 18:11:38,397 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:11:53,601 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:11:33 CET 2018]; root of context hierarchy
2018-12-15 18:11:53,604 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:11:53,605 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Informed to shut down
2018-12-15 18:11:53,605 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:11:53,684 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutting down
2018-12-15 18:11:53,693 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:11:53,693 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=wordcount-lambda-example-client-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-12-15 18:11:53,699 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2018-12-15 18:11:53,700 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutdown complete
2018-12-15 18:11:53,701 INFO kafka-streams-close-thread  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from PENDING_SHUTDOWN to NOT_RUNNING
2018-12-15 18:11:53,701 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Streams client stopped completely
2018-12-15 18:11:53,702 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-15 18:11:53,702 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:11:53,706 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:12:09,093 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 18:12:09,108 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 18:12:09,126 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@47a64f7d, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@33d05366, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@27a0a5a2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@7692cd34, org.springframework.test.context.transaction.TransactionalTestExecutionListener@33aa93c, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@32c0915e]
2018-12-15 18:12:09,991 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11459 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 18:12:09,991 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 18:12:10,073 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@279dd959: startup date [Sat Dec 15 18:12:10 CET 2018]; root of context hierarchy
2018-12-15 18:12:10,508 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 18:12:11,349 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$ce72982] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 18:12:13,177 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 18:12:13,190 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 18:12:13,301 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 18:12:13,304 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 18:12:13,306 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 18:12:13,535 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 18:12:13,589 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 18:12:13,738 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 18:12:14,038 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:12:14,048 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:12:14,734 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 18:12:14,772 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 18:12:14,820 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:12:14,820 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:12:14,826 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 18:12:14,829 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:12:14,865 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:12:14,865 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:12:14,867 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 18:12:14,869 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 18:12:14,891 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:12:14,891 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:12:14,899 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 18:12:14,900 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:12:14,909 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 18:12:14,909 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:12:14,909 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:12:14,914 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Starting
2018-12-15 18:12:14,915 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to RUNNING
2018-12-15 18:12:14,915 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 18:12:14,925 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:12:14,928 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:12:14,928 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:12:14,974 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-15 18:12:14,978 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:12:14,978 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:12:14,979 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:12:14,987 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 18:12:14,991 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:12:14,991 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:12:14,994 WARN main  org.apache.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=my-client-id
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:62)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:425)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:316)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.createProducer(CommandsProcessor.java:83)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>(CommandsProcessor.java:53)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 18:12:14,996 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-15 18:12:15,045 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:12:15,046 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:12:15,053 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Revoking previously assigned partitions []
2018-12-15 18:12:15,053 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-12-15 18:12:15,053 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to REBALANCING
2018-12-15 18:12:15,054 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:12:15,054 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition revocation took 1 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-12-15 18:12:15,054 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] (Re-)joining group
2018-12-15 18:12:15,077 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wordcount-lambda-example-client-StreamThread-1-consumer] Assigned tasks to clients as {ab99e8f9-1882-41a5-84b8-1eb70c95ff0e=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) assignedTasks: ([0_0, 1_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2018-12-15 18:12:15,083 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Successfully joined group with generation 11
2018-12-15 18:12:15,085 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Setting newly assigned partitions [wordcount-lambda-example-shop-items-store-repartition-0, shop-items-0]
2018-12-15 18:12:15,086 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2018-12-15 18:12:15,111 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition assignment took 25 ms.
	current active tasks: [0_0, 1_0]
	current standby tasks: []
	previous active tasks: []

2018-12-15 18:12:15,145 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:12:15,153 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StoreChangelogReader - stream-thread [wordcount-lambda-example-client-StreamThread-1] Restoring task 1_0's state store shop-items-store from beginning of the changelog wordcount-lambda-example-shop-items-store-changelog-0 
2018-12-15 18:12:15,155 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Resetting offset for partition wordcount-lambda-example-shop-items-store-changelog-0 to offset 0.
2018-12-15 18:12:15,182 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:12:15,185 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:12:15,185 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2018-12-15 18:12:15,186 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from REBALANCING to RUNNING
2018-12-15 18:12:15,228 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 54
2018-12-15 18:12:15,236 INFO pool-2-thread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:12:15,236 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:12:15,237 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Revoking previously assigned partitions []
2018-12-15 18:12:15,237 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] (Re-)joining group
2018-12-15 18:12:15,244 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Successfully joined group with generation 37
2018-12-15 18:12:15,245 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Setting newly assigned partitions [shop-items-commands-0]
2018-12-15 18:12:15,249 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Resetting offset for partition shop-items-commands-0 to offset 0.
2018-12-15 18:12:30,230 INFO kafka-coordinator-heartbeat-thread | some-group-id-3  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Attempt to heartbeat failed for since member id order-details-service-consumer-32168240-aa60-40a0-810c-a9156dcdab3f is not valid.
2018-12-15 18:12:35,940 INFO kafka-coordinator-heartbeat-thread | some-group-id-3  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2018-12-15 18:12:37,212 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@279dd959: startup date [Sat Dec 15 18:12:10 CET 2018]; root of context hierarchy
2018-12-15 18:12:37,280 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-15 18:12:37,280 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-15 18:12:37,308 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:12:37,308 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:12:37,343 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:12:37,719 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 28.44 seconds (JVM running for 30.297)
2018-12-15 18:12:37,722 INFO pool-3-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-15T17:12:37.713Z
2018-12-15 18:12:37,776 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:12:47,120 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@279dd959: startup date [Sat Dec 15 18:12:10 CET 2018]; root of context hierarchy
2018-12-15 18:12:47,124 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:12:47,125 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Informed to shut down
2018-12-15 18:12:47,125 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:12:47,188 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutting down
2018-12-15 18:12:47,197 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:12:47,197 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=wordcount-lambda-example-client-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-12-15 18:12:47,204 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2018-12-15 18:12:47,204 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutdown complete
2018-12-15 18:12:47,205 INFO kafka-streams-close-thread  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from PENDING_SHUTDOWN to NOT_RUNNING
2018-12-15 18:12:47,206 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Streams client stopped completely
2018-12-15 18:12:47,206 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-15 18:12:47,206 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:12:47,211 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:12:50,983 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 18:12:51,000 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 18:12:51,017 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@47a64f7d, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@33d05366, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@27a0a5a2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@7692cd34, org.springframework.test.context.transaction.TransactionalTestExecutionListener@33aa93c, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@32c0915e]
2018-12-15 18:12:51,817 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11465 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 18:12:51,817 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 18:12:51,888 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@279dd959: startup date [Sat Dec 15 18:12:51 CET 2018]; root of context hierarchy
2018-12-15 18:12:52,341 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 18:12:53,179 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$ce72982] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 18:12:54,819 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 18:12:54,832 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 18:12:54,944 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 18:12:54,946 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 18:12:54,948 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 18:12:55,186 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 18:12:55,242 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 18:12:55,360 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 18:12:55,618 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:12:55,627 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:12:56,294 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 18:12:56,333 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 18:12:56,391 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:12:56,392 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:12:56,399 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 18:12:56,403 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:12:56,448 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:12:56,449 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:12:56,450 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 18:12:56,452 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 18:12:56,475 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:12:56,475 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:12:56,484 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 18:12:56,486 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:12:56,496 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 18:12:56,497 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:12:56,497 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:12:56,504 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Starting
2018-12-15 18:12:56,504 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to RUNNING
2018-12-15 18:12:56,506 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 18:12:56,517 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:12:56,520 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:12:56,520 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:12:56,576 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-15 18:12:56,581 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:12:56,581 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:12:56,582 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:12:56,591 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 18:12:56,595 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:12:56,596 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:12:56,599 WARN main  org.apache.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=my-client-id
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:62)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:425)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:316)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.createProducer(CommandsProcessor.java:83)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>(CommandsProcessor.java:53)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 18:12:56,602 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-15 18:12:56,626 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:12:56,627 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:12:56,634 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Revoking previously assigned partitions []
2018-12-15 18:12:56,634 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-12-15 18:12:56,634 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to REBALANCING
2018-12-15 18:12:56,634 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:12:56,635 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition revocation took 1 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-12-15 18:12:56,635 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] (Re-)joining group
2018-12-15 18:12:56,659 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wordcount-lambda-example-client-StreamThread-1-consumer] Assigned tasks to clients as {56af64d0-e152-4eb1-8a9f-a4d269668a94=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) assignedTasks: ([0_0, 1_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2018-12-15 18:12:56,665 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Successfully joined group with generation 13
2018-12-15 18:12:56,667 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Setting newly assigned partitions [wordcount-lambda-example-shop-items-store-repartition-0, shop-items-0]
2018-12-15 18:12:56,668 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2018-12-15 18:12:56,694 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition assignment took 26 ms.
	current active tasks: [0_0, 1_0]
	current standby tasks: []
	previous active tasks: []

2018-12-15 18:12:56,735 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:12:56,744 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StoreChangelogReader - stream-thread [wordcount-lambda-example-client-StreamThread-1] Restoring task 1_0's state store shop-items-store from beginning of the changelog wordcount-lambda-example-shop-items-store-changelog-0 
2018-12-15 18:12:56,746 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Resetting offset for partition wordcount-lambda-example-shop-items-store-changelog-0 to offset 0.
2018-12-15 18:12:56,778 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:12:56,781 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:12:56,781 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2018-12-15 18:12:56,782 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from REBALANCING to RUNNING
2018-12-15 18:12:56,822 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 55
2018-12-15 18:12:56,828 INFO pool-2-thread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:12:56,829 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:12:56,829 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Revoking previously assigned partitions []
2018-12-15 18:12:56,830 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] (Re-)joining group
2018-12-15 18:12:56,835 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Successfully joined group with generation 39
2018-12-15 18:12:56,837 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Setting newly assigned partitions [shop-items-commands-0]
2018-12-15 18:12:56,841 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Resetting offset for partition shop-items-commands-0 to offset 0.
2018-12-15 18:13:03,421 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@279dd959: startup date [Sat Dec 15 18:12:51 CET 2018]; root of context hierarchy
2018-12-15 18:13:03,493 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-15 18:13:03,494 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-15 18:13:03,519 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:13:03,519 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:13:03,554 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:13:03,912 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 12.764 seconds (JVM running for 14.519)
2018-12-15 18:13:03,915 INFO pool-3-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-15T17:13:03.905Z
2018-12-15 18:13:03,970 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:13:24,006 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@279dd959: startup date [Sat Dec 15 18:12:51 CET 2018]; root of context hierarchy
2018-12-15 18:13:24,008 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:13:24,010 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Informed to shut down
2018-12-15 18:13:24,010 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:13:24,056 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutting down
2018-12-15 18:13:24,065 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:13:24,066 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=wordcount-lambda-example-client-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-12-15 18:13:24,072 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2018-12-15 18:13:24,072 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutdown complete
2018-12-15 18:13:24,074 INFO kafka-streams-close-thread  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from PENDING_SHUTDOWN to NOT_RUNNING
2018-12-15 18:13:24,074 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Streams client stopped completely
2018-12-15 18:13:24,075 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-15 18:13:24,075 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:13:24,080 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:13:30,145 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 18:13:30,159 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 18:13:30,175 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@47a64f7d, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@33d05366, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@27a0a5a2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@7692cd34, org.springframework.test.context.transaction.TransactionalTestExecutionListener@33aa93c, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@32c0915e]
2018-12-15 18:13:30,979 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11468 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 18:13:30,979 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 18:13:31,049 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@279dd959: startup date [Sat Dec 15 18:13:31 CET 2018]; root of context hierarchy
2018-12-15 18:13:31,493 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 18:13:32,312 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$88f3d604] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 18:13:33,884 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 18:13:33,897 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 18:13:33,993 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 18:13:33,996 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 18:13:33,998 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 18:13:34,225 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 18:13:34,280 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 18:13:34,413 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 18:13:34,687 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:13:34,697 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:13:35,345 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 18:13:35,381 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 18:13:35,431 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:13:35,431 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:13:35,437 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 18:13:35,440 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:13:35,474 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:13:35,474 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:13:35,475 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 18:13:35,477 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 18:13:35,496 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:13:35,496 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:13:35,503 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 18:13:35,505 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:13:35,517 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 18:13:35,517 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:13:35,517 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:13:35,524 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Starting
2018-12-15 18:13:35,524 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to RUNNING
2018-12-15 18:13:35,526 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 18:13:35,536 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:13:35,539 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:13:35,540 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:13:35,587 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-15 18:13:35,590 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:13:35,590 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:13:35,591 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:13:35,599 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 18:13:35,602 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:13:35,602 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:13:35,605 WARN main  org.apache.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=my-client-id
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:62)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:425)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:316)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.createProducer(CommandsProcessor.java:83)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>(CommandsProcessor.java:53)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 18:13:35,607 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-15 18:13:35,655 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:13:35,656 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:13:35,662 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Revoking previously assigned partitions []
2018-12-15 18:13:35,663 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-12-15 18:13:35,663 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to REBALANCING
2018-12-15 18:13:35,663 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:13:35,663 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition revocation took 0 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-12-15 18:13:35,663 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] (Re-)joining group
2018-12-15 18:13:35,687 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wordcount-lambda-example-client-StreamThread-1-consumer] Assigned tasks to clients as {2443b9a2-e9b5-4030-b150-01a057850dd9=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) assignedTasks: ([0_0, 1_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2018-12-15 18:13:35,693 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Successfully joined group with generation 15
2018-12-15 18:13:35,695 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Setting newly assigned partitions [wordcount-lambda-example-shop-items-store-repartition-0, shop-items-0]
2018-12-15 18:13:35,696 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2018-12-15 18:13:35,722 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition assignment took 26 ms.
	current active tasks: [0_0, 1_0]
	current standby tasks: []
	previous active tasks: []

2018-12-15 18:13:35,757 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:13:35,765 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StoreChangelogReader - stream-thread [wordcount-lambda-example-client-StreamThread-1] Restoring task 1_0's state store shop-items-store from beginning of the changelog wordcount-lambda-example-shop-items-store-changelog-0 
2018-12-15 18:13:35,767 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Resetting offset for partition wordcount-lambda-example-shop-items-store-changelog-0 to offset 0.
2018-12-15 18:13:35,795 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:13:35,797 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:13:35,797 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2018-12-15 18:13:35,798 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from REBALANCING to RUNNING
2018-12-15 18:13:35,843 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 56
2018-12-15 18:13:35,849 INFO pool-2-thread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:13:35,849 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:13:35,850 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Revoking previously assigned partitions []
2018-12-15 18:13:35,850 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] (Re-)joining group
2018-12-15 18:13:35,856 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Successfully joined group with generation 41
2018-12-15 18:13:35,857 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Setting newly assigned partitions [shop-items-commands-0]
2018-12-15 18:13:35,861 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Resetting offset for partition shop-items-commands-0 to offset 0.
2018-12-15 18:13:47,656 INFO kafka-coordinator-heartbeat-thread | some-group-id-3  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2018-12-15 18:13:55,393 INFO kafka-coordinator-heartbeat-thread | wordcount-lambda-example  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2018-12-15 18:14:36,304 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:14:36,386 INFO kafka-coordinator-heartbeat-thread | some-group-id-3  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:14:39,859 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Attempt to heartbeat failed for since member id wordcount-lambda-example-client-StreamThread-1-consumer-86786758-74ef-40b4-91ab-68ce58f22ead is not valid.
2018-12-15 18:14:40,162 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@279dd959: startup date [Sat Dec 15 18:13:31 CET 2018]; root of context hierarchy
2018-12-15 18:14:40,168 INFO kafka-coordinator-heartbeat-thread | some-group-id-3  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Attempt to heartbeat failed for since member id order-details-service-consumer-2387b183-a6b3-42df-a765-7e08e15fdcdf is not valid.
2018-12-15 18:14:40,230 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-15 18:14:40,231 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-15 18:14:40,256 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:14:40,257 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:14:40,289 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:14:40,361 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Revoking previously assigned partitions [wordcount-lambda-example-shop-items-store-repartition-0, shop-items-0]
2018-12-15 18:14:40,362 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-12-15 18:14:40,362 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to REBALANCING
2018-12-15 18:14:40,364 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:14:40,364 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition revocation took 2 ms.
	suspended active tasks: [0_0, 1_0]
	suspended standby tasks: []
2018-12-15 18:14:40,364 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] (Re-)joining group
2018-12-15 18:14:40,369 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wordcount-lambda-example-client-StreamThread-1-consumer] Assigned tasks to clients as {2443b9a2-e9b5-4030-b150-01a057850dd9=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) assignedTasks: ([0_0, 1_0]) prevActiveTasks: ([0_0, 1_0]) prevStandbyTasks: ([]) prevAssignedTasks: ([0_0, 1_0]) capacity: 1]}.
2018-12-15 18:14:40,371 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Successfully joined group with generation 17
2018-12-15 18:14:40,371 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Setting newly assigned partitions [wordcount-lambda-example-shop-items-store-repartition-0, shop-items-0]
2018-12-15 18:14:40,371 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2018-12-15 18:14:40,375 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition assignment took 4 ms.
	current active tasks: [0_0, 1_0]
	current standby tasks: []
	previous active tasks: [0_0, 1_0]

2018-12-15 18:14:40,471 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:14:40,471 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:14:40,471 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2018-12-15 18:14:40,471 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from REBALANCING to RUNNING
2018-12-15 18:14:40,670 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 70.373 seconds (JVM running for 72.091)
2018-12-15 18:14:40,672 INFO pool-3-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-15T17:14:40.664Z
2018-12-15 18:14:40,721 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:15:00,765 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@279dd959: startup date [Sat Dec 15 18:13:31 CET 2018]; root of context hierarchy
2018-12-15 18:15:00,771 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:15:00,773 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Informed to shut down
2018-12-15 18:15:00,773 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:15:00,793 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutting down
2018-12-15 18:15:00,800 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:15:00,801 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=wordcount-lambda-example-client-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-12-15 18:15:00,807 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2018-12-15 18:15:00,807 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutdown complete
2018-12-15 18:15:00,808 INFO kafka-streams-close-thread  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from PENDING_SHUTDOWN to NOT_RUNNING
2018-12-15 18:15:00,809 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Streams client stopped completely
2018-12-15 18:15:00,809 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-15 18:15:00,809 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:15:00,814 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:15:27,542 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 18:15:27,556 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 18:15:27,574 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@47a64f7d, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@33d05366, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@27a0a5a2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@7692cd34, org.springframework.test.context.transaction.TransactionalTestExecutionListener@33aa93c, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@32c0915e]
2018-12-15 18:15:28,418 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11473 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 18:15:28,418 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 18:15:28,488 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@279dd959: startup date [Sat Dec 15 18:15:28 CET 2018]; root of context hierarchy
2018-12-15 18:15:28,940 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 18:15:29,765 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$862fa04a] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 18:15:31,470 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 18:15:31,482 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 18:15:31,616 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 18:15:31,618 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 18:15:31,620 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 18:15:31,798 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 18:15:31,855 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 18:15:31,994 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 18:15:32,275 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:15:32,286 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:15:32,983 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 18:15:33,023 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 18:15:33,082 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:15:33,082 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:15:33,089 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 18:15:33,093 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:15:33,140 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:15:33,140 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:15:33,142 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 18:15:33,144 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 18:15:33,168 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:15:33,168 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:15:33,178 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 18:15:33,180 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:15:33,189 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 18:15:33,190 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:15:33,190 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:15:33,197 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Starting
2018-12-15 18:15:33,197 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to RUNNING
2018-12-15 18:15:33,199 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 18:15:33,212 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:15:33,216 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:15:33,217 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:15:33,272 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-15 18:15:33,276 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:15:33,276 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:15:33,277 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:15:33,286 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 18:15:33,291 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:15:33,291 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:15:33,295 WARN main  org.apache.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=my-client-id
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:62)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:425)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:316)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.createProducer(CommandsProcessor.java:83)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>(CommandsProcessor.java:53)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 18:15:33,296 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-15 18:15:33,335 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:15:33,336 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:15:33,343 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Revoking previously assigned partitions []
2018-12-15 18:15:33,343 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-12-15 18:15:33,344 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to REBALANCING
2018-12-15 18:15:33,344 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:15:33,344 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition revocation took 0 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-12-15 18:15:33,344 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] (Re-)joining group
2018-12-15 18:15:33,369 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wordcount-lambda-example-client-StreamThread-1-consumer] Assigned tasks to clients as {ee0ffb8f-d4aa-455c-ad99-159bdaa4dda3=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) assignedTasks: ([0_0, 1_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2018-12-15 18:15:33,375 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Successfully joined group with generation 19
2018-12-15 18:15:33,378 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Setting newly assigned partitions [wordcount-lambda-example-shop-items-store-repartition-0, shop-items-0]
2018-12-15 18:15:33,378 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2018-12-15 18:15:33,408 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition assignment took 30 ms.
	current active tasks: [0_0, 1_0]
	current standby tasks: []
	previous active tasks: []

2018-12-15 18:15:33,440 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:15:33,451 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StoreChangelogReader - stream-thread [wordcount-lambda-example-client-StreamThread-1] Restoring task 1_0's state store shop-items-store from beginning of the changelog wordcount-lambda-example-shop-items-store-changelog-0 
2018-12-15 18:15:33,453 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Resetting offset for partition wordcount-lambda-example-shop-items-store-changelog-0 to offset 0.
2018-12-15 18:15:33,487 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:15:33,490 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:15:33,490 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2018-12-15 18:15:33,491 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from REBALANCING to RUNNING
2018-12-15 18:15:33,526 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 57
2018-12-15 18:15:33,533 INFO pool-2-thread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:15:33,534 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:15:33,535 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Revoking previously assigned partitions []
2018-12-15 18:15:33,535 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] (Re-)joining group
2018-12-15 18:15:33,540 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Successfully joined group with generation 43
2018-12-15 18:15:33,541 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Setting newly assigned partitions [shop-items-commands-0]
2018-12-15 18:15:33,544 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Resetting offset for partition shop-items-commands-0 to offset 0.
2018-12-15 18:15:44,989 INFO kafka-coordinator-heartbeat-thread | wordcount-lambda-example  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2018-12-15 18:15:44,989 INFO kafka-coordinator-heartbeat-thread | some-group-id-3  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2018-12-15 18:15:44,999 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:15:44,999 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2018-12-15 18:16:12,174 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 18:16:12,189 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 18:16:12,206 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@47a64f7d, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@33d05366, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@27a0a5a2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@7692cd34, org.springframework.test.context.transaction.TransactionalTestExecutionListener@33aa93c, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@32c0915e]
2018-12-15 18:16:13,057 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11478 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 18:16:13,058 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 18:16:13,128 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@279dd959: startup date [Sat Dec 15 18:16:13 CET 2018]; root of context hierarchy
2018-12-15 18:16:13,587 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 18:16:14,386 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$7dac8ccb] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 18:16:15,990 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 18:16:16,002 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 18:16:16,096 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 18:16:16,098 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 18:16:16,099 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 18:16:16,324 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 18:16:16,381 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 18:16:16,498 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 18:16:16,733 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:16:16,742 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:16:17,365 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 18:16:17,395 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 18:16:17,439 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:16:17,439 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:16:17,444 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 18:16:17,448 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:16:17,482 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:16:17,483 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:16:17,484 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 18:16:17,485 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 18:16:17,504 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:16:17,504 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:16:17,511 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 18:16:17,512 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:16:17,522 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 18:16:17,522 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:16:17,522 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:16:17,528 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Starting
2018-12-15 18:16:17,528 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to RUNNING
2018-12-15 18:16:17,529 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 18:16:17,538 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:16:17,541 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:16:17,541 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:16:17,585 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-15 18:16:17,588 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:16:17,588 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:16:17,589 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:16:17,596 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 18:16:17,599 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:16:17,599 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:16:17,603 WARN main  org.apache.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=my-client-id
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:62)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:425)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:316)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.createProducer(CommandsProcessor.java:83)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>(CommandsProcessor.java:53)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 18:16:17,604 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-15 18:16:17,652 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:16:17,653 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:16:17,661 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Revoking previously assigned partitions []
2018-12-15 18:16:17,661 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-12-15 18:16:17,661 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to REBALANCING
2018-12-15 18:16:17,662 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:16:17,662 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition revocation took 1 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-12-15 18:16:17,662 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] (Re-)joining group
2018-12-15 18:16:17,687 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wordcount-lambda-example-client-StreamThread-1-consumer] Assigned tasks to clients as {2ccd6f00-32f4-4422-b0aa-e4c04164e08a=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) assignedTasks: ([0_0, 1_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2018-12-15 18:16:17,693 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Successfully joined group with generation 21
2018-12-15 18:16:17,696 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Setting newly assigned partitions [wordcount-lambda-example-shop-items-store-repartition-0, shop-items-0]
2018-12-15 18:16:17,696 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2018-12-15 18:16:17,725 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition assignment took 28 ms.
	current active tasks: [0_0, 1_0]
	current standby tasks: []
	previous active tasks: []

2018-12-15 18:16:17,758 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:16:17,766 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StoreChangelogReader - stream-thread [wordcount-lambda-example-client-StreamThread-1] Restoring task 1_0's state store shop-items-store from beginning of the changelog wordcount-lambda-example-shop-items-store-changelog-0 
2018-12-15 18:16:17,768 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Resetting offset for partition wordcount-lambda-example-shop-items-store-changelog-0 to offset 0.
2018-12-15 18:16:17,798 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:16:17,801 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:16:17,801 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2018-12-15 18:16:17,802 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from REBALANCING to RUNNING
2018-12-15 18:16:17,838 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 58
2018-12-15 18:16:17,848 INFO pool-2-thread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:16:17,848 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:16:17,849 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Revoking previously assigned partitions []
2018-12-15 18:16:17,849 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] (Re-)joining group
2018-12-15 18:16:17,855 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Successfully joined group with generation 45
2018-12-15 18:16:17,856 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Setting newly assigned partitions [shop-items-commands-0]
2018-12-15 18:16:17,862 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Resetting offset for partition shop-items-commands-0 to offset 0.
2018-12-15 18:16:51,240 INFO kafka-coordinator-heartbeat-thread | wordcount-lambda-example  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2018-12-15 18:16:51,240 INFO kafka-coordinator-heartbeat-thread | some-group-id-3  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-3] Group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2018-12-15 18:16:51,250 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:16:51,250 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example] Group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2018-12-15 18:17:10,486 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 18:17:10,504 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 18:17:10,519 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@47a64f7d, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@33d05366, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@27a0a5a2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@7692cd34, org.springframework.test.context.transaction.TransactionalTestExecutionListener@33aa93c, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@32c0915e]
2018-12-15 18:17:11,346 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11484 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 18:17:11,346 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 18:17:11,418 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@46383a78: startup date [Sat Dec 15 18:17:11 CET 2018]; root of context hierarchy
2018-12-15 18:17:11,868 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 18:17:12,678 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$cfa59e7d] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 18:17:14,330 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 18:17:14,342 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 18:17:14,433 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 18:17:14,436 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 18:17:14,438 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 18:17:14,654 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 18:17:14,702 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 18:17:14,824 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 18:17:15,075 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:17:15,083 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:17:15,733 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example-3
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 18:17:15,775 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 18:17:15,833 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:17:15,833 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:17:15,840 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 18:17:15,844 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:17:15,886 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:17:15,887 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:17:15,888 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 18:17:15,890 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 18:17:15,913 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:17:15,913 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:17:15,921 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 18:17:15,923 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example-3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:17:15,931 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 18:17:15,931 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:17:15,931 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:17:15,938 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Starting
2018-12-15 18:17:15,938 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to RUNNING
2018-12-15 18:17:15,940 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 18:17:15,951 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:17:15,954 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:17:15,955 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:17:16,008 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-15 18:17:16,011 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:17:16,012 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:17:16,013 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:17:16,024 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 18:17:16,027 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:17:16,028 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:17:16,031 WARN main  org.apache.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=my-client-id
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:62)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:425)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:316)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.createProducer(CommandsProcessor.java:83)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>(CommandsProcessor.java:53)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 18:17:16,032 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-15 18:17:16,083 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:17:16,084 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-3] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:17:16,091 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-3] Revoking previously assigned partitions []
2018-12-15 18:17:16,091 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-12-15 18:17:16,091 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to REBALANCING
2018-12-15 18:17:16,092 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:17:16,092 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition revocation took 1 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-12-15 18:17:16,092 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-3] (Re-)joining group
2018-12-15 18:17:16,272 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 59
2018-12-15 18:17:16,287 INFO pool-2-thread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:17:16,288 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-4] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:17:16,288 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-4] Revoking previously assigned partitions []
2018-12-15 18:17:16,289 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-4] (Re-)joining group
2018-12-15 18:17:16,293 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wordcount-lambda-example-client-StreamThread-1-consumer] Assigned tasks to clients as {beda098a-1a50-4dbf-9d42-ecaba0ceae57=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) assignedTasks: ([0_0, 1_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2018-12-15 18:17:16,296 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-3] The following not-subscribed topics are assigned, and their metadata will be fetched from the brokers: [wordcount-lambda-example-3-shop-items-store-repartition]
2018-12-15 18:17:16,299 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-4] Successfully joined group with generation 1
2018-12-15 18:17:16,301 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-3] Successfully joined group with generation 1
2018-12-15 18:17:16,303 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-4] Setting newly assigned partitions [shop-items-commands-0]
2018-12-15 18:17:16,304 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-3] Setting newly assigned partitions [shop-items-0, wordcount-lambda-example-3-shop-items-store-repartition-0]
2018-12-15 18:17:16,304 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2018-12-15 18:17:16,315 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-4] Resetting offset for partition shop-items-commands-0 to offset 0.
2018-12-15 18:17:16,342 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition assignment took 38 ms.
	current active tasks: [0_0, 1_0]
	current standby tasks: []
	previous active tasks: []

2018-12-15 18:17:16,345 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-3] Resetting offset for partition shop-items-0 to offset 0.
2018-12-15 18:17:16,345 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-3] Resetting offset for partition wordcount-lambda-example-3-shop-items-store-repartition-0 to offset 0.
2018-12-15 18:17:34,315 INFO kafka-coordinator-heartbeat-thread | some-group-id-4  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-4] Group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2018-12-15 18:17:34,315 INFO kafka-coordinator-heartbeat-thread | wordcount-lambda-example-3  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-3] Group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2018-12-15 18:18:40,235 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-3] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:18:40,255 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:18:40,272 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:18:40,275 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:18:40,275 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2018-12-15 18:18:40,275 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from REBALANCING to RUNNING
2018-12-15 18:18:40,278 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-3] Attempt to heartbeat failed for since member id wordcount-lambda-example-client-StreamThread-1-consumer-128d2833-37d1-4071-aacb-1254a3aa40ad is not valid.
2018-12-15 18:18:40,282 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-3] Revoking previously assigned partitions [shop-items-0, wordcount-lambda-example-3-shop-items-store-repartition-0]
2018-12-15 18:18:40,282 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-12-15 18:18:40,282 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to REBALANCING
2018-12-15 18:18:58,339 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 18:18:58,351 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 18:18:58,363 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ae42ce3, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4f5991f6, org.springframework.test.context.support.DirtiesContextTestExecutionListener@484094a5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@38234a38, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@63fbfaeb]
2018-12-15 18:18:59,143 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11489 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 18:18:59,143 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 18:18:59,201 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:18:59 CET 2018]; root of context hierarchy
2018-12-15 18:18:59,579 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 18:19:00,270 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$d0b6a69] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 18:19:01,535 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 18:19:01,543 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 18:19:01,604 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 18:19:01,605 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 18:19:01,607 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 18:19:01,758 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 18:19:01,803 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 18:19:01,918 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 18:19:02,117 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:19:02,125 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:19:02,688 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example-5
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 18:19:02,719 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 18:19:02,767 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:19:02,767 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:19:02,774 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 18:19:02,778 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:19:02,818 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:19:02,818 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:19:02,819 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 18:19:02,821 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 18:19:02,842 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:19:02,842 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:19:02,850 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 18:19:02,851 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example-5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:19:02,860 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 18:19:02,861 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:19:02,861 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:19:02,867 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Starting
2018-12-15 18:19:02,867 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to RUNNING
2018-12-15 18:19:02,868 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 18:19:02,874 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:19:02,878 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:19:02,878 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:19:02,914 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-15 18:19:02,917 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:19:02,917 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:19:02,918 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:19:02,924 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 18:19:02,926 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:19:02,926 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:19:02,929 WARN main  org.apache.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=my-client-id
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:62)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:425)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:316)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.createProducer(CommandsProcessor.java:83)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>(CommandsProcessor.java:53)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 18:19:02,930 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-15 18:19:02,963 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:19:02,963 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:19:02,970 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Revoking previously assigned partitions []
2018-12-15 18:19:02,970 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-12-15 18:19:02,970 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to REBALANCING
2018-12-15 18:19:02,971 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:19:02,971 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition revocation took 1 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-12-15 18:19:02,971 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] (Re-)joining group
2018-12-15 18:19:03,114 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wordcount-lambda-example-client-StreamThread-1-consumer] Assigned tasks to clients as {0d6ec131-7074-4f8e-94ca-41d1a6126ee3=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) assignedTasks: ([0_0, 1_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2018-12-15 18:19:03,116 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] The following not-subscribed topics are assigned, and their metadata will be fetched from the brokers: [wordcount-lambda-example-5-shop-items-store-repartition]
2018-12-15 18:19:03,121 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Successfully joined group with generation 1
2018-12-15 18:19:03,124 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Setting newly assigned partitions [shop-items-0, wordcount-lambda-example-5-shop-items-store-repartition-0]
2018-12-15 18:19:03,124 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2018-12-15 18:19:03,147 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition assignment took 23 ms.
	current active tasks: [0_0, 1_0]
	current standby tasks: []
	previous active tasks: []

2018-12-15 18:19:03,150 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 60
2018-12-15 18:19:03,156 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Resetting offset for partition shop-items-0 to offset 0.
2018-12-15 18:19:03,156 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Resetting offset for partition wordcount-lambda-example-5-shop-items-store-repartition-0 to offset 0.
2018-12-15 18:19:03,156 INFO pool-2-thread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:19:03,157 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:19:03,157 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Revoking previously assigned partitions []
2018-12-15 18:19:03,158 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] (Re-)joining group
2018-12-15 18:19:03,164 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Successfully joined group with generation 1
2018-12-15 18:19:03,165 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Setting newly assigned partitions [shop-items-commands-0]
2018-12-15 18:19:03,170 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Resetting offset for partition shop-items-commands-0 to offset 0.
2018-12-15 18:19:03,249 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:19:03,257 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:19:03,260 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:19:03,260 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2018-12-15 18:19:03,262 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from REBALANCING to RUNNING
2018-12-15 18:19:03,293 INFO kafka-producer-network-thread | wordcount-lambda-example-client-StreamThread-1-producer  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:19:03,506 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:18:59 CET 2018]; root of context hierarchy
2018-12-15 18:19:03,562 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-15 18:19:03,563 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-15 18:19:03,586 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:19:03,586 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:19:03,616 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:19:03,862 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.395 seconds (JVM running for 6.828)
2018-12-15 18:19:03,864 INFO pool-3-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-15T17:19:03.857Z
2018-12-15 18:19:03,905 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:19:13,921 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:18:59 CET 2018]; root of context hierarchy
2018-12-15 18:19:13,924 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:19:13,925 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Informed to shut down
2018-12-15 18:19:13,925 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:19:13,965 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutting down
2018-12-15 18:19:13,981 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:19:13,982 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=wordcount-lambda-example-client-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-12-15 18:19:13,988 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2018-12-15 18:19:13,988 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutdown complete
2018-12-15 18:19:13,989 INFO kafka-streams-close-thread  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from PENDING_SHUTDOWN to NOT_RUNNING
2018-12-15 18:19:13,990 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Streams client stopped completely
2018-12-15 18:19:13,990 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-15 18:19:13,991 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:19:13,995 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:19:51,023 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 18:19:51,041 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 18:19:51,061 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@47a64f7d, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@33d05366, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@27a0a5a2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@7692cd34, org.springframework.test.context.transaction.TransactionalTestExecutionListener@33aa93c, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@32c0915e]
2018-12-15 18:19:51,889 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11494 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 18:19:51,889 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 18:19:51,979 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@279dd959: startup date [Sat Dec 15 18:19:51 CET 2018]; root of context hierarchy
2018-12-15 18:19:52,397 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 18:19:53,274 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$af54ce91] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 18:19:54,862 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 18:19:54,872 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 18:19:54,958 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 18:19:54,961 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 18:19:54,963 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 18:19:55,167 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 18:19:55,216 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 18:19:55,330 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 18:19:55,558 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:19:55,567 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:19:56,212 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example-5
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 18:19:56,247 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 18:19:56,298 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:19:56,299 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:19:56,306 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 18:19:56,309 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:19:56,348 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:19:56,348 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:19:56,349 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 18:19:56,351 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 18:19:56,373 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:19:56,373 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:19:56,380 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 18:19:56,382 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example-5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:19:56,390 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 18:19:56,391 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:19:56,391 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:19:56,397 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Starting
2018-12-15 18:19:56,397 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to RUNNING
2018-12-15 18:19:56,398 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 18:19:56,409 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:19:56,412 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:19:56,412 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:19:56,464 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-15 18:19:56,467 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:19:56,468 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:19:56,469 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:19:56,477 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 18:19:56,482 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:19:56,482 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:19:56,486 WARN main  org.apache.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=my-client-id
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:62)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:425)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:316)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.createProducer(CommandsProcessor.java:84)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>(CommandsProcessor.java:54)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 18:19:56,488 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-15 18:19:56,534 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:19:56,535 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:19:56,542 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Revoking previously assigned partitions []
2018-12-15 18:19:56,543 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-12-15 18:19:56,543 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to REBALANCING
2018-12-15 18:19:56,543 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:19:56,543 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition revocation took 0 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-12-15 18:19:56,543 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] (Re-)joining group
2018-12-15 18:19:56,567 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wordcount-lambda-example-client-StreamThread-1-consumer] Assigned tasks to clients as {c0e439c0-1425-4e6d-8965-0dc04d4cc506=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) assignedTasks: ([0_0, 1_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2018-12-15 18:19:56,573 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Successfully joined group with generation 3
2018-12-15 18:19:56,577 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Setting newly assigned partitions [shop-items-0, wordcount-lambda-example-5-shop-items-store-repartition-0]
2018-12-15 18:19:56,577 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2018-12-15 18:19:56,605 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition assignment took 28 ms.
	current active tasks: [0_0, 1_0]
	current standby tasks: []
	previous active tasks: []

2018-12-15 18:19:56,635 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:19:56,643 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StoreChangelogReader - stream-thread [wordcount-lambda-example-client-StreamThread-1] Restoring task 1_0's state store shop-items-store from beginning of the changelog wordcount-lambda-example-5-shop-items-store-changelog-0 
2018-12-15 18:19:56,644 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Resetting offset for partition wordcount-lambda-example-5-shop-items-store-changelog-0 to offset 0.
2018-12-15 18:19:56,673 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:19:56,676 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:19:56,676 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2018-12-15 18:19:56,676 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from REBALANCING to RUNNING
2018-12-15 18:19:56,720 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 61
2018-12-15 18:19:56,726 INFO pool-2-thread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:19:56,727 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:19:56,727 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Revoking previously assigned partitions []
2018-12-15 18:19:56,728 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] (Re-)joining group
2018-12-15 18:19:56,734 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Successfully joined group with generation 3
2018-12-15 18:19:56,735 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Setting newly assigned partitions [shop-items-commands-0]
2018-12-15 18:19:56,740 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Resetting offset for partition shop-items-commands-0 to offset 0.
2018-12-15 18:20:13,757 INFO kafka-coordinator-heartbeat-thread | some-group-id-5  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2018-12-15 18:20:13,757 INFO kafka-coordinator-heartbeat-thread | wordcount-lambda-example-5  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2018-12-15 18:20:13,765 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:20:13,766 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2018-12-15 18:20:13,766 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:20:13,766 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2018-12-15 18:20:18,433 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 18:20:18,448 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 18:20:18,464 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@47a64f7d, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@33d05366, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@27a0a5a2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@7692cd34, org.springframework.test.context.transaction.TransactionalTestExecutionListener@33aa93c, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@32c0915e]
2018-12-15 18:20:19,290 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11500 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 18:20:19,290 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 18:20:19,362 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@46383a78: startup date [Sat Dec 15 18:20:19 CET 2018]; root of context hierarchy
2018-12-15 18:20:19,820 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 18:20:20,606 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$56ce8f2b] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 18:20:22,183 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 18:20:22,195 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 18:20:22,290 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 18:20:22,292 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 18:20:22,294 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 18:20:22,515 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 18:20:22,570 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 18:20:22,696 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 18:20:22,938 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:20:22,945 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:20:23,554 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example-5
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 18:20:23,584 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 18:20:23,630 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:20:23,630 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:20:23,636 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 18:20:23,639 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:20:23,677 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:20:23,677 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:20:23,678 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 18:20:23,680 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 18:20:23,701 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:20:23,701 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:20:23,708 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 18:20:23,709 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example-5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:20:23,716 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 18:20:23,717 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:20:23,717 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:20:23,722 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Starting
2018-12-15 18:20:23,722 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to RUNNING
2018-12-15 18:20:23,723 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 18:20:23,732 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:20:23,736 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:20:23,736 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:20:23,783 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-15 18:20:23,786 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:20:23,786 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:20:23,787 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:20:23,795 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 18:20:23,798 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:20:23,799 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:20:23,803 WARN main  org.apache.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=my-client-id
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:62)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:425)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:316)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.createProducer(CommandsProcessor.java:84)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>(CommandsProcessor.java:54)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 18:20:23,805 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-15 18:20:23,854 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:20:23,855 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:20:23,863 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Revoking previously assigned partitions []
2018-12-15 18:20:23,863 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-12-15 18:20:23,864 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to REBALANCING
2018-12-15 18:20:23,864 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:20:23,864 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition revocation took 0 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-12-15 18:20:23,864 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] (Re-)joining group
2018-12-15 18:20:23,888 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wordcount-lambda-example-client-StreamThread-1-consumer] Assigned tasks to clients as {0dd99437-ba42-4831-b001-780c550ffa71=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) assignedTasks: ([0_0, 1_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2018-12-15 18:20:23,894 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Successfully joined group with generation 5
2018-12-15 18:20:23,896 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Setting newly assigned partitions [shop-items-0, wordcount-lambda-example-5-shop-items-store-repartition-0]
2018-12-15 18:20:23,897 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2018-12-15 18:20:23,922 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition assignment took 25 ms.
	current active tasks: [0_0, 1_0]
	current standby tasks: []
	previous active tasks: []

2018-12-15 18:20:23,955 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:20:23,963 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StoreChangelogReader - stream-thread [wordcount-lambda-example-client-StreamThread-1] Restoring task 1_0's state store shop-items-store from beginning of the changelog wordcount-lambda-example-5-shop-items-store-changelog-0 
2018-12-15 18:20:23,965 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Resetting offset for partition wordcount-lambda-example-5-shop-items-store-changelog-0 to offset 0.
2018-12-15 18:20:23,992 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:20:23,995 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:20:23,995 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2018-12-15 18:20:23,996 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from REBALANCING to RUNNING
2018-12-15 18:20:24,042 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 62
2018-12-15 18:20:24,049 INFO pool-2-thread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:20:24,049 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:20:24,050 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Revoking previously assigned partitions []
2018-12-15 18:20:24,050 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] (Re-)joining group
2018-12-15 18:20:24,056 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Successfully joined group with generation 5
2018-12-15 18:20:24,057 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Setting newly assigned partitions [shop-items-commands-0]
2018-12-15 18:20:24,061 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Resetting offset for partition shop-items-commands-0 to offset 0.
2018-12-15 18:20:39,907 INFO kafka-coordinator-heartbeat-thread | wordcount-lambda-example-5  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2018-12-15 18:20:39,907 INFO kafka-coordinator-heartbeat-thread | some-group-id-5  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2018-12-15 18:20:39,915 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:20:39,915 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2018-12-15 18:20:39,915 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:20:39,915 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2018-12-15 18:21:05,280 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 18:21:05,294 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 18:21:05,306 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ae42ce3, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4f5991f6, org.springframework.test.context.support.DirtiesContextTestExecutionListener@484094a5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@38234a38, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@63fbfaeb]
2018-12-15 18:21:06,057 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11505 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 18:21:06,057 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 18:21:06,116 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:21:06 CET 2018]; root of context hierarchy
2018-12-15 18:21:06,481 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 18:21:07,131 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$d0b6a69] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 18:21:08,397 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 18:21:08,404 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 18:21:08,465 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 18:21:08,466 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 18:21:08,467 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 18:21:08,624 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 18:21:08,673 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 18:21:08,812 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 18:21:09,045 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:21:09,054 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:21:09,617 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example-5
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 18:21:09,650 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 18:21:09,699 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:21:09,699 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:21:09,705 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 18:21:09,709 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:21:09,749 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:21:09,749 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:21:09,751 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 18:21:09,753 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 18:21:09,773 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:21:09,774 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:21:09,781 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 18:21:09,783 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example-5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:21:09,790 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 18:21:09,790 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:21:09,791 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:21:09,795 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Starting
2018-12-15 18:21:09,796 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to RUNNING
2018-12-15 18:21:09,796 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 18:21:09,803 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:21:09,807 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:21:09,807 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:21:09,843 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-15 18:21:09,848 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:21:09,848 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:21:09,849 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:21:09,858 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 18:21:09,862 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:21:09,862 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:21:09,865 WARN main  org.apache.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=my-client-id
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:62)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:425)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:316)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.createProducer(CommandsProcessor.java:86)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>(CommandsProcessor.java:56)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 18:21:09,866 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-15 18:21:09,891 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:21:09,892 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:21:09,898 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Revoking previously assigned partitions []
2018-12-15 18:21:09,899 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-12-15 18:21:09,899 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to REBALANCING
2018-12-15 18:21:09,900 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:21:09,901 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition revocation took 2 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-12-15 18:21:09,901 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] (Re-)joining group
2018-12-15 18:21:09,922 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wordcount-lambda-example-client-StreamThread-1-consumer] Assigned tasks to clients as {59d1e0c3-d209-4e42-af52-e50c49e2e220=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) assignedTasks: ([0_0, 1_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2018-12-15 18:21:09,927 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Successfully joined group with generation 7
2018-12-15 18:21:09,930 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Setting newly assigned partitions [shop-items-0, wordcount-lambda-example-5-shop-items-store-repartition-0]
2018-12-15 18:21:09,931 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2018-12-15 18:21:09,955 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition assignment took 24 ms.
	current active tasks: [0_0, 1_0]
	current standby tasks: []
	previous active tasks: []

2018-12-15 18:21:10,031 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:21:10,039 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StoreChangelogReader - stream-thread [wordcount-lambda-example-client-StreamThread-1] Restoring task 1_0's state store shop-items-store from beginning of the changelog wordcount-lambda-example-5-shop-items-store-changelog-0 
2018-12-15 18:21:10,041 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Resetting offset for partition wordcount-lambda-example-5-shop-items-store-changelog-0 to offset 0.
2018-12-15 18:21:10,067 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:21:10,070 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:21:10,070 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2018-12-15 18:21:10,070 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from REBALANCING to RUNNING
2018-12-15 18:21:10,085 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 63
2018-12-15 18:21:10,090 INFO pool-2-thread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:21:10,091 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:21:10,091 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Revoking previously assigned partitions []
2018-12-15 18:21:10,092 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] (Re-)joining group
2018-12-15 18:21:10,097 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Successfully joined group with generation 7
2018-12-15 18:21:10,098 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Setting newly assigned partitions [shop-items-commands-0]
2018-12-15 18:21:10,102 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Resetting offset for partition shop-items-commands-0 to offset 0.
2018-12-15 18:21:10,154 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:21:10,192 INFO kafka-producer-network-thread | wordcount-lambda-example-client-StreamThread-1-producer  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:21:10,433 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:21:06 CET 2018]; root of context hierarchy
2018-12-15 18:21:10,492 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-15 18:21:10,493 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-15 18:21:10,517 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:21:10,518 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:21:10,545 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:21:10,791 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.383 seconds (JVM running for 6.82)
2018-12-15 18:21:10,794 INFO pool-3-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-15T17:21:10.786Z
2018-12-15 18:21:10,841 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:21:13,305 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:21:06 CET 2018]; root of context hierarchy
2018-12-15 18:21:13,308 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:21:13,309 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Informed to shut down
2018-12-15 18:21:13,309 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:21:13,314 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutting down
2018-12-15 18:21:13,329 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:21:13,329 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=wordcount-lambda-example-client-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-12-15 18:21:13,335 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2018-12-15 18:21:13,336 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutdown complete
2018-12-15 18:21:13,337 INFO kafka-streams-close-thread  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from PENDING_SHUTDOWN to NOT_RUNNING
2018-12-15 18:21:13,337 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Streams client stopped completely
2018-12-15 18:21:13,337 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-15 18:21:13,338 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:21:13,341 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:21:24,554 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 18:21:24,571 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 18:21:24,589 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@47a64f7d, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@33d05366, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@27a0a5a2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@7692cd34, org.springframework.test.context.transaction.TransactionalTestExecutionListener@33aa93c, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@32c0915e]
2018-12-15 18:21:25,428 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11509 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 18:21:25,428 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 18:21:25,507 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@279dd959: startup date [Sat Dec 15 18:21:25 CET 2018]; root of context hierarchy
2018-12-15 18:21:26,025 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 18:21:26,901 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$1e9532d7] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 18:21:28,617 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 18:21:28,629 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 18:21:28,725 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 18:21:28,728 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 18:21:28,729 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 18:21:28,946 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 18:21:28,993 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 18:21:29,114 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 18:21:29,347 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:21:29,355 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:21:30,001 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example-5
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 18:21:30,040 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 18:21:30,090 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:21:30,090 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:21:30,097 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 18:21:30,100 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:21:30,141 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:21:30,141 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:21:30,143 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 18:21:30,145 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 18:21:30,167 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:21:30,168 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:21:30,176 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 18:21:30,177 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example-5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:21:30,187 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 18:21:30,187 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:21:30,187 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:21:30,193 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Starting
2018-12-15 18:21:30,194 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to RUNNING
2018-12-15 18:21:30,195 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 18:21:30,205 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:21:30,209 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:21:30,209 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:21:30,267 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-15 18:21:30,271 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:21:30,271 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:21:30,271 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:21:30,279 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 18:21:30,282 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:21:30,282 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:21:30,286 WARN main  org.apache.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=my-client-id
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:62)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:425)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:316)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.createProducer(CommandsProcessor.java:86)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>(CommandsProcessor.java:56)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 18:21:30,288 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-15 18:21:30,340 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:21:30,341 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:21:30,348 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Revoking previously assigned partitions []
2018-12-15 18:21:30,348 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-12-15 18:21:30,348 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to REBALANCING
2018-12-15 18:21:30,349 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:21:30,349 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition revocation took 0 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-12-15 18:21:30,349 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] (Re-)joining group
2018-12-15 18:21:30,372 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wordcount-lambda-example-client-StreamThread-1-consumer] Assigned tasks to clients as {f97c6338-2fa5-4220-baf1-24d997890bf4=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) assignedTasks: ([0_0, 1_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2018-12-15 18:21:30,378 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Successfully joined group with generation 9
2018-12-15 18:21:30,381 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Setting newly assigned partitions [shop-items-0, wordcount-lambda-example-5-shop-items-store-repartition-0]
2018-12-15 18:21:30,381 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2018-12-15 18:21:30,409 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition assignment took 28 ms.
	current active tasks: [0_0, 1_0]
	current standby tasks: []
	previous active tasks: []

2018-12-15 18:21:30,445 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:21:30,453 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StoreChangelogReader - stream-thread [wordcount-lambda-example-client-StreamThread-1] Restoring task 1_0's state store shop-items-store from beginning of the changelog wordcount-lambda-example-5-shop-items-store-changelog-0 
2018-12-15 18:21:30,455 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Resetting offset for partition wordcount-lambda-example-5-shop-items-store-changelog-0 to offset 0.
2018-12-15 18:21:30,486 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:21:30,489 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:21:30,489 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2018-12-15 18:21:30,490 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from REBALANCING to RUNNING
2018-12-15 18:21:30,530 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 64
2018-12-15 18:21:30,538 INFO pool-2-thread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:21:30,538 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:21:30,539 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Revoking previously assigned partitions []
2018-12-15 18:21:30,539 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] (Re-)joining group
2018-12-15 18:21:30,546 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Successfully joined group with generation 9
2018-12-15 18:21:30,547 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Setting newly assigned partitions [shop-items-commands-0]
2018-12-15 18:21:42,151 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:21:54,319 INFO kafka-coordinator-heartbeat-thread | some-group-id-5  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2018-12-15 18:21:55,565 INFO kafka-coordinator-heartbeat-thread | wordcount-lambda-example-5  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2018-12-15 18:21:58,129 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:21:58,129 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2018-12-15 18:21:58,231 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:21:58,233 INFO kafka-coordinator-heartbeat-thread | some-group-id-5  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:21:58,234 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Attempt to heartbeat failed for since member id wordcount-lambda-example-client-StreamThread-1-consumer-cc38ab20-54b4-45ad-a751-23bcdb8b70fe is not valid.
2018-12-15 18:21:58,244 INFO kafka-producer-network-thread | wordcount-lambda-example-client-StreamThread-1-producer  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:21:58,280 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@279dd959: startup date [Sat Dec 15 18:21:25 CET 2018]; root of context hierarchy
2018-12-15 18:21:59,190 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Revoking previously assigned partitions [shop-items-0, wordcount-lambda-example-5-shop-items-store-repartition-0]
2018-12-15 18:21:59,190 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-12-15 18:21:59,190 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to REBALANCING
2018-12-15 18:21:59,193 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.AssignedStreamsTasks - stream-thread [wordcount-lambda-example-client-StreamThread-1] Failed to suspend stream task 0_0 since it got migrated to another thread already. Closing it as zombie and move on.
2018-12-15 18:21:59,194 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:21:59,195 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition revocation took 5 ms.
	suspended active tasks: [1_0]
	suspended standby tasks: []
2018-12-15 18:21:59,195 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] (Re-)joining group
2018-12-15 18:21:59,199 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-15 18:21:59,199 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wordcount-lambda-example-client-StreamThread-1-consumer] Assigned tasks to clients as {f97c6338-2fa5-4220-baf1-24d997890bf4=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) assignedTasks: ([0_0, 1_0]) prevActiveTasks: ([1_0]) prevStandbyTasks: ([]) prevAssignedTasks: ([1_0]) capacity: 1]}.
2018-12-15 18:21:59,200 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-15 18:21:59,200 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Successfully joined group with generation 11
2018-12-15 18:21:59,201 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Setting newly assigned partitions [shop-items-0, wordcount-lambda-example-5-shop-items-store-repartition-0]
2018-12-15 18:22:03,792 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2018-12-15 18:22:27,415 INFO kafka-coordinator-heartbeat-thread | wordcount-lambda-example-5  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2018-12-15 18:22:27,415 INFO kafka-coordinator-heartbeat-thread | some-group-id-5  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Attempt to heartbeat failed for since member id order-details-service-consumer-597306dd-9290-4682-829c-9e28c2376b10 is not valid.
2018-12-15 18:22:27,415 INFO kafka-coordinator-heartbeat-thread | some-group-id-5  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2018-12-15 18:22:27,418 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition assignment took 24834 ms.
	current active tasks: [0_0, 1_0]
	current standby tasks: []
	previous active tasks: [1_0]

2018-12-15 18:22:27,418 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:22:27,418 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2018-12-15 18:22:27,421 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:22:27,421 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:22:27,421 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2018-12-15 18:22:27,421 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from REBALANCING to RUNNING
2018-12-15 18:22:27,423 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:22:27,423 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2018-12-15 18:22:27,444 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:22:27,444 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:22:40,939 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 18:22:40,952 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 18:22:40,966 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ae42ce3, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4f5991f6, org.springframework.test.context.support.DirtiesContextTestExecutionListener@484094a5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@38234a38, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@63fbfaeb]
2018-12-15 18:22:41,731 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11514 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 18:22:41,731 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 18:22:41,790 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:22:41 CET 2018]; root of context hierarchy
2018-12-15 18:22:42,141 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 18:22:42,774 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$d0b6a69] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 18:22:44,012 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 18:22:44,022 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 18:22:44,088 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 18:22:44,089 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 18:22:44,090 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 18:22:44,263 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 18:22:44,316 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 18:22:44,439 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 18:22:44,627 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:22:44,635 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:22:45,182 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example-5
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 18:22:45,207 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 18:22:45,245 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:22:45,245 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:22:45,249 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 18:22:45,252 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:22:45,279 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:22:45,280 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:22:45,280 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 18:22:45,282 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 18:22:45,298 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:22:45,298 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:22:45,304 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 18:22:45,306 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example-5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:22:45,313 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 18:22:45,313 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:22:45,313 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:22:45,317 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Starting
2018-12-15 18:22:45,318 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to RUNNING
2018-12-15 18:22:45,318 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 18:22:45,324 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:22:45,327 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:22:45,327 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:22:45,355 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-15 18:22:45,357 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:22:45,357 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:22:45,358 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:22:45,363 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 18:22:45,365 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:22:45,365 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:22:45,368 WARN main  org.apache.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=my-client-id
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:62)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:425)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:316)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.createProducer(CommandsProcessor.java:86)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>(CommandsProcessor.java:56)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 18:22:45,369 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-15 18:22:45,396 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:22:45,396 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:22:45,403 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Revoking previously assigned partitions []
2018-12-15 18:22:45,403 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-12-15 18:22:45,403 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to REBALANCING
2018-12-15 18:22:45,404 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:22:45,404 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition revocation took 1 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-12-15 18:22:45,404 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] (Re-)joining group
2018-12-15 18:22:45,426 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wordcount-lambda-example-client-StreamThread-1-consumer] Assigned tasks to clients as {ff58515f-4108-4f4f-abe3-6ad37f5f417c=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) assignedTasks: ([0_0, 1_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2018-12-15 18:22:45,431 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Successfully joined group with generation 13
2018-12-15 18:22:45,433 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Setting newly assigned partitions [shop-items-0, wordcount-lambda-example-5-shop-items-store-repartition-0]
2018-12-15 18:22:45,433 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2018-12-15 18:22:45,458 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition assignment took 25 ms.
	current active tasks: [0_0, 1_0]
	current standby tasks: []
	previous active tasks: []

2018-12-15 18:22:45,554 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:22:45,562 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StoreChangelogReader - stream-thread [wordcount-lambda-example-client-StreamThread-1] Restoring task 1_0's state store shop-items-store from beginning of the changelog wordcount-lambda-example-5-shop-items-store-changelog-0 
2018-12-15 18:22:45,563 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Resetting offset for partition wordcount-lambda-example-5-shop-items-store-changelog-0 to offset 0.
2018-12-15 18:22:45,588 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:22:45,590 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:22:45,590 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2018-12-15 18:22:45,591 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from REBALANCING to RUNNING
2018-12-15 18:22:45,591 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 65
2018-12-15 18:22:45,597 INFO pool-2-thread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:22:45,597 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:22:45,598 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Revoking previously assigned partitions []
2018-12-15 18:22:45,598 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] (Re-)joining group
2018-12-15 18:22:45,604 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Successfully joined group with generation 11
2018-12-15 18:22:45,605 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Setting newly assigned partitions [shop-items-commands-0]
2018-12-15 18:22:45,636 INFO kafka-producer-network-thread | wordcount-lambda-example-client-StreamThread-1-producer  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:22:45,915 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:22:41 CET 2018]; root of context hierarchy
2018-12-15 18:22:45,971 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-15 18:22:45,972 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-15 18:22:45,993 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:22:45,994 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:22:46,022 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:22:46,271 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.199 seconds (JVM running for 6.651)
2018-12-15 18:22:46,275 INFO pool-3-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-15T17:22:46.266Z
2018-12-15 18:22:46,322 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:22:46,341 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:22:46,576 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:22:41 CET 2018]; root of context hierarchy
2018-12-15 18:22:46,580 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:22:46,581 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Informed to shut down
2018-12-15 18:22:46,581 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:22:46,665 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutting down
2018-12-15 18:22:46,679 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:22:46,679 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=wordcount-lambda-example-client-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-12-15 18:22:46,686 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2018-12-15 18:22:46,686 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutdown complete
2018-12-15 18:22:46,687 INFO kafka-streams-close-thread  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from PENDING_SHUTDOWN to NOT_RUNNING
2018-12-15 18:22:46,687 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Streams client stopped completely
2018-12-15 18:22:46,688 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-15 18:22:46,688 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:22:46,692 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:23:23,128 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 18:23:23,141 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 18:23:23,154 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ae42ce3, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4f5991f6, org.springframework.test.context.support.DirtiesContextTestExecutionListener@484094a5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@38234a38, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@63fbfaeb]
2018-12-15 18:23:23,928 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11520 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 18:23:23,929 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 18:23:23,986 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:23:23 CET 2018]; root of context hierarchy
2018-12-15 18:23:24,368 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 18:23:25,132 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$d0b6a69] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 18:23:26,542 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 18:23:26,550 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 18:23:26,613 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 18:23:26,615 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 18:23:26,616 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 18:23:26,779 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 18:23:26,825 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 18:23:26,950 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 18:23:27,174 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:23:27,183 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:23:27,717 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example-5
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 18:23:27,750 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 18:23:27,800 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:23:27,800 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:23:27,806 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 18:23:27,809 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:23:27,845 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:23:27,845 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:23:27,846 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 18:23:27,848 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 18:23:27,866 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:23:27,867 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:23:27,873 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 18:23:27,875 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example-5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:23:27,883 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 18:23:27,883 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:23:27,883 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:23:27,888 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Starting
2018-12-15 18:23:27,888 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to RUNNING
2018-12-15 18:23:27,889 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 18:23:27,897 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:23:27,900 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:23:27,900 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:23:27,937 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-15 18:23:27,940 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:23:27,940 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:23:27,940 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:23:27,946 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 18:23:27,949 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:23:27,950 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:23:27,952 WARN main  org.apache.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=my-client-id
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:62)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:425)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:316)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.createProducer(CommandsProcessor.java:86)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>(CommandsProcessor.java:56)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 18:23:27,953 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-15 18:23:27,987 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:23:27,988 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:23:27,996 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Revoking previously assigned partitions []
2018-12-15 18:23:27,997 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-12-15 18:23:27,997 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to REBALANCING
2018-12-15 18:23:27,997 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:23:27,997 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition revocation took 0 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-12-15 18:23:27,997 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] (Re-)joining group
2018-12-15 18:23:28,022 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wordcount-lambda-example-client-StreamThread-1-consumer] Assigned tasks to clients as {f478ede9-dd08-4293-8cd4-c87867a9f349=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) assignedTasks: ([0_0, 1_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2018-12-15 18:23:28,029 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Successfully joined group with generation 15
2018-12-15 18:23:28,032 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Setting newly assigned partitions [shop-items-0, wordcount-lambda-example-5-shop-items-store-repartition-0]
2018-12-15 18:23:28,032 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2018-12-15 18:23:28,059 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition assignment took 27 ms.
	current active tasks: [0_0, 1_0]
	current standby tasks: []
	previous active tasks: []

2018-12-15 18:23:28,117 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:23:28,124 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StoreChangelogReader - stream-thread [wordcount-lambda-example-client-StreamThread-1] Restoring task 1_0's state store shop-items-store from beginning of the changelog wordcount-lambda-example-5-shop-items-store-changelog-0 
2018-12-15 18:23:28,126 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Resetting offset for partition wordcount-lambda-example-5-shop-items-store-changelog-0 to offset 0.
2018-12-15 18:23:28,149 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:23:28,151 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:23:28,151 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2018-12-15 18:23:28,151 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from REBALANCING to RUNNING
2018-12-15 18:23:28,178 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 66
2018-12-15 18:23:28,185 INFO pool-2-thread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:23:28,186 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:23:28,186 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Revoking previously assigned partitions []
2018-12-15 18:23:28,187 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] (Re-)joining group
2018-12-15 18:23:28,192 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Successfully joined group with generation 13
2018-12-15 18:23:28,193 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Setting newly assigned partitions [shop-items-commands-0]
2018-12-15 18:23:28,490 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:23:23 CET 2018]; root of context hierarchy
2018-12-15 18:23:28,546 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-15 18:23:28,547 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-15 18:23:28,568 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:23:28,569 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:23:28,597 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:23:28,834 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.569 seconds (JVM running for 7.031)
2018-12-15 18:23:28,836 INFO pool-3-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-15T17:23:28.829Z
2018-12-15 18:23:28,878 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:23:28,904 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:23:29,127 INFO kafka-producer-network-thread | wordcount-lambda-example-client-StreamThread-1-producer  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:23:29,149 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:23:23 CET 2018]; root of context hierarchy
2018-12-15 18:23:29,152 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:23:29,153 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Informed to shut down
2018-12-15 18:23:29,154 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:23:29,229 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutting down
2018-12-15 18:23:29,247 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:23:29,247 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=wordcount-lambda-example-client-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-12-15 18:23:29,254 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2018-12-15 18:23:29,254 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutdown complete
2018-12-15 18:23:29,256 INFO kafka-streams-close-thread  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from PENDING_SHUTDOWN to NOT_RUNNING
2018-12-15 18:23:29,256 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Streams client stopped completely
2018-12-15 18:23:29,256 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-15 18:23:29,256 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:23:29,260 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:24:19,426 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 18:24:19,439 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 18:24:19,452 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ae42ce3, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4f5991f6, org.springframework.test.context.support.DirtiesContextTestExecutionListener@484094a5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@38234a38, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@63fbfaeb]
2018-12-15 18:24:20,193 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11524 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 18:24:20,193 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 18:24:20,251 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:24:20 CET 2018]; root of context hierarchy
2018-12-15 18:24:20,623 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 18:24:21,356 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$d0b6a69] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 18:24:22,684 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 18:24:22,692 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 18:24:22,756 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 18:24:22,758 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 18:24:22,759 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 18:24:22,910 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 18:24:22,953 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 18:24:23,061 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 18:24:23,283 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:24:23,292 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:24:23,841 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example-5
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 18:24:23,869 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 18:24:23,912 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:24:23,913 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:24:23,918 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 18:24:23,921 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:24:23,955 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:24:23,956 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:24:23,957 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 18:24:23,958 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 18:24:23,976 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:24:23,976 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:24:23,982 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 18:24:23,984 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example-5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:24:23,992 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 18:24:23,992 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:24:23,992 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:24:23,997 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Starting
2018-12-15 18:24:23,997 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to RUNNING
2018-12-15 18:24:23,999 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 18:24:24,006 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:24:24,009 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:24:24,009 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:24:24,040 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-15 18:24:24,043 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:24:24,043 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:24:24,044 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:24:24,050 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 18:24:24,053 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:24:24,053 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:24:24,057 WARN main  org.apache.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=my-client-id
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:62)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:425)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:316)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.createProducer(CommandsProcessor.java:86)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>(CommandsProcessor.java:56)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 18:24:24,058 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-15 18:24:24,085 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:24:24,086 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:24:24,092 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Revoking previously assigned partitions []
2018-12-15 18:24:24,092 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-12-15 18:24:24,092 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to REBALANCING
2018-12-15 18:24:24,093 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:24:24,093 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition revocation took 1 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-12-15 18:24:24,093 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] (Re-)joining group
2018-12-15 18:24:24,117 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wordcount-lambda-example-client-StreamThread-1-consumer] Assigned tasks to clients as {e2203937-8238-4c7c-9f22-1ffeb3a0c95a=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) assignedTasks: ([0_0, 1_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2018-12-15 18:24:24,123 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Successfully joined group with generation 17
2018-12-15 18:24:24,126 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Setting newly assigned partitions [shop-items-0, wordcount-lambda-example-5-shop-items-store-repartition-0]
2018-12-15 18:24:24,126 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2018-12-15 18:24:24,152 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition assignment took 26 ms.
	current active tasks: [0_0, 1_0]
	current standby tasks: []
	previous active tasks: []

2018-12-15 18:24:24,221 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:24:24,229 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StoreChangelogReader - stream-thread [wordcount-lambda-example-client-StreamThread-1] Restoring task 1_0's state store shop-items-store from beginning of the changelog wordcount-lambda-example-5-shop-items-store-changelog-0 
2018-12-15 18:24:24,231 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Resetting offset for partition wordcount-lambda-example-5-shop-items-store-changelog-0 to offset 0.
2018-12-15 18:24:24,256 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:24:24,258 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:24:24,259 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2018-12-15 18:24:24,259 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from REBALANCING to RUNNING
2018-12-15 18:24:24,278 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 67
2018-12-15 18:24:24,284 INFO pool-2-thread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:24:24,284 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:24:24,285 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Revoking previously assigned partitions []
2018-12-15 18:24:24,285 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] (Re-)joining group
2018-12-15 18:24:24,290 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Successfully joined group with generation 15
2018-12-15 18:24:24,291 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Setting newly assigned partitions [shop-items-commands-0]
2018-12-15 18:24:24,609 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:24:20 CET 2018]; root of context hierarchy
2018-12-15 18:24:24,666 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-15 18:24:24,666 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-15 18:24:24,689 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:24:24,689 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:24:24,720 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:24:24,968 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.406 seconds (JVM running for 6.813)
2018-12-15 18:24:24,970 INFO pool-3-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-15T17:24:24.963Z
2018-12-15 18:24:25,010 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:24:25,037 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:24:25,263 INFO kafka-producer-network-thread | wordcount-lambda-example-client-StreamThread-1-producer  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:24:25,284 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:24:20 CET 2018]; root of context hierarchy
2018-12-15 18:24:25,288 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:24:25,290 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Informed to shut down
2018-12-15 18:24:25,290 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:24:25,368 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutting down
2018-12-15 18:24:25,387 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:24:25,387 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=wordcount-lambda-example-client-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-12-15 18:24:25,393 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2018-12-15 18:24:25,394 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutdown complete
2018-12-15 18:24:25,395 INFO kafka-streams-close-thread  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from PENDING_SHUTDOWN to NOT_RUNNING
2018-12-15 18:24:25,395 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Streams client stopped completely
2018-12-15 18:24:25,395 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-15 18:24:25,396 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:24:25,399 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:25:17,549 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 18:25:17,563 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 18:25:17,576 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ae42ce3, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4f5991f6, org.springframework.test.context.support.DirtiesContextTestExecutionListener@484094a5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@38234a38, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@63fbfaeb]
2018-12-15 18:25:18,324 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11529 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 18:25:18,325 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 18:25:18,390 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:25:18 CET 2018]; root of context hierarchy
2018-12-15 18:25:18,807 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 18:25:19,587 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$e7c123f6] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 18:25:20,861 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 18:25:20,870 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 18:25:20,954 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 18:25:20,956 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 18:25:20,957 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 18:25:21,105 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 18:25:21,145 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 18:25:21,255 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 18:25:21,461 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:25:21,469 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:25:22,026 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example-5
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 18:25:22,057 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 18:25:22,107 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:25:22,107 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:25:22,113 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 18:25:22,117 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:25:22,152 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:25:22,152 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:25:22,154 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 18:25:22,156 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 18:25:22,177 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:25:22,177 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:25:22,185 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 18:25:22,187 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example-5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:25:22,199 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 18:25:22,200 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:25:22,200 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:25:22,206 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Starting
2018-12-15 18:25:22,206 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to RUNNING
2018-12-15 18:25:22,207 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 18:25:22,214 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:25:22,218 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:25:22,218 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:25:22,262 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-15 18:25:22,266 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:25:22,266 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:25:22,266 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:25:22,273 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 18:25:22,276 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:25:22,276 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:25:22,280 WARN main  org.apache.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=my-client-id
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:62)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:425)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:316)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.createProducer(CommandsProcessor.java:86)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>(CommandsProcessor.java:56)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 18:25:22,282 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-15 18:25:22,301 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:25:22,301 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:25:22,307 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Revoking previously assigned partitions []
2018-12-15 18:25:22,308 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-12-15 18:25:22,308 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to REBALANCING
2018-12-15 18:25:22,308 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:25:22,309 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition revocation took 1 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-12-15 18:25:22,309 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] (Re-)joining group
2018-12-15 18:25:22,333 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wordcount-lambda-example-client-StreamThread-1-consumer] Assigned tasks to clients as {bc8b8235-71ab-4cc0-a570-f5bb54107d4a=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) assignedTasks: ([0_0, 1_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2018-12-15 18:25:22,340 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Successfully joined group with generation 19
2018-12-15 18:25:22,342 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Setting newly assigned partitions [shop-items-0, wordcount-lambda-example-5-shop-items-store-repartition-0]
2018-12-15 18:25:22,343 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2018-12-15 18:25:22,369 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition assignment took 26 ms.
	current active tasks: [0_0, 1_0]
	current standby tasks: []
	previous active tasks: []

2018-12-15 18:25:22,437 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:25:22,444 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StoreChangelogReader - stream-thread [wordcount-lambda-example-client-StreamThread-1] Restoring task 1_0's state store shop-items-store from beginning of the changelog wordcount-lambda-example-5-shop-items-store-changelog-0 
2018-12-15 18:25:22,446 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Resetting offset for partition wordcount-lambda-example-5-shop-items-store-changelog-0 to offset 0.
2018-12-15 18:25:22,470 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:25:22,472 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:25:22,472 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2018-12-15 18:25:22,473 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from REBALANCING to RUNNING
2018-12-15 18:25:22,496 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 68
2018-12-15 18:25:22,502 INFO pool-2-thread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:25:22,502 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:25:22,503 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Revoking previously assigned partitions []
2018-12-15 18:25:22,503 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] (Re-)joining group
2018-12-15 18:25:22,511 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Successfully joined group with generation 17
2018-12-15 18:25:22,512 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Setting newly assigned partitions [shop-items-commands-0]
2018-12-15 18:25:22,817 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:25:18 CET 2018]; root of context hierarchy
2018-12-15 18:25:22,876 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-15 18:25:22,877 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-15 18:25:22,897 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:25:22,898 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:25:22,926 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:25:23,168 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.487 seconds (JVM running for 6.963)
2018-12-15 18:25:23,171 INFO pool-3-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-15T17:25:23.164Z
2018-12-15 18:25:23,212 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:25:23,238 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:25:23,465 INFO kafka-producer-network-thread | wordcount-lambda-example-client-StreamThread-1-producer  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:25:23,584 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:25:18 CET 2018]; root of context hierarchy
2018-12-15 18:25:23,588 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:25:23,589 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Informed to shut down
2018-12-15 18:25:23,589 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:25:23,680 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutting down
2018-12-15 18:25:23,693 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:25:23,693 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=wordcount-lambda-example-client-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-12-15 18:25:23,699 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2018-12-15 18:25:23,699 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutdown complete
2018-12-15 18:25:23,701 INFO kafka-streams-close-thread  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from PENDING_SHUTDOWN to NOT_RUNNING
2018-12-15 18:25:23,701 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Streams client stopped completely
2018-12-15 18:25:23,701 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-15 18:25:23,701 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:25:23,705 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:40:29,471 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 18:40:29,486 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 18:40:29,499 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ae42ce3, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4f5991f6, org.springframework.test.context.support.DirtiesContextTestExecutionListener@484094a5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@38234a38, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@63fbfaeb]
2018-12-15 18:40:30,290 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11834 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 18:40:30,290 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 18:40:30,347 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:40:30 CET 2018]; root of context hierarchy
2018-12-15 18:40:30,704 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 18:40:31,340 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$e7c123f6] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 18:40:32,539 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 18:40:32,547 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 18:40:32,611 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 18:40:32,613 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 18:40:32,615 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 18:40:32,790 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 18:40:32,845 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 18:40:32,971 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 18:40:33,198 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:40:33,206 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:40:33,770 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example-5
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 18:40:33,800 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 18:40:33,847 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:40:33,847 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:40:33,852 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 18:40:33,856 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:40:33,888 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:40:33,888 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:40:33,889 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 18:40:33,891 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 18:40:33,909 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:40:33,909 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:40:33,915 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 18:40:33,916 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example-5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:40:33,924 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 18:40:33,924 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:40:33,924 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:40:33,928 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Starting
2018-12-15 18:40:33,929 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to RUNNING
2018-12-15 18:40:33,929 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 18:40:33,936 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:40:33,939 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:40:33,939 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:40:33,969 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-15 18:40:33,972 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:40:33,972 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:40:33,972 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:40:33,978 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 18:40:33,980 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:40:33,980 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:40:33,982 WARN main  org.apache.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=my-client-id
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:62)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:425)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:316)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.createProducer(CommandsProcessor.java:86)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>(CommandsProcessor.java:56)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 18:40:33,983 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-15 18:40:34,016 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:40:34,016 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:40:34,023 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Revoking previously assigned partitions []
2018-12-15 18:40:34,023 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-12-15 18:40:34,023 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to REBALANCING
2018-12-15 18:40:34,024 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:40:34,024 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition revocation took 1 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-12-15 18:40:34,024 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] (Re-)joining group
2018-12-15 18:40:34,047 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wordcount-lambda-example-client-StreamThread-1-consumer] Assigned tasks to clients as {ae40cfa0-5b40-4744-9dfb-c149bd15bcdd=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) assignedTasks: ([0_0, 1_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2018-12-15 18:40:34,053 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Successfully joined group with generation 21
2018-12-15 18:40:34,056 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Setting newly assigned partitions [shop-items-0, wordcount-lambda-example-5-shop-items-store-repartition-0]
2018-12-15 18:40:34,056 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2018-12-15 18:40:34,081 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition assignment took 25 ms.
	current active tasks: [0_0, 1_0]
	current standby tasks: []
	previous active tasks: []

2018-12-15 18:40:34,152 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:40:34,159 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StoreChangelogReader - stream-thread [wordcount-lambda-example-client-StreamThread-1] Restoring task 1_0's state store shop-items-store from beginning of the changelog wordcount-lambda-example-5-shop-items-store-changelog-0 
2018-12-15 18:40:34,160 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Resetting offset for partition wordcount-lambda-example-5-shop-items-store-changelog-0 to offset 0.
2018-12-15 18:40:34,182 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:40:34,184 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:40:34,184 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2018-12-15 18:40:34,185 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from REBALANCING to RUNNING
2018-12-15 18:40:34,210 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 69
2018-12-15 18:40:34,215 INFO pool-2-thread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:40:34,216 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:40:34,216 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Revoking previously assigned partitions []
2018-12-15 18:40:34,217 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] (Re-)joining group
2018-12-15 18:40:34,222 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Successfully joined group with generation 19
2018-12-15 18:40:34,223 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Setting newly assigned partitions [shop-items-commands-0]
2018-12-15 18:40:34,535 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:40:30 CET 2018]; root of context hierarchy
2018-12-15 18:40:34,593 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-15 18:40:34,594 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-15 18:40:34,615 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:40:34,615 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:40:34,643 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:40:34,887 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.268 seconds (JVM running for 6.739)
2018-12-15 18:40:34,889 INFO pool-3-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-15T17:40:34.882Z
2018-12-15 18:40:34,933 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:40:34,995 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:40:35,023 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:40:30 CET 2018]; root of context hierarchy
2018-12-15 18:40:35,027 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:40:35,028 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Informed to shut down
2018-12-15 18:40:35,028 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:40:35,111 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutting down
2018-12-15 18:40:35,118 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:40:35,118 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=wordcount-lambda-example-client-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-12-15 18:40:35,125 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2018-12-15 18:40:35,125 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutdown complete
2018-12-15 18:40:35,127 INFO kafka-streams-close-thread  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from PENDING_SHUTDOWN to NOT_RUNNING
2018-12-15 18:40:35,127 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Streams client stopped completely
2018-12-15 18:40:35,127 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-15 18:40:35,127 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:40:35,131 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:40:45,530 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 18:40:45,543 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 18:40:45,557 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ae42ce3, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4f5991f6, org.springframework.test.context.support.DirtiesContextTestExecutionListener@484094a5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@38234a38, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@63fbfaeb]
2018-12-15 18:40:46,342 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11838 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 18:40:46,342 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 18:40:46,400 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:40:46 CET 2018]; root of context hierarchy
2018-12-15 18:40:46,786 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 18:40:47,507 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$e8f0e71] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 18:40:48,815 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 18:40:48,823 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 18:40:48,886 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 18:40:48,887 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 18:40:48,889 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 18:40:49,046 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 18:40:49,093 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 18:40:49,203 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 18:40:49,397 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:40:49,406 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:40:49,945 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example-5
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 18:40:49,974 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 18:40:50,019 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:40:50,019 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:40:50,025 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 18:40:50,028 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:40:50,065 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:40:50,065 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:40:50,066 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 18:40:50,068 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 18:40:50,088 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:40:50,089 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:40:50,095 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 18:40:50,097 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example-5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:40:50,105 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 18:40:50,105 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:40:50,105 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:40:50,110 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Starting
2018-12-15 18:40:50,110 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to RUNNING
2018-12-15 18:40:50,111 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 18:40:50,118 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:40:50,121 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:40:50,121 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:40:50,155 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-15 18:40:50,158 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:40:50,159 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:40:50,159 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:40:50,167 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 18:40:50,170 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:40:50,170 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:40:50,172 WARN main  org.apache.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=my-client-id
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:62)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:425)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:316)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.createProducer(CommandsProcessor.java:86)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>(CommandsProcessor.java:56)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 18:40:50,173 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-15 18:40:50,206 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:40:50,207 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:40:50,215 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Revoking previously assigned partitions []
2018-12-15 18:40:50,216 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-12-15 18:40:50,216 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to REBALANCING
2018-12-15 18:40:50,217 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:40:50,217 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition revocation took 1 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-12-15 18:40:50,218 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] (Re-)joining group
2018-12-15 18:40:50,242 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wordcount-lambda-example-client-StreamThread-1-consumer] Assigned tasks to clients as {33a9c106-6d40-4894-81c5-823cd25fe1c1=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) assignedTasks: ([0_0, 1_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2018-12-15 18:40:50,248 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Successfully joined group with generation 23
2018-12-15 18:40:50,251 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Setting newly assigned partitions [shop-items-0, wordcount-lambda-example-5-shop-items-store-repartition-0]
2018-12-15 18:40:50,251 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2018-12-15 18:40:50,279 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition assignment took 28 ms.
	current active tasks: [0_0, 1_0]
	current standby tasks: []
	previous active tasks: []

2018-12-15 18:40:50,347 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:40:50,354 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StoreChangelogReader - stream-thread [wordcount-lambda-example-client-StreamThread-1] Restoring task 1_0's state store shop-items-store from beginning of the changelog wordcount-lambda-example-5-shop-items-store-changelog-0 
2018-12-15 18:40:50,356 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Resetting offset for partition wordcount-lambda-example-5-shop-items-store-changelog-0 to offset 0.
2018-12-15 18:40:50,378 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:40:50,380 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:40:50,380 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2018-12-15 18:40:50,381 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from REBALANCING to RUNNING
2018-12-15 18:40:50,500 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 71
2018-12-15 18:40:50,505 INFO pool-2-thread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:40:50,505 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:40:50,506 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Revoking previously assigned partitions []
2018-12-15 18:40:50,506 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] (Re-)joining group
2018-12-15 18:40:50,510 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Successfully joined group with generation 21
2018-12-15 18:40:50,510 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Setting newly assigned partitions [shop-items-commands-0]
2018-12-15 18:40:50,551 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:40:50,795 INFO kafka-producer-network-thread | wordcount-lambda-example-client-StreamThread-1-producer  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:40:50,821 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:40:46 CET 2018]; root of context hierarchy
2018-12-15 18:40:50,877 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-15 18:40:50,878 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-15 18:40:50,900 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:40:50,900 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:40:50,930 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:40:51,189 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.523 seconds (JVM running for 6.926)
2018-12-15 18:40:51,192 INFO pool-3-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-15T17:40:51.185Z
2018-12-15 18:40:51,233 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:40:51,372 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:40:46 CET 2018]; root of context hierarchy
2018-12-15 18:40:51,375 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:40:51,376 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Informed to shut down
2018-12-15 18:40:51,376 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:40:51,456 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutting down
2018-12-15 18:40:51,469 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:40:51,469 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=wordcount-lambda-example-client-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-12-15 18:40:51,475 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2018-12-15 18:40:51,475 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutdown complete
2018-12-15 18:40:51,476 INFO kafka-streams-close-thread  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from PENDING_SHUTDOWN to NOT_RUNNING
2018-12-15 18:40:51,476 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Streams client stopped completely
2018-12-15 18:40:51,477 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-15 18:40:51,477 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:40:51,481 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:49:50,266 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 18:49:50,280 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 18:49:50,293 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ae42ce3, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4f5991f6, org.springframework.test.context.support.DirtiesContextTestExecutionListener@484094a5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@38234a38, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@63fbfaeb]
2018-12-15 18:49:51,072 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11858 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 18:49:51,073 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 18:49:51,133 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:49:51 CET 2018]; root of context hierarchy
2018-12-15 18:49:51,486 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 18:49:52,122 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$e7c123f6] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 18:49:53,317 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 18:49:53,325 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 18:49:53,387 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 18:49:53,388 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 18:49:53,389 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 18:49:53,549 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 18:49:53,608 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 18:49:53,729 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 18:49:53,952 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:49:53,959 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:49:54,178 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example-5
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 18:49:54,210 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 18:49:54,259 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:49:54,259 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:49:54,265 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 18:49:54,268 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:49:54,456 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:49:54,456 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:49:54,457 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 18:49:54,459 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 18:49:54,479 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:49:54,480 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:49:54,487 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 18:49:54,489 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example-5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:49:54,497 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 18:49:54,498 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:49:54,498 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:49:54,504 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Starting
2018-12-15 18:49:54,505 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to RUNNING
2018-12-15 18:49:54,505 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 18:49:54,512 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:49:54,515 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:49:54,515 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:49:54,598 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:49:54,599 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:49:54,605 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Revoking previously assigned partitions []
2018-12-15 18:49:54,606 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-12-15 18:49:54,606 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to REBALANCING
2018-12-15 18:49:54,607 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:49:54,608 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition revocation took 1 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-12-15 18:49:54,608 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] (Re-)joining group
2018-12-15 18:49:54,629 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wordcount-lambda-example-client-StreamThread-1-consumer] Assigned tasks to clients as {bb6e6a05-99f0-4439-a868-b334ecaa79a1=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) assignedTasks: ([0_0, 1_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2018-12-15 18:49:54,635 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Successfully joined group with generation 25
2018-12-15 18:49:54,638 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Setting newly assigned partitions [shop-items-0, wordcount-lambda-example-5-shop-items-store-repartition-0]
2018-12-15 18:49:54,638 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2018-12-15 18:49:54,663 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition assignment took 25 ms.
	current active tasks: [0_0, 1_0]
	current standby tasks: []
	previous active tasks: []

2018-12-15 18:49:54,740 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:49:54,748 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StoreChangelogReader - stream-thread [wordcount-lambda-example-client-StreamThread-1] Restoring task 1_0's state store shop-items-store from beginning of the changelog wordcount-lambda-example-5-shop-items-store-changelog-0 
2018-12-15 18:49:54,750 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Resetting offset for partition wordcount-lambda-example-5-shop-items-store-changelog-0 to offset 0.
2018-12-15 18:49:54,773 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-15 18:49:54,775 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:49:54,776 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:49:54,776 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:49:54,781 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:49:54,783 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 18:49:54,783 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:49:54,784 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2018-12-15 18:49:54,784 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from REBALANCING to RUNNING
2018-12-15 18:49:54,785 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:49:54,785 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:49:54,787 WARN main  org.apache.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=my-client-id
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:62)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:425)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:316)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.createProducer(CommandsProcessor.java:86)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>(CommandsProcessor.java:56)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 18:49:54,788 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-15 18:49:55,002 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 72
2018-12-15 18:49:55,008 INFO pool-2-thread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:49:55,008 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:49:55,009 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Revoking previously assigned partitions []
2018-12-15 18:49:55,009 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] (Re-)joining group
2018-12-15 18:49:55,016 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Successfully joined group with generation 23
2018-12-15 18:49:55,017 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Setting newly assigned partitions [shop-items-commands-0]
2018-12-15 18:49:55,319 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:49:51 CET 2018]; root of context hierarchy
2018-12-15 18:49:55,376 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-15 18:49:55,377 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-15 18:49:55,398 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:49:55,398 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:49:55,424 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:49:55,675 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.273 seconds (JVM running for 6.719)
2018-12-15 18:49:55,678 INFO pool-3-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-15T17:49:55.669Z
2018-12-15 18:49:55,726 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:49:55,782 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:49:55,863 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:49:51 CET 2018]; root of context hierarchy
2018-12-15 18:49:55,866 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:49:55,867 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Informed to shut down
2018-12-15 18:49:55,867 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:49:55,917 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutting down
2018-12-15 18:49:55,924 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:49:55,924 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=wordcount-lambda-example-client-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-12-15 18:49:55,931 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2018-12-15 18:49:55,931 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutdown complete
2018-12-15 18:49:55,933 INFO kafka-streams-close-thread  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from PENDING_SHUTDOWN to NOT_RUNNING
2018-12-15 18:49:55,933 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Streams client stopped completely
2018-12-15 18:49:55,933 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-15 18:49:55,934 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:49:55,938 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:50:03,100 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 18:50:03,121 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 18:50:03,136 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ae42ce3, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4f5991f6, org.springframework.test.context.support.DirtiesContextTestExecutionListener@484094a5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@38234a38, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@63fbfaeb]
2018-12-15 18:50:03,881 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11861 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 18:50:03,882 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 18:50:03,941 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:50:03 CET 2018]; root of context hierarchy
2018-12-15 18:50:04,325 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 18:50:05,100 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$e8f0e71] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 18:50:06,703 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 18:50:06,711 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 18:50:06,782 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 18:50:06,783 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 18:50:06,785 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 18:50:06,960 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 18:50:07,023 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 18:50:07,173 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 18:50:07,384 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:50:07,392 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:50:07,635 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example-5
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 18:50:07,670 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 18:50:07,717 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:50:07,717 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:50:07,722 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 18:50:07,725 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:50:07,911 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:50:07,911 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:50:07,912 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 18:50:07,915 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 18:50:07,939 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:50:07,939 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:50:07,949 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 18:50:07,951 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example-5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:50:07,959 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 18:50:07,959 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:50:07,960 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:50:07,965 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Starting
2018-12-15 18:50:07,965 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to RUNNING
2018-12-15 18:50:07,966 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 18:50:07,974 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:50:07,978 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:50:07,979 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:50:08,075 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:50:08,076 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:50:08,085 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Revoking previously assigned partitions []
2018-12-15 18:50:08,085 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-12-15 18:50:08,085 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to REBALANCING
2018-12-15 18:50:08,086 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:50:08,086 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition revocation took 0 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-12-15 18:50:08,087 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] (Re-)joining group
2018-12-15 18:50:08,110 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wordcount-lambda-example-client-StreamThread-1-consumer] Assigned tasks to clients as {bf5f149a-ec51-488c-b228-734da4e51a2f=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) assignedTasks: ([0_0, 1_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2018-12-15 18:50:08,117 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Successfully joined group with generation 27
2018-12-15 18:50:08,121 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Setting newly assigned partitions [shop-items-0, wordcount-lambda-example-5-shop-items-store-repartition-0]
2018-12-15 18:50:08,121 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2018-12-15 18:50:08,149 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition assignment took 28 ms.
	current active tasks: [0_0, 1_0]
	current standby tasks: []
	previous active tasks: []

2018-12-15 18:50:08,193 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:50:08,202 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StoreChangelogReader - stream-thread [wordcount-lambda-example-client-StreamThread-1] Restoring task 1_0's state store shop-items-store from beginning of the changelog wordcount-lambda-example-5-shop-items-store-changelog-0 
2018-12-15 18:50:08,205 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Resetting offset for partition wordcount-lambda-example-5-shop-items-store-changelog-0 to offset 0.
2018-12-15 18:50:08,233 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:50:08,235 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:50:08,235 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2018-12-15 18:50:08,236 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from REBALANCING to RUNNING
2018-12-15 18:50:08,260 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-15 18:50:08,262 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:50:08,262 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:50:08,262 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:50:08,267 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 18:50:08,269 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:50:08,269 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:50:08,271 WARN main  org.apache.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=my-client-id
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:62)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:425)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:316)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.createProducer(CommandsProcessor.java:86)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>(CommandsProcessor.java:56)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 18:50:08,272 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-15 18:50:08,592 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 74
2018-12-15 18:50:08,598 INFO pool-2-thread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:50:08,598 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:50:08,598 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Revoking previously assigned partitions []
2018-12-15 18:50:08,599 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] (Re-)joining group
2018-12-15 18:50:08,604 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Successfully joined group with generation 25
2018-12-15 18:50:08,605 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Setting newly assigned partitions [shop-items-commands-0]
2018-12-15 18:50:08,650 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:50:08,891 INFO kafka-producer-network-thread | wordcount-lambda-example-client-StreamThread-1-producer  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:50:08,923 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:50:03 CET 2018]; root of context hierarchy
2018-12-15 18:50:08,995 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-15 18:50:08,996 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-15 18:50:09,027 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:50:09,027 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:50:09,061 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:50:09,333 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 6.095 seconds (JVM running for 7.539)
2018-12-15 18:50:09,336 INFO pool-3-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-15T17:50:09.328Z
2018-12-15 18:50:09,376 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:50:09,515 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:50:03 CET 2018]; root of context hierarchy
2018-12-15 18:50:09,518 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:50:09,519 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Informed to shut down
2018-12-15 18:50:09,520 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:50:09,597 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutting down
2018-12-15 18:50:09,611 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:50:09,611 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=wordcount-lambda-example-client-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-12-15 18:50:09,618 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2018-12-15 18:50:09,619 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutdown complete
2018-12-15 18:50:09,620 INFO kafka-streams-close-thread  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from PENDING_SHUTDOWN to NOT_RUNNING
2018-12-15 18:50:09,620 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Streams client stopped completely
2018-12-15 18:50:09,621 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-15 18:50:09,621 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:50:09,625 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:51:17,541 INFO main  org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [io.dddbyexamples.eventsource.integration.IntegrationSpec]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-12-15 18:51:17,554 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2018-12-15 18:51:17,566 INFO main  org.springframework.test.context.web.WebTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5a755cc1, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ae42ce3, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4f5991f6, org.springframework.test.context.support.DirtiesContextTestExecutionListener@484094a5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@38234a38, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@63fbfaeb]
2018-12-15 18:51:18,284 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Starting ShopItemsIntegrationSpec on pawes-macbook-pro.home with PID 11867 (/Users/pszymczyk/Dev/repo/event-source-cqrs-sample/out/test/classes started by pszymczyk in /Users/pszymczyk/Dev/repo/event-source-cqrs-sample)
2018-12-15 18:51:18,284 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - The following profiles are active: test
2018-12-15 18:51:18,331 INFO main  org.springframework.web.context.support.GenericWebApplicationContext - Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:51:18 CET 2018]; root of context hierarchy
2018-12-15 18:51:18,689 INFO background-preinit  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.2.4.Final
2018-12-15 18:51:19,333 INFO main  org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$e7c123f6] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-15 18:51:20,544 INFO main  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-12-15 18:51:20,554 INFO main  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-12-15 18:51:20,621 INFO main  org.hibernate.Version - HHH000412: Hibernate Core {4.3.11.Final}
2018-12-15 18:51:20,622 INFO main  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
2018-12-15 18:51:20,624 INFO main  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
2018-12-15 18:51:20,806 INFO main  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-12-15 18:51:20,861 INFO main  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-12-15 18:51:20,989 INFO main  org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory - HHH000397: Using ASTQueryTranslatorFactory
2018-12-15 18:51:21,186 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:51:21,195 INFO main  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
2018-12-15 18:51:21,398 INFO main  org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
	application.id = wordcount-lambda-example-5
	application.server = 
	bootstrap.servers = [localhost:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = wordcount-lambda-example-client
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2018-12-15 18:51:21,427 INFO main  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-12-15 18:51:21,471 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:51:21,471 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:51:21,476 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating restore consumer client
2018-12-15 18:51:21,479 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:51:21,657 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:51:21,658 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:51:21,659 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating shared producer client
2018-12-15 18:51:21,661 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-12-15 18:51:21,680 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:51:21,680 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:51:21,687 INFO main  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Creating consumer client
2018-12-15 18:51:21,688 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = wordcount-lambda-example-client-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wordcount-lambda-example-5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-12-15 18:51:21,696 WARN main  org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
2018-12-15 18:51:21,696 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:51:21,696 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:51:21,701 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Starting
2018-12-15 18:51:21,702 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from CREATED to RUNNING
2018-12-15 18:51:21,702 INFO main  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Started Streams client
2018-12-15 18:51:21,708 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:51:21,712 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:51:21,712 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:51:21,790 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:51:21,790 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:51:21,797 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Revoking previously assigned partitions []
2018-12-15 18:51:21,798 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-12-15 18:51:21,798 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to REBALANCING
2018-12-15 18:51:21,799 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:51:21,799 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition revocation took 1 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-12-15 18:51:21,799 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] (Re-)joining group
2018-12-15 18:51:21,818 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wordcount-lambda-example-client-StreamThread-1-consumer] Assigned tasks to clients as {6c7be380-a212-45f0-a7aa-ac2a6b6a99ac=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) assignedTasks: ([0_0, 1_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2018-12-15 18:51:21,823 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Successfully joined group with generation 29
2018-12-15 18:51:21,826 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-consumer, groupId=wordcount-lambda-example-5] Setting newly assigned partitions [shop-items-0, wordcount-lambda-example-5-shop-items-store-repartition-0]
2018-12-15 18:51:21,826 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2018-12-15 18:51:21,849 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] partition assignment took 23 ms.
	current active tasks: [0_0, 1_0]
	current standby tasks: []
	previous active tasks: []

2018-12-15 18:51:21,934 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:51:21,943 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StoreChangelogReader - stream-thread [wordcount-lambda-example-client-StreamThread-1] Restoring task 1_0's state store shop-items-store from beginning of the changelog wordcount-lambda-example-5-shop-items-store-changelog-0 
2018-12-15 18:51:21,945 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Resetting offset for partition wordcount-lambda-example-5-shop-items-store-changelog-0 to offset 0.
2018-12-15 18:51:21,950 INFO main  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = order-details-service-consumer
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = some-group-id-5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2018-12-15 18:51:21,952 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:51:21,952 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:51:21,953 INFO main  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = my-client-id
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = my-transactional-id
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2018-12-15 18:51:21,960 INFO main  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=my-client-id, transactionalId=my-transactional-id] Instantiated a transactional producer.
2018-12-15 18:51:21,962 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.1.0
2018-12-15 18:51:21,962 INFO main  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : eec43959745f444f
2018-12-15 18:51:21,965 WARN main  org.apache.kafka.common.utils.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=my-client-id
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:62)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:425)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:316)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.createProducer(CommandsProcessor.java:85)
	at io.dddbyexamples.eventsource.kafka.CommandsProcessor.<init>(CommandsProcessor.java:56)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:766)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.test.SpringApplicationContextLoader.loadContext(SpringApplicationContextLoader.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:98)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:116)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:183)
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:123)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:228)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:49)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:42)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:28)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:87)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:471)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:375)
	at org.spockframework.runtime.BaseSpecRunner.runSetup(BaseSpecRunner.java:370)
	at org.spockframework.runtime.BaseSpecRunner.doRunIteration(BaseSpecRunner.java:323)
	at org.spockframework.runtime.BaseSpecRunner$6.invoke(BaseSpecRunner.java:309)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runIteration(BaseSpecRunner.java:288)
	at org.spockframework.runtime.BaseSpecRunner.initializeAndRunIteration(BaseSpecRunner.java:278)
	at org.spockframework.runtime.BaseSpecRunner.runSimpleFeature(BaseSpecRunner.java:269)
	at org.spockframework.runtime.BaseSpecRunner.doRunFeature(BaseSpecRunner.java:263)
	at org.spockframework.runtime.BaseSpecRunner$5.invoke(BaseSpecRunner.java:246)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runFeature(BaseSpecRunner.java:238)
	at org.spockframework.runtime.BaseSpecRunner.runFeatures(BaseSpecRunner.java:188)
	at org.spockframework.runtime.BaseSpecRunner.doRunSpec(BaseSpecRunner.java:98)
	at org.spockframework.runtime.BaseSpecRunner$1.invoke(BaseSpecRunner.java:84)
	at org.spockframework.runtime.BaseSpecRunner.invokeRaw(BaseSpecRunner.java:480)
	at org.spockframework.runtime.BaseSpecRunner.invoke(BaseSpecRunner.java:463)
	at org.spockframework.runtime.BaseSpecRunner.runSpec(BaseSpecRunner.java:76)
	at org.spockframework.runtime.BaseSpecRunner.run(BaseSpecRunner.java:67)
	at org.spockframework.runtime.Sputnik.run(Sputnik.java:63)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2018-12-15 18:51:21,966 INFO main  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to -1 with epoch -1
2018-12-15 18:51:21,975 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:51:21,977 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:51:21,977 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2018-12-15 18:51:21,978 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from REBALANCING to RUNNING
2018-12-15 18:51:22,179 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=my-client-id, transactionalId=my-transactional-id] ProducerId set to 0 with epoch 75
2018-12-15 18:51:22,184 INFO pool-2-thread-1  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:51:22,185 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Discovered group coordinator pawes-macbook-pro.home:9092 (id: 2147483647 rack: null)
2018-12-15 18:51:22,185 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Revoking previously assigned partitions []
2018-12-15 18:51:22,185 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] (Re-)joining group
2018-12-15 18:51:22,191 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Successfully joined group with generation 27
2018-12-15 18:51:22,192 INFO pool-2-thread-1  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=order-details-service-consumer, groupId=some-group-id-5] Setting newly assigned partitions [shop-items-commands-0]
2018-12-15 18:51:22,497 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:51:18 CET 2018]; root of context hierarchy
2018-12-15 18:51:22,554 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-15 18:51:22,555 INFO main  org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-15 18:51:22,577 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:51:22,577 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:51:22,604 INFO main  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-15 18:51:22,851 INFO main  io.dddbyexamples.eventsource.integration.boundary.ShopItemsIntegrationSpec - Started ShopItemsIntegrationSpec in 5.18 seconds (JVM running for 6.598)
2018-12-15 18:51:22,854 INFO pool-3-thread-1  io.dddbyexamples.eventsource.readmodel.PaymentTimeoutChecker - Marking 0 items that payment did not arrive at 2018-12-15T17:51:22.847Z
2018-12-15 18:51:22,903 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:51:22,964 INFO kafka-producer-network-thread | my-client-id  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:51:23,197 INFO kafka-producer-network-thread | wordcount-lambda-example-client-StreamThread-1-producer  org.apache.kafka.clients.Metadata - Cluster ID: UG-Taq7aQG2zNQPNCw-Oog
2018-12-15 18:51:23,422 INFO Thread-2  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@5a6482a9: startup date [Sat Dec 15 18:51:18 CET 2018]; root of context hierarchy
2018-12-15 18:51:23,426 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:51:23,427 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Informed to shut down
2018-12-15 18:51:23,427 INFO kafka-streams-close-thread  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN
2018-12-15 18:51:23,524 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutting down
2018-12-15 18:51:23,541 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wordcount-lambda-example-client-StreamThread-1-restore-consumer, groupId=] Unsubscribed all topics or patterns and assigned partitions
2018-12-15 18:51:23,541 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=wordcount-lambda-example-client-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-12-15 18:51:23,548 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2018-12-15 18:51:23,548 INFO wordcount-lambda-example-client-StreamThread-1  org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wordcount-lambda-example-client-StreamThread-1] Shutdown complete
2018-12-15 18:51:23,549 INFO kafka-streams-close-thread  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] State transition from PENDING_SHUTDOWN to NOT_RUNNING
2018-12-15 18:51:23,549 INFO Thread-2  org.apache.kafka.streams.KafkaStreams - stream-client [wordcount-lambda-example-client] Streams client stopped completely
2018-12-15 18:51:23,549 INFO Thread-2  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-12-15 18:51:23,550 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000227: Running hbm2ddl schema export
2018-12-15 18:51:23,553 INFO Thread-2  org.hibernate.tool.hbm2ddl.SchemaExport - HHH000230: Schema export complete
